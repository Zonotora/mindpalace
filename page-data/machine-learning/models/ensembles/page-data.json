{"componentChunkName":"component---src-templates-file-js","path":"/machine-learning/models/ensembles","result":{"data":{"markdownRemark":{"html":"<h1 id=\"What-is-an-ensemble\">What is an ensemble?</h1>\n<p>Ensembles \n          <sup><a class=\"reference-link\" href=\"#reference-link-wiki\">[1]</a></sup>\n         are machine learning models that combine several other models. Ensembles often have great accuracy. If an ensemble is built by many different classifiers each with an accuracy of 0.6. The errors of each model are independent. Thus, there is a greater probability that the classifiers (because of diversity) can complement each other. It is often not very realistic to assume that the errors are independent .</p>\n<p>An ensemble could use the average of all the different models as the final prediction value. It could also use a technique called \n          <span class=\"keyword-link\" id=\"keyword-link-stacking\">\n          stacking\n          </span>\n          .</p>\n<p>Scikit-learn has many useful methods for managing ensembles \n          <sup><a class=\"reference-link\" href=\"#reference-link-sklearn\">[2]</a></sup>\n        .</p>\n<h1 id=\"Training\">Training</h1>\n<p>One idea is called \n          <span class=\"keyword-link\" id=\"keyword-link-bagging\">\n          bagging\n          </span>\n          . In that approach we take the original training set and sample from it. Thus, we get a number of new training sets. It is normally done with replacement which may result in one instance ending up many times in the new sample or not at all. Another useful techique is called \n          <span class=\"keyword-link\" id=\"keyword-link-spinning\">\n          spinning\n          </span>\n          . It craetes new training sets by randomly picking subsets of features. This is often done without replacement. We could combine both ideas.</p>\n<h1 id=\"Boosting\">Boosting</h1>\n<p><p>There are two popular boosting algorithms, \n          <span class=\"keyword-link\" id=\"keyword-link-adaboost\">\n          AdaBoost\n          </span>\n           and \n          <span class=\"keyword-link\" id=\"keyword-link-gradientboosting\">\n          gradient boosting\n          </span>\n          , where AdaBoost being the most popular. Both are supported by Scikit-learn \n          <sup><a class=\"reference-link\" href=\"#reference-link-adaboost\">[3]</a></sup>\n         \n          <sup><a class=\"reference-link\" href=\"#reference-link-gradientboostingc\">[4]</a></sup>\n         \n          <sup><a class=\"reference-link\" href=\"#reference-link-gradientboostingr\">[5]</a></sup>\n        . AdaBoost works by giving each instances which are misclassified a higher importance after each iteration before the next one. Unlike bagging, we may overfit the model if we add more trees to a boosting algorithm.</p></p>\n<h1 id=\"References\">References</h1>\n\n\n\n\n\n<div class=\"reference-items\"><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-wiki\">[1]</div><div class=\"reference-content\"><i>Ensemble learning</i>. <a href=\"https://en.wikipedia.org/wiki/Ensemble_learning\">https://en.wikipedia.org/wiki/Ensemble_learning</a>. </div></div><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-sklearn\">[2]</div><div class=\"reference-content\"><i>Ensemble methods</i>. <a href=\"https://scikit-learn.org/stable/modules/ensemble.html\">https://scikit-learn.org/stable/modules/ensemble.html</a>. </div></div><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-adaboost\">[3]</div><div class=\"reference-content\"><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html</a>. </div></div><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-gradientboostingc\">[4]</div><div class=\"reference-content\"><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</a>. </div></div><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-gradientboostingr\">[5]</div><div class=\"reference-content\"><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html</a>. </div></div></div>","frontmatter":{"slug":"/machine-learning/models/ensembles","tags":["machine-learning"],"lastModified":"2021-04-30","created":"2021-04-02","title":"Ensembles","header":[{"depth":1,"name":"What is an ensemble?","link":"What-is-an-ensemble?"},{"depth":1,"name":"Training","link":"Training"},{"depth":1,"name":"Boosting","link":"Boosting"},{"depth":1,"name":"References","link":"References"}]}}},"pageContext":{"slug":"/machine-learning/models/ensembles"}},"staticQueryHashes":[]}