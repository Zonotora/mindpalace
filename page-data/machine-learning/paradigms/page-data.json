{"componentChunkName":"component---src-templates-file-js","path":"/machine-learning/paradigms","result":{"data":{"markdownRemark":{"html":"<h1 id=\"Supervised-learning\">Supervised learning</h1>\n<p>Our model tries to imitate examples.</p>\n<h1 id=\"Unsupervised-learning\">Unsupervised learning</h1>\n<p>In unsupervised learning we do not have the labeled parts. In unsupervised learning we try to discover some patterns about the data: explore, visualize and understand.</p>\n<h2 id=\"Clustering\">Clustering</h2>\n<p>Clustering \n          <sup><a class=\"reference-link\" href=\"#reference-link-clusteringwiki\">[1]</a></sup>\n         \n          <sup><a class=\"reference-link\" href=\"#reference-link-clustering\">[2]</a></sup>\n         describes data by forming it into groups or hierarchies. The goal of clustering is to discover natural groups in a data set. A natural group is data points which are very much alike but different from other groups.</p>\n<p>To evaluate similarity there are some different options. For vectorized data it is common to use Euclidean distance.</p>\n<h3 id=\"Flat\">Flat</h3>\n<h4 id=\"Finding-representatives\">Finding representatives</h4>\n<p>Each cluster is characterized by a center. We can used different techniques, e.g. \n          <span class=\"keyword-link\" id=\"keyword-link-k-means\">\n          k-means\n          </span>\n          , \n          <span class=\"keyword-link\" id=\"keyword-link-k-medoids\">\n          k-medoids\n          </span>\n           or \n          <span class=\"keyword-link\" id=\"keyword-link-mean shift\">\n          mean shift\n          </span>\n          , to get a center vector.</p>\n<h4 id=\"Probabilistic-approach\">Probabilistic approach</h4>\n<p>Each cluster is represented by a distribution.</p>\n<h4 id=\"Dense-approach\">Dense approach</h4>\n<p>Find dense regions with algorithms like \n          <span class=\"keyword-link\" id=\"keyword-link-DBSCAN\">\n          DBSCAN\n          </span>\n          </p>\n<h3 id=\"Hierarchical\">Hierarchical</h3>\n<p>There are two approaches, \n          <span class=\"keyword-link\" id=\"keyword-link-agglomerative\">\n          applomerative\n          </span>\n           which is bottom-up and \n          <span class=\"keyword-link\" id=\"keyword-link-divisive\">\n          divisive\n          </span>\n           which is top-down.</p>\n<h2 id=\"Statistical-distribution\">Statistical distribution</h2>\n<p>We want to use our model to find data points that are highly unusual.</p>\n<h2 id=\"Representation\">Representation</h2>\n<p>We want to learn some new representation of the data, e.g. reducing the data set to lower dimensions.</p>\n<p>It is good for visualization, and reducing the need for storage which makes the algorithm run faster and the learning easier.</p>\n<h1 id=\"Semisupervised-learning\">Semisupervised learning</h1>\n<p>Follows the same patterns as supervised learning, but we just don't have enough labeled data.</p>\n<h1 id=\"Reinforcement-learning\">Reinforcement learning</h1>\n<h1 id=\"References\">References</h1>\n\n\n<div class=\"reference-items\"><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-clusteringwiki\">[1]</div><div class=\"reference-content\"><a href=\"https://en.wikipedia.org/wiki/Cluster_analysis\">https://en.wikipedia.org/wiki/Cluster_analysis</a>. </div></div><div class=\"reference\"><div class=\"reference-number\"\n      id=\"reference-link-clustering\">[2]</div><div class=\"reference-content\"><a href=\"https://scikit-learn.org/stable/modules/clustering.html\">https://scikit-learn.org/stable/modules/clustering.html</a>. </div></div></div>","frontmatter":{"slug":"/machine-learning/paradigms","tags":["chalmers","machine-learning"],"lastModified":"2021-05-03","created":"2021-05-03","title":"Paradigms","header":[{"depth":1,"name":"Supervised learning","link":"Supervised-learning"},{"depth":1,"name":"Unsupervised learning","link":"Unsupervised-learning"},{"depth":2,"name":"Clustering","link":"Clustering"},{"depth":3,"name":"Flat","link":"Flat"},{"depth":4,"name":"Finding representatives","link":"Finding-representatives"},{"depth":4,"name":"Probabilistic approach","link":"Probabilistic-approach"},{"depth":4,"name":"Dense approach","link":"Dense-approach"},{"depth":3,"name":"Hierarchical","link":"Hierarchical"},{"depth":2,"name":"Statistical distribution","link":"Statistical-distribution"},{"depth":2,"name":"Representation","link":"Representation"},{"depth":1,"name":"Semisupervised learning","link":"Semisupervised-learning"},{"depth":1,"name":"Reinforcement learning","link":"Reinforcement-learning"},{"depth":1,"name":"References","link":"References"}]}}},"pageContext":{"slug":"/machine-learning/paradigms"}},"staticQueryHashes":[]}