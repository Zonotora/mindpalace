{"componentChunkName":"component---src-templates-file-js","path":"/os/processes-and-threads","result":{"data":{"markdownRemark":{"html":"<h1 id=\"Introduction\">Introduction</h1>\n<p>Concurrent is not the same as parallel. Concurrent means that we feel that many processes run at the same time, but they actually do not. The kernel switch so fast between each process that we feel that they run at the same time. Parallel execution means that the processes are actually run in parallel. They are executed at the same time on different CPU cores.</p>\n<h2 id=\"Amdahls-Law\">Amdahl's Law</h2>\n<p>Amdahl's law state the performance gain by adding CPU cores to an execution that has both serial and parallel components. It could be stated in a formula:</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">speedup</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.56644em;vertical-align:-1.245em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.1099999999999994em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05764em;\">S</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span><span style=\"top:-3.2399999999999998em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.687em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.245em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>\n<p>where <span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span> is the <em>serial portion</em> and <span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> is the <em>processing cores</em>.</p>\n<p>As an example, suppose that an application has a section that is 75% parallel and 25% serial, then moving from 1 to 2 cores has</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">speedup</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.56644em;vertical-align:-1.245em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.1099999999999994em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">2</span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">2</span><span class=\"mord mtight\">5</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span><span style=\"top:-3.2399999999999998em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.687em;\"><span class=\"pstrut\" style=\"height:3.01em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.245em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\">6</span></span></span></span></span>\n<p>Thus the speedup cannot be greater than <span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\">6</span></span></span></span>.</p>\n<h1 id=\"Processes\">Processes</h1>\n<p>A process is one of the oldest and most important abstractions in an operating system. They support (pseudo) concurrent operations even when there is only one CPU available. In a multiprogramming system the CPU switches between processes very quickly only running each for a couple of (multiple of) milliseconds. Thus, at any given time only one process is running, but because of the fast switching between processes it gives the illusion of concurrent execution.</p>\n<h2 id=\"The-model\">The model</h2>\n<p>A process is an instance of an executing program including information about the program counter, variables and registers. The os can therefore switch between processes in a rapid manner and save each process' state so the next time that process starts executing it can go on from where it left. The rapid switching of processes is called \n          <span class=\"keyword-link\" id=\"keyword-link-multiprogramming\">\n          multiprogramming\n          </span>\n          . Processes in UNIX form a tree structure, while this is not the case in Windows.</p>\n<h2 id=\"Creation\">Creation</h2>\n<p>Four main events can cause processes to be generated:</p>\n<ol>\n<li>System initialization.</li>\n<li>Calling a process-creation system call from a running process.</li>\n<li>A user request.</li>\n<li>Initiation of a batch job.</li>\n</ol>\n<p>When the operating system is booting a number of different processes are created. These could be foreground applications or background processes, also called \n          <span class=\"keyword-link\" id=\"keyword-link-daemons\">\n          daemons\n          </span>\n          . In UNIX(-like) there is only one system call to create a new process: <code class=\"language-text\">fork()</code>. This call duplicates the running process and the two processes will after the call, have the same memory image, environment, the same open files. To fork in C we do the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    pid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">// if pid=0 we are the child process</span>\n    <span class=\"token comment\">// else we are the parent process</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\">// child</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\">// parent</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>We need to wait for the child process to completely remove the process from memory once it has finished. We do this by the <code class=\"language-text\">waitpid</code> system call.\nA zombie process is a process which has finished, but not been successfully terminated from its parent (waited). A process will when it dies, send the <code class=\"language-text\">SIGCHLD</code> signal to its parent indicating that the parent can wait for the child process to exit it successfully.\nWe can't kill zombie processes with the <code class=\"language-text\">SIGKILL</code> signal as zombie processes are already dead. Instead we have to send the <code class=\"language-text\">SIGCHLD</code> signal to the parent process. We can do this by the <code class=\"language-text\">kill</code> command as follows:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">kill</span> -s SIGCHILD pid</code></pre></div>\n<p>If the parent is not programmed to handle this signal, we have to kill the parent process. Zombie processes of a terminated process will be inherited by <code class=\"language-text\">init</code>, which will become the new parent. <code class=\"language-text\">init</code> is the first process started and has <span class=\"katex\"><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">pid</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>. <code class=\"language-text\">init</code> will wait for each zombie child process periodically, making them exit gracefully.\nIf we do not free up any zombie processes, they will start taking up a majority of the available pids on the system, which eventually will block us from creating new processes.</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// pid_t waitpid(pid_t pid, int *status, int options);</span>\n<span class=\"token comment\">// pid     0: Wait for any child process whose process</span>\n<span class=\"token comment\">//            group ID is equal to that of the calling process.</span>\n<span class=\"token comment\">//        -1: Wait for any child process.</span>\n<span class=\"token comment\">//       > 0: Wait for the child whose process ID is equal to</span>\n<span class=\"token comment\">//            the value of pid.</span>\n<span class=\"token comment\">//      &lt; -1: Wait for any child process whose process group</span>\n<span class=\"token comment\">//            ID is equal to the absolute value of pid.</span>\n<span class=\"token function\">waitpid</span><span class=\"token punctuation\">(</span>pid<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>status<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>By default this system call is blocking. To prevent this we can pass the flag option <code class=\"language-text\">WNOHANG</code>. This tells <code class=\"language-text\">waitpid</code> to return immediately if there is no child processes ready to be noticed.</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// pid_t waitpid(pid_t pid, int *status, int options);</span>\n<span class=\"token comment\">// options    WNOHANG: Return immediately</span>\n<span class=\"token comment\">//          WUNTRACED: Additionally return if a child has</span>\n<span class=\"token comment\">//                     stopped.</span>\n<span class=\"token comment\">//         WCONTINUED: Additionally return if a stopped child</span>\n<span class=\"token comment\">//                     has been resumed by the signal SIGCONT</span>\n<span class=\"token function\">waitpid</span><span class=\"token punctuation\">(</span>pid<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>status<span class=\"token punctuation\">,</span> WNOHANG<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>Here is an example of a signal handler that will take care of background child processes when they are finished:</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// handler for SIGCHLD, the signal that indicates that at</span>\n<span class=\"token comment\">// least one child process has been terminated</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">background_wait</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> s<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">int</span> wpid<span class=\"token punctuation\">,</span> status<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\">// check if there are some processes that have</span>\n        <span class=\"token comment\">// finished running and finish them then return</span>\n        wpid <span class=\"token operator\">=</span> <span class=\"token function\">waitpid</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>status<span class=\"token punctuation\">,</span> WNOHANG<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// there are some processes that are not finished</span>\n        <span class=\"token comment\">// or no processes at all return</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>wpid <span class=\"token operator\">&lt;=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>The <code class=\"language-text\">SIGCHLD</code> handler must be set up before a child process is forked. We need to have a loop here because we don't know how many child processes that have exited.</p>\n<h2 id=\"State\">State</h2>\n<p>A process may be in the following states:</p>\n<ol>\n<li>Running (using the CPU)</li>\n<li>Ready (temporarily stopped to let another process run, but runnable)</li>\n<li>Blocked (unable to run until some external event happens)</li>\n</ol>\n<p>The first and second state are almost the same, both signaling that they want to be run. It is just a matter of which process the operating system chooses to \"switch to\" at that time instant. The third state will not run even if the CPU is idle. In systems like UNIX when a process reads from a pipe or special file and there is no input available the process is automatically blocked. Transitions from state 1 and state 2 is dependent on the process scheduler. There are many different algorithms to choose from when implementing the process schduler, each optimizing some requirement. There is, however no algorithm that excels in every aspect which leads to tradeoffs.</p>\n<h2 id=\"Implementation\">Implementation</h2>\n<p>The operating system maintains a table with one process per entry. Each entry contains important information about the process' state, like the stack pointer, memory allocation, program counter, open files, scheduling information and other useful information. This information is needed to allow the operating system to start the process again after being the blocked or ready state as if it was never there. The \n          <span class=\"keyword-link\" id=\"keyword-link-interrupt-vector\">\n          interrupt vector\n          </span>\n           assists in maintaining multiple processes on each CPU. This table shows some of the usual information which is used in a process table entry:</p>\n<table>\n<thead>\n<tr>\n<th>Process management</th>\n<th>Memory management</th>\n<th>File management</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Registers</td>\n<td>Pointer to text segment info</td>\n<td>Root directory</td>\n</tr>\n<tr>\n<td>Program counter</td>\n<td>Pointer to data segment info</td>\n<td>Working directory</td>\n</tr>\n<tr>\n<td>Program status word</td>\n<td>Pointer to stack segment info</td>\n<td>File descriptors</td>\n</tr>\n<tr>\n<td>Stack pointer</td>\n<td></td>\n<td>User ID</td>\n</tr>\n<tr>\n<td>Process state</td>\n<td></td>\n<td>Group ID</td>\n</tr>\n<tr>\n<td>Priority</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Scheduling parameters</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Process ID</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Parent process</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Process group</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Signals</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Time when process started</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>CPU time used</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Children's CPU time</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Time of next alarm</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"Threads\">Threads</h1>\n<p>A thread is just like a process, but with one major difference: it shares the same address space with other threads of the same process. That means every thread of a process will also share the same global variables. A thread has the same states as a process:</p>\n<ul>\n<li>running</li>\n<li>blocked</li>\n<li>ready</li>\n<li>terminated</li>\n</ul>\n<p>There are a couple of multithreading models:</p>\n<ul>\n<li>Many-to-One</li>\n<li>One-to-One</li>\n<li>Many-to-Many</li>\n</ul>\n<h2 id=\"Implicit-threading\">Implicit threading</h2>\n<p>Program correctness may become very difficult to assure as the number of threads increase leading to management of threads by the programmer becoming hard to sustain. This leads to thread management being done by compilers or run-time libraries instead of the programmers.</p>\n<h2 id=\"POSIX-threads\">POSIX threads</h2>\n<p>IEEE defines a standard for writing portable threaded programs and most UNIX system supports it.</p>\n<table>\n<thead>\n<tr>\n<th>Call</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Pthread_create</td>\n<td>Creates a new thread</td>\n</tr>\n<tr>\n<td>Pthread_exit</td>\n<td>Terminates the thread</td>\n</tr>\n<tr>\n<td>Pthread_join</td>\n<td>Waits for a thread to exit</td>\n</tr>\n<tr>\n<td>Pthread_yield</td>\n<td>Release CPU for another thread</td>\n</tr>\n<tr>\n<td>Pthread_attr_init</td>\n<td>Create and initialize a thread's attribute structure</td>\n</tr>\n<tr>\n<td>Pthread_attr_destroy</td>\n<td>Remove a thread's attribute structure</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Implementation-user-space\">Implementation user space</h2>\n<p>A thread may be implemented in either the user space or the kernel. If the implementation is in the user space it has the advantage of not needing the operating system to support threading (the kernel). A \n          <span class=\"keyword-link\" id=\"keyword-link-thread-table\">\n          thread table\n          </span>\n           is needed as well, which has a similar function to the kernel's process table. Invoking threading operations in user space is just local procedures, which certainly is more efficient than making a kernel call, because no trapping is needed, no context switching and the memory cache does not need to be flushed. The threading algorithm may be customized as well in a more flexible manner. However, there are few problems. Namely, how to implement blocking system calls. Letting one thread make a blocking system call will stop all threads, because it blocks the whole process. Another problem is that if a thread starts running it never stops if it does not want to. Precisely, a thread must give up the CPU volountarily so that other threads also can work, because there is no clock interrupts making it impossible to schedule round-robin. Solutions to overcome this is often messy. The general argument against user space threading is that threads are used to make blocking calls, so that other code can run meanwhile the application is waiting for a certain task. But implementing blocking behaviour is messy.</p>\n<h2 id=\"Implementation-kernel\">Implementation kernel</h2>\n<p>A kernal implementation of threading does not need a run-time system for each threads as well as no thread table in each process. The kernel keeps track of each thread with a thread table of its own. Every mutating operation involving threading is updated in the thread table. The thread table stores each thread's registers, state, among other information (the same information as user space threads but different location). The process table is still used alongside the thread table. Every blocking call in each thread is implemented as a system call. When a thread is blocked, the kernel may run a thread from the same process or a thread from another process. But this all comes with a greatly increased cost, which is why some systems recycle threads. That is, when a thread is destroyed it is marked as not runnable, but the data structure remains untouched. When a new thread is created later on, it can reuse the recycled thread's data structure to save some overhead.</p>\n<h2 id=\"Scheduler-activations\">Scheduler activations</h2>\n<p>To use the best of both worlds, a concept called scheduler activations was developed. They try to mimic the functionality of kernel threads, but with performance more alike of user threads. Nonblocking system calls and checks in advance should not be necessary to make certain system calls. When a thread is blocking because of a system call or a page fault, other threads within the same process should be able to run. The kernel creates a certain number of virtual processors for each process. The user space run-time is then allowed to allocate threads to the processors. The basic idea behind scheduler activations then follows a mechanism called \n          <span class=\"keyword-link\" id=\"keyword-link-upcall\">\n          upcall\n          </span>\n          .</p>\n<h2 id=\"Pop-up-thread\">Pop-up thread</h2>\n<p>A pop-up thread is a thread that is created to handle a new request meanwhile the parent thread continues to handle new incoming requests.</p>\n<h1 id=\"Processes-and-threads-in-Linux\">Processes and threads in Linux</h1>\n<p>The kernel represents processes as tasks internally. A task represents any execution context, therefore making no distiction between a process and a thread. This is unlike most OS approaches. A single-threaded process will hence be represented as one task, and a multithreaded process will have one task for each thread. Linux identifies each process with its PID. For each process a process descriptor is active in memory for as long as the process is active. It contains information needed to manage all processes, e.g. scheduling parameters, open file descriptors with more. The information can be split up in a few broad categories:</p>\n<ol>\n<li><strong>Scheduling parameters</strong> Includes process priority, consumed CPU time and consumed sleep time which are used to determine which process to run next.</li>\n<li><strong>Memory image</strong> Pointers to the page tables and text, data, and stack segements of a process when the process is in memory. When it is not it instead contains the location on the disk. This also includes visiblity information about each data block.</li>\n<li><strong>Signals</strong> Which signals should be caught, ignored, blocked and active.</li>\n<li><strong>Machine registers</strong> Traps to the kernel are stored here.</li>\n<li><strong>System call state</strong> The current system call is stored here.</li>\n<li><strong>File descriptor table</strong> Involved file descriptors for a system call.</li>\n<li><strong>Acounting</strong> General limits the kernel puts on each process, like maximum stack size for each process.</li>\n<li><strong>Kernel stack</strong> The kernel stack which is used to handle kernel parts by a process.</li>\n<li><strong>Other</strong> Current process state with more.</li>\n</ol>\n<p>When a new process is created a new process descriptor is created which contains information that mostly is filled in by the parent process often based upon its own values. Linux checks for an available PID, assigns it, and updates the PID hash-table to point to the new task. The semantics of the the instruction <code class=\"language-text\">fork</code> say that no memory is shared between the parent and the child, but that means that we need to copy these structures. Linux avoids this by giving each child its own empty structure but pointing them to the parent with read-only access. The structures are only allocated once the child attempts to write to these read-only parent structures. Then being marked with both read and write access. Linux introduces a system call <code class=\"language-text\">clone</code> not found in any other version of UNIX, to deal with many of the issuses arising from threads when for example forking.</p>\n<h1 id=\"Scheduling\">Scheduling</h1>\n<p>When a computer is constructed to allow multiple processes to run at the same time, each process constantly competes for CPU time. If one process is the only one in ready state, the competition is easy. But when there a more than one process in ready state and only CPU is available the operating system has to decide which process to execute next. The component making this desicion is the scheduler which uses a scheduling algorithm to decide which process to execute next. Scheduling most often applies to both processes and threads.</p>\n<h2 id=\"Process-behaviour\">Process behaviour</h2>\n<p>To be able to construct a good scheduling algorithm one needs to analyze how different processes utilize the CPU. Some processes spend a considerable amount of time computing. These processes are called \n          <span class=\"keyword-link\" id=\"keyword-link-CPU-bound\">\n          CPU-bound\n          </span>\n          . Other processes are mostly waiting for I/O and they are called \n          <span class=\"keyword-link\" id=\"keyword-link-I/O-bound\">\n          I/O-bound\n          </span>\n           processes. I/O-bound activity is defined as when a process enters blocked state while waiting for an external device to finish. One observation is that CPU-bound processes have long CPU bursts (occupies the CPU for longer period of time) while I/O-bound processes have short CPU bursts (occupies the CPU for shorter period of time). Thus, the principal idea is to let I/O-bound processes higher priority to run so that they can issue disk requests and keep the disk busy while the CPU is doing some other computation. If there are no available processes after a process exits, an idle process provided by the system is usually run. Scheduling algorithms can be divided into two different groups: \n          <span class=\"keyword-link\" id=\"keyword-link-nonpreemptive\">\n          nonpreemptive\n          </span>\n           and \n          <span class=\"keyword-link\" id=\"keyword-link-preemptive\">\n          preemptive\n          </span>\n           depending on how the deal with clock interrupts. A nonpreemptive scheduling algorihtm picks a process to run until it blocks. It could in fact run for several hours nonstop. A preemptive scheduling algorithm picks a process to run for a fixed amount of time. When that fixed period of time has finished the process is \n          <span class=\"keyword-link\" id=\"keyword-link-suspended\">\n          suspended\n          </span>\n           and the algorithm picks another process to run instead.</p>\n<h2 id=\"Categories-of-scheduling\">Categories of scheduling</h2>\n<p>There are three different environments worth distinguishing when talking about scheduling. These are</p>\n<ol>\n<li>Batch</li>\n<li>Interactive</li>\n<li>Real time</li>\n</ol>\n<p>In <strong>batch</strong> systems long waiting times are often acceptable, which means a nonpreemptive or a preemptive (with a long fixed duration) is suitable. They are applicable in corporate mainframes. When there are <strong>interative</strong> users involved in the system, preemption is necessary to keep one process from dominating the CPU usage. In <strong>real time</strong> systems there is often no need to have preemptive scheduling, because the processes run in such environment know that they are not going to use the compute resources for a long time and blocks quickly. Because there are different use cases, the goal of the scheduling algorithm differs as well.</p>\n<p><strong>General System</strong></p>\n<ul>\n<li>Fairness</li>\n<li>Policy enforcement</li>\n<li>Balance</li>\n</ul>\n<p><strong>Batch</strong></p>\n<ul>\n<li>Throughput</li>\n<li>Turnaround time (time for a batch to finish)</li>\n<li>CPU utilization</li>\n</ul>\n<p><strong>Interative</strong></p>\n<ul>\n<li>Response time</li>\n<li>User experience (proportionality)</li>\n</ul>\n<p><strong>Real time</strong></p>\n<ul>\n<li>Deadlines</li>\n<li>Predictability</li>\n</ul>\n<h2 id=\"Algorithms-used-in-batch-systems\">Algorithms used in batch systems</h2>\n<p><strong>Nonpreemptive first-come, first-served</strong>. Here we have a single queue of ready processes. The first process that enters the queue may run for how much as it wants, then when terminated or blocked, the next process that started (the next process in the queue) gets to run. As more processes start they are put onto the end of the queue. When a blocked process becomes ready, it is also put onto the end of the queue. The disadvantages with this is that processes with short CPU time but that are I/O bound and placed after a long CPU bound process will have to wait until their turn, even though that could have run simultaneously with the long CPU bound process.</p>\n<p><strong>Shortest job first</strong>. This is another nonpreemptive algorithm that run times are known beforehand. The scheduler picks the shortest of these run times first. If we have four jobs A,B,C,D with runtimes 8,4,4,4 minutes the turnaround time for each one of these is 8,12,16,20 respectively if we run them in the order given. If we use the shortest job first we instead run A last, reducing the mean of the turnaround times. It is an optimal solution if every job is available simultaneously.</p>\n<p><strong>Shortest remaining time left</strong>. This is a preemptive version of the shortest job first. The scheduler chooses the process with the smallest run time remaining. Again we must know the run times in advance. This algorithm favors new processes with small run time.</p>\n<h2 id=\"Algorithms-used-in-interactive-systems\">Algorithms used in interactive systems</h2>\n<p><strong>Round-robin scheduling</strong>. One of the classics (oldest, fairest and most widely used). Each process gets a time interval called <code class=\"language-text\">quantum</code> during which it is allowed to run. If the process is still running at the end of the quantum the scheduler gives the CPU to another process. Otherwise, the schedule switching occurs when the process blocks or terminates as usual. The scheduler keeps a list of all the processes. When a process has finished its quantum it is put at the end of the list. Setting the quantum to a reasonable length is often a tradeoff between switching to much (context switch overhead) and not giving short interactive requests time to run (longer quantum length). In pratice 20-50 msec is often used.</p>\n<p><strong>Priority scheduling</strong>. In this algorithm a process is assigned a priority of how important it is. The scheduler switches to the process with the highest priority. It is often convenient to use round-robin in combination with priority scheduling and use priority classes. Within each class round-robin is used, but for each class priority scheduling is used.</p>\n<p><strong>Other</strong></p>\n<ul>\n<li>Multiple queues</li>\n<li>Shortest process next (similar to shortest job first, but for interactive systems)</li>\n<li>Guaranteed scheduling</li>\n<li>Lottery scheduling</li>\n<li>Fair-share scheduling</li>\n</ul>\n<h2 id=\"Policy\">Policy</h2>\n<p>Because no scheduler algorithm is best in all cases there is a need to separate the logic of the scheduling mechanism from the scheduling policy. The scheduling algorithm in of itself becomes parametrized in a way which makes it more flexible and can depend on the scenario instead of being fixed.</p>\n<div class=\"reference-items\"></div>","frontmatter":{"slug":"/os/processes-and-threads","tags":[],"lastModified":"2022-03-31","created":"2021-09-11","title":"Processes And Threads","header":[{"depth":1,"name":"Introduction","link":"Introduction"},{"depth":2,"name":"Amdahl's Law","link":"Amdahl's-Law"},{"depth":1,"name":"Processes","link":"Processes"},{"depth":2,"name":"The model","link":"The-model"},{"depth":2,"name":"Creation","link":"Creation"},{"depth":2,"name":"State","link":"State"},{"depth":2,"name":"Implementation","link":"Implementation"},{"depth":1,"name":"Threads","link":"Threads"},{"depth":2,"name":"Implicit threading","link":"Implicit-threading"},{"depth":2,"name":"POSIX threads","link":"POSIX-threads"},{"depth":2,"name":"Implementation user space","link":"Implementation-user-space"},{"depth":2,"name":"Implementation kernel","link":"Implementation-kernel"},{"depth":2,"name":"Scheduler activations","link":"Scheduler-activations"},{"depth":2,"name":"Pop-up thread","link":"Pop-up-thread"},{"depth":1,"name":"Processes and threads in Linux","link":"Processes-and-threads-in-Linux"},{"depth":1,"name":"Scheduling","link":"Scheduling"},{"depth":2,"name":"Process behaviour","link":"Process-behaviour"},{"depth":2,"name":"Categories of scheduling","link":"Categories-of-scheduling"},{"depth":2,"name":"Algorithms used in batch systems","link":"Algorithms-used-in-batch-systems"},{"depth":2,"name":"Algorithms used in interactive systems","link":"Algorithms-used-in-interactive-systems"},{"depth":2,"name":"Policy","link":"Policy"}]}}},"pageContext":{"slug":"/os/processes-and-threads"}},"staticQueryHashes":[]}