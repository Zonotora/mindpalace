{"/bandits#":{"id":"/bandits#","title":"/bandits#","tags":"[\"wip\"]#","body":""},"/bandits#Notation":{"id":"/bandits#Notation","title":"/bandits#Notation","tags":"[\"wip\"]#Notation","body":"| Definition | Description |\n|-| :\n"},"/control-theory#":{"id":"/control-theory#","title":"/control-theory#","tags":"[]#","body":"Linjarisering\"},{\"depth\":1,\"name\":\"Tids- och frekvensplanet\",\"link\":\"Tids--och-frekvensplanet\"},{\"depth\":2,\"name\":\"Första ordningens system\",\"link\":\"Forsta-ordningens-system\"},{\"depth\":2,\"name\":\"Andra ordningens system\",\"link\":\"Andra-ordningens-system\"},{\"depth\":2,\"name\":\"Bodediagram\",\"link\":\"Bodediagram\"},{\"depth\":3,\"name\":\"Geometrisk tolkning\",\"link\":\"Geometrisk-tolkning\"},{\"depth\":3,\"name\":\"Arbetsgång - Bodediagram\",\"link\":\"Arbetsgang\n"},"/image-analysis#":{"id":"/image-analysis#","title":"/image-analysis#","tags":"[\"wip\"]#","body":""},"/image-analysis#Image-processing":{"id":"/image-analysis#Image-processing","title":"/image-analysis#Image-processing","tags":"[\"wip\"]#Image-processing","body":""},"/image-analysis#Linear-filtering":{"id":"/image-analysis#Linear-filtering","title":"/image-analysis#Linear-filtering","tags":"[\"wip\"]#Linear-filtering","body":""},"/image-analysis#Non-linear-filtering":{"id":"/image-analysis#Non-linear-filtering","title":"/image-analysis#Non-linear-filtering","tags":"[\"wip\"]#Non-linear-filtering","body":""},"/image-analysis#Feature-detection":{"id":"/image-analysis#Feature-detection","title":"/image-analysis#Feature-detection","tags":"[\"wip\"]#Feature-detection","body":""},"/image-analysis#-Feature-detectors":{"id":"/image-analysis#-Feature-detectors","title":"/image-analysis#-Feature-detectors","tags":"[\"wip\"]#-Feature-detectors","body":"1. Point features\n- Aperture problem\n- spatially varying weighting (or window) function: https://en.wikipedia.org/wiki/Window_function\n- auto-correlation function or surface\n- Adaptive non-maximal suppression (ANMS).\n- Measuring repeatability.\n- Scale invariance\n- SIFT\n- Rotational invariance and orientation estimation\n    - dominant orientation\n- aggregation window vs detection window\n- Affine invariance\n"},"/image-analysis#Feature-descriptors":{"id":"/image-analysis#Feature-descriptors","title":"/image-analysis#Feature-descriptors","tags":"[\"wip\"]#Feature-descriptors","body":"Feature descriptors are used to match keypoints retrieved by feature detection algorithms in different images. When we have extracted descriptors from each feature in at least two images, we begin by selecting a **matching strategy** (determined by the context, e.g. image stitching, object detecting, etc) that determines which correspondences that are qualified to the next stage for further processing. To perform matching as efficiently as possible the second step is to select performant **data structures** for the corresponding problem.\n1. Bias and gain normalization (MOPS).\n- Scale invariant feature transform (SIFT) : https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\n- PCA-SIFT.\n- Gradient location-orientation histogram (GLOH).\n- Steerable filters.\n- ROC curve\n    - the use of TP (true positives), FP (false positive), TN (true negatives), and FN (false negatives) when measuring the performance of the matching strategy.\n- Nearest Neighbor Distance Ratio (NNDR)\n- Efficient matching\n    - indexing structure can be used (hash maps)\n    - multi-dimensional hashing\n    - locality sensitive hashing\n    - parameter sensitive hashing\n    - k-d trees\n"},"/image-analysis#Verification-of-matches":{"id":"/image-analysis#Verification-of-matches","title":"/image-analysis#Verification-of-matches","tags":"[\"wip\"]#Verification-of-matches","body":"When we have gotten matches from the above steps we can use geometric alignment to verify **inliers** and **outliers** in the matches.\n1. Random sampling (RANSAC)\n"},"/image-analysis#Feature-tracking":{"id":"/image-analysis#Feature-tracking","title":"/image-analysis#Feature-tracking","tags":"[\"wip\"]#Feature-tracking","body":"Instead of independently finding features in images and then match them with each other, we could find likely feature locations in the first image and search in these locations in the next images. Commonly used in video tracking applications.\n"},"/image-analysis#Camera":{"id":"/image-analysis#Camera","title":"/image-analysis#Camera","tags":"[\"wip\"]#Camera","body":""},"/image-analysis#2D-point":{"id":"/image-analysis#2D-point","title":"/image-analysis#2D-point","tags":"[\"wip\"]#2D-point","body":"$$\n\\bold x = \\begin{bmatrix}\n    x  \\\\\n    y \\\\\n\\end{bmatrix}\n$$\n"},"/image-analysis#Homogeneous-coordinates":{"id":"/image-analysis#Homogeneous-coordinates","title":"/image-analysis#Homogeneous-coordinates","tags":"[\"wip\"]#Homogeneous-coordinates","body":"Homogeneous coordinates are given on the form\n$$\n\\begin{bmatrix}\n    x \\\\\n    y \\\\\n\\end{bmatrix} \\to\nw \\cdot \\begin{bmatrix}\n    x \\\\\n    y \\\\\n    1 \\\\\n\\end{bmatrix}, \\qquad w \\neq 0\n$$\n"},"/image-analysis#De-homogeneous-coordinates":{"id":"/image-analysis#De-homogeneous-coordinates","title":"/image-analysis#De-homogeneous-coordinates","tags":"[\"wip\"]#De-homogeneous-coordinates","body":"$$\n\\begin{bmatrix}\n    x \\\\\n    y \\\\\n    w \\\\\n\\end{bmatrix} \\to\n\\begin{bmatrix}\n    x/w \\\\\n    y/w \\\\\n\\end{bmatrix}\n$$\n"},"/image-analysis#Basic-set-of-2D-transformations":{"id":"/image-analysis#Basic-set-of-2D-transformations","title":"/image-analysis#Basic-set-of-2D-transformations","tags":"[\"wip\"]#Basic-set-of-2D-transformations","body":"Basic transformation with homogeneous coordinates.\n"},"/image-analysis#Translation-+-rotation":{"id":"/image-analysis#Translation-+-rotation","title":"/image-analysis#Translation-+-rotation","tags":"[\"wip\"]#Translation-+-rotation","body":"$$\n\\tilde \\bold x = \\begin{bmatrix}\n    \\cos \\theta & -\\sin \\theta & t_x \\\\\n    \\sin \\theta & \\cos \\theta & t_y \\\\\n\\end{bmatrix}\n\\bold x\n$$\n"},"/image-analysis#Scaled-rotation":{"id":"/image-analysis#Scaled-rotation","title":"/image-analysis#Scaled-rotation","tags":"[\"wip\"]#Scaled-rotation","body":"$$\n\\tilde \\bold x = \\begin{bmatrix}\n    a & -b & t_x \\\\\n    b & a & t_y \\\\\n\\end{bmatrix}\n\\bold x\n$$\n"},"/image-analysis#Affine":{"id":"/image-analysis#Affine","title":"/image-analysis#Affine","tags":"[\"wip\"]#Affine","body":"$$\n\\tilde \\bold x = \\begin{bmatrix}\n    a_{00} & a_{01} & a_{02} \\\\\n    a_{10} & a_{11} & a_{12} \\\\\n\\end{bmatrix}\n\\bold x\n$$\n"},"/image-analysis#Projective":{"id":"/image-analysis#Projective","title":"/image-analysis#Projective","tags":"[\"wip\"]#Projective","body":"Projective is also known as homography.\n"},"/image-analysis#Orthography":{"id":"/image-analysis#Orthography","title":"/image-analysis#Orthography","tags":"[\"wip\"]#Orthography","body":"Contrary to how projective projection, orthographic projection simply drops the z component of a three-dimensional coordinate to obtain the 2D point.\n"},"/image-analysis#Homography":{"id":"/image-analysis#Homography","title":"/image-analysis#Homography","tags":"[\"wip\"]#Homography","body":"Homography is the technique of using projection mapping with the homogeneous coordinates to achieve the transformation. It is written like this\n$$\n\\begin{bmatrix}\n    \\tilde x \\\\\n    \\tilde y \\\\\n    \\tilde w \\\\\n\\end{bmatrix} =\n\\begin{bmatrix}\n    a & b & c \\\\\n    d & e & f \\\\\n    g & h & i \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n    x \\\\\n    y \\\\\n    w \\\\\n\\end{bmatrix}\n$$\nIt could also be written like this\n$$\n\\tilde x = H x\n$$\nIt is required that\n1. H needs to be invertible\n- H has 8 Degrees-of-Freedom (DoF)\nTo apply the transformation, we first transform the coordinates to homogeneous coordinates. Then we use homography on the coordinates. Then we transform the coordinates back by de-homogenzing them.\n"},"/image-analysis#General-intrinsic-camera-calibration-matrix":{"id":"/image-analysis#General-intrinsic-camera-calibration-matrix","title":"/image-analysis#General-intrinsic-camera-calibration-matrix","tags":"[\"wip\"]#General-intrinsic-camera-calibration-matrix","body":"$$\nK = \\begin{bmatrix}\n    f & s & p_x \\\\\n    0 & \\alpha f & p_y \\\\\n    0 & 0 & 1 \\\\\n\\end{bmatrix}\n$$\n"},"/image-analysis#Relative-pose-estimation":{"id":"/image-analysis#Relative-pose-estimation","title":"/image-analysis#Relative-pose-estimation","tags":"[\"wip\"]#Relative-pose-estimation","body":""},"/image-analysis#Epipolar-geometry":{"id":"/image-analysis#Epipolar-geometry","title":"/image-analysis#Epipolar-geometry","tags":"[\"wip\"]#Epipolar-geometry","body":""},"/image-analysis#The-essential-matrix":{"id":"/image-analysis#The-essential-matrix","title":"/image-analysis#The-essential-matrix","tags":"[\"wip\"]#The-essential-matrix","body":""},"/image-analysis#The-fundamental-matrix":{"id":"/image-analysis#The-fundamental-matrix","title":"/image-analysis#The-fundamental-matrix","tags":"[\"wip\"]#The-fundamental-matrix","body":""},"/latex#":{"id":"/latex#","title":"/latex#","tags":"[\"wip\"]#","body":""},"/latex#List-to-Katex-supported":{"id":"/latex#List-to-Katex-supported","title":"/latex#List-to-Katex-supported","tags":"[\"wip\"]#List-to-Katex-supported","body":"https://katex.org/docs/supported.html\n"},"/latex#Symbols":{"id":"/latex#Symbols","title":"/latex#Symbols","tags":"[\"wip\"]#Symbols","body":"|$ \\Alpha $ | `\\Alpha`|$ \\Beta $ | `\\Beta`|$ \\Gamma $ | `\\Gamma`|$ \\Delta $ | `\\Delta`|\n|-|-|-|-|-|-|-|-|\n|$ \\Epsilon $ | `\\Epsilon`|$ \\Zeta $ | `\\Zeta`|$ \\Eta $ | `\\Eta`|$ \\Theta $ | `\\Theta`|\n|$ \\Iota $ | `\\Iota`|$ \\Kappa $ | `\\Kappa`|$ \\Lambda $ | `\\Lambda`|$ \\Mu $ | `\\Mu`|\n|$ \\Nu $ | `\\Nu`|$ \\Xi $ | `\\Xi`|$ \\Omicron $ | `\\Omicron`|$ \\Pi $ | `\\Pi`|\n|$ \\Rho $ | `\\Rho`|$ \\Sigma $ | `\\Sigma`|$ \\Tau $ | `\\Tau`|$ \\Upsilon $ | `\\Upsilon`|\n|$ \\Phi $ | `\\Phi`|$ \\Chi $ | `\\Chi`|$ \\Psi $ | `\\Psi`|$ \\Omega $ | `\\Omega`|\n|$ \\varGamma $ | `\\varGamma`|$ \\varDelta $ | `\\varDelta`|$ \\varTheta $ | `\\varTheta`|$ \\varLambda $ | `\\varLambda`|\n|$ \\varXi $ | `\\varXi`|$ \\varPi $ | `\\varPi`|$ \\varSigma $ | `\\varSigma`|$ \\varUpsilon $ | `\\varUpsilon`|\n|$ \\varPhi $ | `\\varPhi`|$ \\varPsi $ | `\\varPsi`|$ \\varOmega $ | `\\varOmega`||\n|$ \\alpha $ | `\\alpha`|$ \\beta $ | `\\beta`|$ \\gamma $ | `\\gamma`|$ \\delta $ | `\\delta`|\n|$ \\epsilon $ | `\\epsilon`|$ \\zeta $ | `\\zeta`|$ \\eta $ | `\\eta`|$ \\theta $ | `\\theta`|\n|$ \\iota $ | `\\iota`|$ \\kappa $ | `\\kappa`|$ \\lambda $ | `\\lambda`|$ \\mu $ | `\\mu`|\n|$ \\nu $ | `\\nu`|$ \\xi $ | `\\xi`|$ \\omicron $ | `\\omicron`|$ \\pi $ | `\\pi`|\n|$ \\rho $ | `\\rho`|$ \\sigma $ | `\\sigma`|$ \\tau $ | `\\tau`|$ \\upsilon $ | `\\upsilon`|\n|$ \\phi $ | `\\phi`|$ \\chi $ | `\\chi`|$ \\psi $ | `\\psi`|$ \\omega $ | `\\omega`|\n|$ \\varepsilon $ | `\\varepsilon`|$ \\varkappa $ | `\\varkappa`|$ \\vartheta $ | `\\vartheta`|$ \\thetasym $ | `\\thetasym`|\n|$ \\varpi $ | `\\varpi`|$ \\varrho $ | `\\varrho`|$ \\varsigma $ | `\\varsigma`|$ \\varphi $ | `\\varphi`|\n|$ \\digamma $ | `\\digamma`||||\n"},"/algorithms/algorithms#":{"id":"/algorithms/algorithms#","title":"/algorithms/algorithms#","tags":"[\"wip\"]#","body":""},"/algorithms/algorithms#Introduction":{"id":"/algorithms/algorithms#Introduction","title":"/algorithms/algorithms#Introduction","tags":"[\"wip\"]#Introduction","body":""},"/algorithms/algorithms#Techniques":{"id":"/algorithms/algorithms#Techniques","title":"/algorithms/algorithms#Techniques","tags":"[\"wip\"]#Techniques","body":""},"/algorithms/algorithms#Dynamic-programming":{"id":"/algorithms/algorithms#Dynamic-programming","title":"/algorithms/algorithms#Dynamic-programming","tags":"[\"wip\"]#Dynamic-programming","body":"We have to come up with smaller subproblems, and each of these smaller subproblems can be easily solved. The solution to the original problem can easily be deduced when we know the solution to each of the subproblems.\nWe want that three conditions hold, namely\n1. There should be a polynomial number of subproblems.\n2. The solutions should yield a solution to the original problem.\n3. We should be able to build up solutions using a recurrence.\n"},"/algorithms/algorithms#Memoization":{"id":"/algorithms/algorithms#Memoization","title":"/algorithms/algorithms#Memoization","tags":"[\"wip\"]#Memoization","body":""},"/algorithms/algorithms#Divide-and-conquer":{"id":"/algorithms/algorithms#Divide-and-conquer","title":"/algorithms/algorithms#Divide-and-conquer","tags":"[\"wip\"]#Divide-and-conquer","body":""},"/algorithms/algorithms#Metrics":{"id":"/algorithms/algorithms#Metrics","title":"/algorithms/algorithms#Metrics","tags":"[\"wip\"]#Metrics","body":"Worst-case running time is the largest possible running time an algorithm may have. In some cases it may not be a good measure for efficiency, e.g. if the algorithm runs well on 99.9 % of the input but very badly on 0.1 % of the input. We could make use of average-case running time instead in some cases but it depends. The goal when studying algorithms is thus to find the bound of the worst-case or average-case (or some other metric) running times to evaluate how performant the algorithm is.\nBrute-force solution is a solution where we try every single possibility to see if it works.\n"},"/algorithms/algorithms#Definition-of-efficiency":{"id":"/algorithms/algorithms#Definition-of-efficiency","title":"/algorithms/algorithms#Definition-of-efficiency","tags":"[\"wip\"]#Definition-of-efficiency","body":"If an algorithm at an analytical level achieves much better worst-case performance than a brute-force solution we say that the algorithm is efficient (or more efficient at least).\n"},"/algorithms/algorithms#Polynomial-running-time":{"id":"/algorithms/algorithms#Polynomial-running-time","title":"/algorithms/algorithms#Polynomial-running-time","tags":"[\"wip\"]#Polynomial-running-time","body":"A polynomial running time algorithm has a scaling property which means that if the input size increases from $ N $ to $ 2N $ the bound of the algorithm increases from $ cN^d $ to $ c(2N)^d = c \\cdot 2^dN^d $. The slowdown is therefore a factor of $ 2^d $; this is a constant however, but indicate that we have better scaling behavior with smaller polynomials. Problems with polynomial-time bounds tend to be efficient while the opposite is true if there is no known polynomial-time bound for an algorithm. Problems with polynomial-time bounds tend to be efficient while the opposite is true if there is no known polynomial-time bound for an algorithm.\n"},"/algorithms/algorithms#Asymptotic-order-of-growth":{"id":"/algorithms/algorithms#Asymptotic-order-of-growth","title":"/algorithms/algorithms#Asymptotic-order-of-growth","tags":"[\"wip\"]#Asymptotic-order-of-growth","body":"Somewhat unclear..\n"},"/algorithms/algorithms#Asymptotic-upper-bound":{"id":"/algorithms/algorithms#Asymptotic-upper-bound","title":"/algorithms/algorithms#Asymptotic-upper-bound","tags":"[\"wip\"]#Asymptotic-upper-bound","body":"Let $ T(n) $ be the worst-case running time of an algorithm of size $ n $. $ T(n) $ is bounded by another function $ f(n) $, $ T(n) is O(f(n)) $, there there exists some constant $ c > 0, n_0 \\geq 0 $ so that for all $ n \\geq n_0 $ we have $ T(n) \\leq c \\cdot f(n) $. It could also be written like $ T(n) = O(f(n)) $, but we should be careful with this because there is no equality (the relation is not reflexive). The function $ T $ is **asymptotically upper-bounded** by $ f $. Generally we want to find the **lowest** upper bound to a function, e.g. every bound above a valid bound is also valid as upper bounds. It is correct to say that $ T(n) = pn^2 + qn + r $ is $ O(n^3) $ since $ (p + q + r)n^2 \\leq cn^3 $ for some constant $ c > 0 $.\n"},"/algorithms/algorithms#Asymptotic-lower-bound":{"id":"/algorithms/algorithms#Asymptotic-lower-bound","title":"/algorithms/algorithms#Asymptotic-lower-bound","tags":"[\"wip\"]#Asymptotic-lower-bound","body":"If we have proven that the worst-case running time of $ T(n) $ is $ O(f(n)) $ we want to show that this is the best possible bound, the tightest bound. We then say that $ T(n) $ is $ \\Omega(f(n)) $ if there exists some constants $ \\epsilon > 0 $ and $ n_0 \\geq 0 $ so that for all $ n \\geq n_0 $ we have $ T(n) \\geq \\epsilon \\cdot f(n) $. It is correct to say that $ T(n) = pn^2 + qn + r $ is $ \\Omega(n) $ since $ pn^2 \\geq pn $.\n"},"/algorithms/algorithms#Asymptotic-tight-bound":{"id":"/algorithms/algorithms#Asymptotic-tight-bound","title":"/algorithms/algorithms#Asymptotic-tight-bound","tags":"[\"wip\"]#Asymptotic-tight-bound","body":"If we can show that the running time $ T(n) $ of an algorithm has the asymptotic upper bound $ O(f(n)) $ and the asymptotic lower bound $ \\Omega (f(n)) $, we know that $ T $ behave just like $ f $ in terms of growth within a constant factor, denoted $ \\varTheta(f(n)) $. If $ T(n) = pn^2 + qn + r $ we know $ O(n^2) $ and $ \\Omega(n^2) $.\nWe may obtain an asymptotically tight bound of two functions $ f(n) $ and $ g(n) $ if the ratio between these functions converges to a positive constant when $ n \\to \\infty $. Thus\n$$\n\\underset{n \\to \\infty}{\\lim} \\frac{f(n)}{g(n)} = c > 0\n$$\n"},"/algorithms/algorithms#Properties":{"id":"/algorithms/algorithms#Properties","title":"/algorithms/algorithms#Properties","tags":"[\"wip\"]#Properties","body":""},"/algorithms/algorithms#Transitivity":{"id":"/algorithms/algorithms#Transitivity","title":"/algorithms/algorithms#Transitivity","tags":"[\"wip\"]#Transitivity","body":"1. If $ f = O(g) $ and $ g = O(h) $ then $ f = O(h) $.\n- If $ f = \\Omega(g) $ and $ g = \\Omega(h) $ then $ f = \\Omega(h) $.\n"},"/algorithms/algorithms#Sum":{"id":"/algorithms/algorithms#Sum","title":"/algorithms/algorithms#Sum","tags":"[\"wip\"]#Sum","body":"If $ f = O(h) $ and $ g = O(h) $ then $ f + g = O(h) $.\n"},"/algorithms/algorithms#Types-of-algorithms":{"id":"/algorithms/algorithms#Types-of-algorithms","title":"/algorithms/algorithms#Types-of-algorithms","tags":"[\"wip\"]#Types-of-algorithms","body":"1. Greedy\n    - greedy algorithm stays ahead\n    - exchange argument\n2. Dynamic programming\n    - Defining the objective value\n    - Computing the objective value\n"},"/algorithms/algorithms#Algorithm-development-strategies":{"id":"/algorithms/algorithms#Algorithm-development-strategies","title":"/algorithms/algorithms#Algorithm-development-strategies","tags":"[\"wip\"]#Algorithm-development-strategies","body":"1. **Brute force**. Some straightforward approach that tests all the possibilities.\n- **Smaller instances**. If we are able to solve smaller instances of the problem, can we use these to solve the overall problem?\n- **Greedy approaches**. Try different greedy approaches and find counter examples. Find valuable hints in the counter examples.\n"},"/algorithms/algorithms#Recurrence":{"id":"/algorithms/algorithms#Recurrence","title":"/algorithms/algorithms#Recurrence","tags":"[\"wip\"]#Recurrence","body":"If $ T(n) $ denotes the running time of an algorithm designed in a divide-and-conquer style, then $ T(n) $ will follow the recurrence relation\n$$\nT(n) \\leq q T(n/2) + cn, \\quad n > 2, T(2) \\leq c\n$$\nwhere $ q $ is the recursive calls used.\n"},"/algorithms/algorithms#Different-cases":{"id":"/algorithms/algorithms#Different-cases","title":"/algorithms/algorithms#Different-cases","tags":"[\"wip\"]#Different-cases","body":"We have different cases when $ q = 1, q = 2 $ and $ q > 2 $.\nWhen we have $ q > 2  $, then any function $ T(\\cdot) $ that satisfies the above equation is bounded by\n$$\nO(n^{\\log_2 q})\n$$\nWhen we have $ q = 1  $, then any function $ T(\\cdot) $ that satisfies the above equation is bounded by\n$$\nO(n)\n$$\nWhen we have $ q = 2  $, then any function $ T(\\cdot) $ that satisfies the above equation is bounded by\n$$\nO(n \\log n)\n$$\n"},"/algorithms/algorithms#NP":{"id":"/algorithms/algorithms#NP","title":"/algorithms/algorithms#NP","tags":"[\"wip\"]#NP","body":"NP (Nondeterministic polynomial) is a class of problems which we can denote as $ \\mathcal{NP} $.\nNP is the class of all decision problems that easily can be verified in polynomial time given some advice in addition to the input. This advice is usually a solution. The verification does not solve the problem in polynomial time, just checks that in fact it is a valid solution to the problem.\n We denote the class of all polynomial algorithms as $ \\mathcal{P} $. We notice that $ \\mathcal{P} \\sube \\mathcal{NP} $. One question we might ask ourselves is whether there exists a problem in $ \\mathcal{NP} $ that does not belong to $ \\mathcal{P} $. Does $ \\mathcal{P} = \\mathcal{NP} $?\nThere is a general belief that this is not the case and regarded as a working hypothesis in the field. This question is regarded as one of the most famous problems in computer science.\nThere is a contrast between finding a solution and checking if a solution is correct.\n"},"/algorithms/algorithms#NP-complete":{"id":"/algorithms/algorithms#NP-complete","title":"/algorithms/algorithms#NP-complete","tags":"[\"wip\"]#NP-complete","body":""},"/algorithms/cheat-sheet#":{"id":"/algorithms/cheat-sheet#","title":"/algorithms/cheat-sheet#","tags":"[]#","body":""},"/algorithms/cheat-sheet#Anagram":{"id":"/algorithms/cheat-sheet#Anagram","title":"/algorithms/cheat-sheet#Anagram","tags":"[]#Anagram","body":"- `Time: -`\n- `Space: -`\n```python\ndef anagrams(S):\n    d = {}\n    for word in S:\n        s = ’’.join(sorted(word))\n        if s in d:\n            d[s].append(word)\n        else:\n            d[s] = [word]\n    return [d[s] for s in d if len(d[s]) > 1]\n```\n"},"/algorithms/cheat-sheet#Convex-hull":{"id":"/algorithms/cheat-sheet#Convex-hull","title":"/algorithms/cheat-sheet#Convex-hull","tags":"[]#Convex-hull","body":"This algorithm is based on an algorithm by Ronald Graham, but this algorithm process points in order of their x-coordinate, not their angle around some fixed point.\n- `Time: O(n log n)`\n- `Space: -`\n```python\ndef left_turn(a, b, c):\n    return ((a[0] - c[0]) * (b[1] - c[1]) -\n            (a[1] - c[1]) * (b[0] - c[0]) > 0)\n# S: A set of points { (x, y) in R^2 }\ndef convex_hull(S):\n    S.sort()\n    top = []\n    bot = []\n    for p in S:\n        while len(top) >= 2 and not left_turn(p, top[-1], top[-2]):\n            top.pop()\n        top.append(p)\n        while len(bot) >= 2 and not left_turn(bot[-2], bot[-1], p):\n            bot.pop()\n        bot.append(p)\n    return bot[:-1] + top[:0:-1]\n```\n"},"/algorithms/cheat-sheet#GCD":{"id":"/algorithms/cheat-sheet#GCD","title":"/algorithms/cheat-sheet#GCD","tags":"[]#GCD","body":"- `Time: O(log a + log b)`\n- `Space: -`\n```python\ndef gcd(a, b):\n    return a if b == 0 else gcd(b, a % b)\n```\n"},"/algorithms/cheat-sheet#Maximum-value":{"id":"/algorithms/cheat-sheet#Maximum-value","title":"/algorithms/cheat-sheet#Maximum-value","tags":"[]#Maximum-value","body":"- `Time: O(n)`\n- `Space: -`\n```python\ndef max_value(arr):\n    m = arr[0]\n    for i in range(1, len(arr)):\n        m = max(m, arr[i])\n    return m\n```\n"},"/algorithms/cheat-sheet#Merging-two-sorted-lists":{"id":"/algorithms/cheat-sheet#Merging-two-sorted-lists","title":"/algorithms/cheat-sheet#Merging-two-sorted-lists","tags":"[]#Merging-two-sorted-lists","body":"- `Time: O(n)`\n- `Space: -`\n```python\n# ascending order\ndef merge_sorted_list(arr1, arr2):\n    ret = []\n    p1, p2 = 0, 0 # pointer to each list\n    while p1 < len(arr1) and p2 < len(arr2):\n        if arr1[p1] < arr2[p2]:\n            ret.append(arr1[p1])\n            p1 += 1\n        else:\n            ret.append(arr2[p2])\n            p2 += 1\n    # we have remainder elements left\n    # in some of the lists add them to\n    # the return list\n    while p1 < len(arr1):\n        ret.append(arr1[p1])\n        p1 += 1\n    while p2 < len(arr2):\n        ret.append(arr2[p2])\n        p2 += 1\n    return ret\n```\n"},"/algorithms/cheat-sheet#Closest-pair-or-points-(brute-force)":{"id":"/algorithms/cheat-sheet#Closest-pair-or-points-(brute-force)","title":"/algorithms/cheat-sheet#Closest-pair-or-points-(brute-force)","tags":"[]#Closest-pair-or-points-(brute-force)","body":"- `Time: O(n^2)`\n- `Space: -`\n```python\ndef closest_point(points):\n    min_distance = MAX_VALUE\n    for i in range(len(points)):\n        for j in range(len(points)):\n            if i == j: continue\n            [x1, y1] = points[i]\n            [x2, y2] = points[j]\n            distance = (x1 - x2)**2 + (y1 - y2)**2)**0.5\n            min_distance = min(min_distance, distance)\n    return distance\n```\n"},"/algorithms/cheat-sheet#Gale-Shapley-algorithm":{"id":"/algorithms/cheat-sheet#Gale-Shapley-algorithm","title":"/algorithms/cheat-sheet#Gale-Shapley-algorithm","tags":"[]#Gale-Shapley-algorithm","body":""},"/algorithms/keywords#":{"id":"/algorithms/keywords#","title":"/algorithms/keywords#","tags":"[]#","body":"1. subproblems\n- recurrences\n- pseudo-polynomial\n- computational intractability\n- NP class\n- NP-complete\n- boolean notation\n- 3-SAT\n- satisfying assignment\n- satisﬁable clauses\n- strongly connected\n- mutually reachable\n- directed acyclic graph (DAG)\n"},"/algorithms/keywords#SAT":{"id":"/algorithms/keywords#SAT","title":"/algorithms/keywords#SAT","tags":"[]#SAT","body":"Given a set of clauses $ C_1, \\dots, C_k $ over a set of variables $ X = \\{x_1, \\dots, x_n\\} $ does there exist a satisfying truth assignment?\n"},"/algorithms/keywords#3-SAT":{"id":"/algorithms/keywords#3-SAT","title":"/algorithms/keywords#3-SAT","tags":"[]#3-SAT","body":"Given a set of clauses $ C_1, \\dots, C_k $ each of length 3, over a set of variables\n$ X = \\{x_1, \\dots, x_n\\} $, does there exist a satisfying truth assignment?\n"},"/algorithms/problem-list#":{"id":"/algorithms/problem-list#","title":"/algorithms/problem-list#","tags":"[]#","body":"1. stable Matching problem\n- knapsack\n- subset sum\n- segmentation\n- sequence comparison\n- IMPL: sequence alignment\n- segmented least squares\n- median finding (randomized divide-and-conquer)\n- counting inversions\n- finding the closest pair of points\n- integer multiplication\n- vertex cover\n- independent set\n- packing problem\n- covering problem\n- satisﬁability problem\n- circuit satisﬁability problem\n- traveling salesman\n- hamiltonian cycle\n- hamiltonian path\n- partitioning problem\n- 3-dimensional-matching\n- graph coloring\n- bipartite matching\n- s-t connectivity\n"},"/art/painters#":{"id":"/art/painters#","title":"/art/painters#","tags":"[]#","body":""},"/art/painters#Rembrandt":{"id":"/art/painters#Rembrandt","title":"/art/painters#Rembrandt","tags":"[]#Rembrandt","body":"A [collection](https://en.wikipedia.org/wiki/List_of_paintings_by_Rembrandt) of the paintings of Rembrandt.\n"},"/databases/databases#":{"id":"/databases/databases#","title":"/databases/databases#","tags":"[\"wip\"]#","body":""},"/databases/databases#Database-management-system-(DBMS)":{"id":"/databases/databases#Database-management-system-(DBMS)","title":"/databases/databases#Database-management-system-(DBMS)","tags":"[\"wip\"]#Database-management-system-(DBMS)","body":"A database is a framework that is structured (the data is stored in efficient data structures), persistent (the data is not lost without deliberate action) and mutable (data can be added, deleted and modified). Often a specialized software is used called database management system that efficiently handles these three requirements at scale. The are many different DBMSs: Oracle, MS SQL Server, PostgreSQL, MySQL. and many more.\n"},"/databases/databases#PostgreSQL":{"id":"/databases/databases#PostgreSQL","title":"/databases/databases#PostgreSQL","tags":"[\"wip\"]#PostgreSQL","body":""},"/databases/databases#Types":{"id":"/databases/databases#Types","title":"/databases/databases#Types","tags":"[\"wip\"]#Types","body":""},"/databases/databases#Relational-databases":{"id":"/databases/databases#Relational-databases","title":"/databases/databases#Relational-databases","tags":"[\"wip\"]#Relational-databases","body":""},"/databases/databases#Semi-structured-databases":{"id":"/databases/databases#Semi-structured-databases","title":"/databases/databases#Semi-structured-databases","tags":"[\"wip\"]#Semi-structured-databases","body":""},"/databases/databases#JSON":{"id":"/databases/databases#JSON","title":"/databases/databases#JSON","tags":"[\"wip\"]#JSON","body":""},"/databases/databases#JSON-schemas":{"id":"/databases/databases#JSON-schemas","title":"/databases/databases#JSON-schemas","tags":"[\"wip\"]#JSON-schemas","body":"A JSON schema is either be a root schema or subschema, and it is defined as at JSON object itself. A specification of the core JSON schema can be found here @{core}. Because JSON is an non-structured model, schemas are a goof way of regaining some structure. Schemas tell us what to expect out of the document, optional and required parts, general structure and so on. They allow us to validate our data against our schemas as well to make sure that the data is consistent with our model. The schema consists of several different types of keywords that each maps to some value that determine if the a JSON object is valid given the schema.\n`title` and `description` are used to identify the schema.\n```json\n{\n    \"title\": \"Title\",\n    \"description\": \"This is a description.\"\n}\n```\n| Valid | Invalid |\n| - | - |\n| Everything | Nothing |\n`type` is used to define what type that is valid. Allowed types are: **array**, **boolean**, **integer**, **null**, **number**, **object** and **string**.\n```json\n{\n    \"type\": \"number\",\n}\n```\n| Valid | Invalid |\n| - | - |\n| 1 | true |\n| 3.14 | \"test\" |\n| 3.14e+10 | [1,2,3] |\n`enum` specifies a set of valid values.\n```json\n{\n    \"type\": \"string\",\n    \"enum\": [\"A\", \"B\", \"C\"]\n}\n```\n| Valid | Invalid |\n| - | - |\n| \"A\" | 3 |\n| \"B\" | \"D\" |\n`minimum` and `maximum` specifies a range of valid values.\n```json\n{\n    \"type\": \"integer\",\n    \"minimum\": 1,\n    \"maximum\": 10\n}\n```\n| Valid | Invalid |\n| - | - |\n| 1 | 0 |\n| 7 | 11 |\n`minLength` and `maxLength` specifies how short or long a string might be.\n```json\n{\n    \"type\": \"string\",\n    \"minLength\": 2,\n    \"maxLength\": 3\n}\n```\n| Valid | Invalid |\n| - | - |\n| \"asd\" | \"z\" |\n| \"qw\" | \"asdf\" |\n`properties` is used to define properties for objects. Properties allow us to have recursive types.\n```json\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": { \"type\": \"string\" },\n        \"age\": { \"type\": \"integer\" }\n    }\n}\n```\n| Valid | Invalid |\n| - | - |\n| {\"name\": \"Test\", \"other\": 3 } | {  \"name\": 123, \"other\": 3 } |\n| {\"name\" : \"Qwerty\", \"age\": 123 } | 123 |\n| {} | { \"age\": \"123\" } |\n`additionalProperties` is a boolean that specifies whether an object may contain properties that is not included in the schema.\n```json\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"age\": { \"type\": \"integer\" }\n    },\n    \"additionalProperties\": false\n}\n```\n| Valid | Invalid |\n| - | - |\n| { \"age\": 123 } | { \"name\": false } |\n| {} | { \"name\" : \"Qwerty\", \"age\": 123 } |\n|  | { \"age\": \"123\" } |\n`required` specifies what properties an object must have.\n```json\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"age\": { \"type\": \"integer\" }\n    },\n    \"required\": [\"name\", \"age\"]\n}\n```\n| Valid | Invalid |\n| - | - |\n| { \"name\": false, \"age\": 123 } | { \"name\": \"Test\" } |\n|  { \"name\" : \"Qwerty\", \"age\": 123 } | \"asd\" |\n| { \"name\" : \"Qwerty\", \"age\": 123, \"other\": true } | {} |\n`minProperties` and `maxProperties` specifies the minimum and maximum number of properties an object must have.\n```json\n{\n    \"type\": \"object\",\n    \"minProperties\": 1,\n    \"maxProperties\": 2\n}\n```\n| Valid | Invalid |\n| - | - |\n| { \"name\": false, \"age\": 123 } | { \"name\": \"Test\", \"age\": false, \"other\": 123 } |\n|  { \"name\" : \"Qwerty\", \"age\": 123 } | \"asd\" |\n| { \"name\" : \"Qwerty\" } | {} |\n`items` specifies the properties of array elements.\n```json\n{\n    \"type\": \"array\",\n    \"items\": { \"type\": \"integer\" }\n}\n```\n| Valid | Invalid |\n| - | - |\n| [1,2,3] | [\"asd\"] |\n| [1,2,3,4,5] | [\"asd\",false,0,1,2] |\n`uniqueItems` specifies that items must be unique.\n```json\n{\n    \"type\": \"array\",\n    \"items\": { \"type\": \"integer\" },\n    \"uniqueItems\": true\n}\n```\n| Valid | Invalid |\n| - | - |\n| [1,2,3] | [\"asd\"] |\n| [1,2,3,4,5] | [1,1,2,3,4] |\n| [] | 123 |\n`minItems` and `maxItems` specifies the minimum and maximum number of items an array must have.\n```json\n{\n    \"type\": \"array\",\n    \"minItems\": 1,\n    \"maxItems\": 2\n}\n```\n| Valid | Invalid |\n| - | - |\n| [1,false] | [1,2,3] |\n| [\"test\"] | [] |\n`contains` specifies the an array must contain a specific item.\n```json\n{\n    \"type\": \"array\",\n    \"contains\": {\"const\": 42},\n}\n```\n| Valid | Invalid |\n| - | - |\n| [1,false,42] | [1,2,3] |\n| [\"test\",42] | [] |\n| [\"test\",1,2,false,42] | [[42]] |\n`allOf`, `anyOf`, `oneOf`, and `not` are used to combine multiple schemas with logic.\n"},"/databases/databases#JSON-in-PostgreSQL":{"id":"/databases/databases#JSON-in-PostgreSQL","title":"/databases/databases#JSON-in-PostgreSQL","tags":"[\"wip\"]#JSON-in-PostgreSQL","body":""},"/databases/databases#NoSQL":{"id":"/databases/databases#NoSQL","title":"/databases/databases#NoSQL","tags":"[\"wip\"]#NoSQL","body":""},"/databases/databases#SQL-queries-?":{"id":"/databases/databases#SQL-queries-?","title":"/databases/databases#SQL-queries-?","tags":"[\"wip\"]#SQL-queries-?","body":""},"/databases/databases#Design-using-ER":{"id":"/databases/databases#Design-using-ER","title":"/databases/databases#Design-using-ER","tags":"[\"wip\"]#Design-using-ER","body":"The Entity-Relationship model is a high level design that expresses the aspects of the database as entities. It is very useful way of going from the domain to implementing the SQL. Going from the domain directly to SQL is often error prone, difficult and it can be hard to cooperate.\n"},"/databases/databases#Weak-entities":{"id":"/databases/databases#Weak-entities","title":"/databases/databases#Weak-entities","tags":"[\"wip\"]#Weak-entities","body":""},"/databases/databases#ISA-relationship":{"id":"/databases/databases#ISA-relationship","title":"/databases/databases#ISA-relationship","tags":"[\"wip\"]#ISA-relationship","body":""},"/databases/databases#Design-using-functional-dependencies":{"id":"/databases/databases#Design-using-functional-dependencies","title":"/databases/databases#Design-using-functional-dependencies","tags":"[\"wip\"]#Design-using-functional-dependencies","body":"Functional dependencies are another way of translating the domain to SQL schemas. Functional dependencies takes several formal statements about the domain description by which we can compute different normalized schemas with.\nA functional dependency between a set of attributes to an attribute is written like\n$$\n\\text{attribute(s)} \\to \\text{attribute}\n$$\nA concrete example could be\n$$\n\\text{time} \\,\\, \\text{room} \\to \\text{course}\n$$\nWhich would mean that if we know a time and a room, we can uniquely identify a course. That means it can be at most one course per each time and room pair.\n"},"/databases/databases#Closure":{"id":"/databases/databases#Closure","title":"/databases/databases#Closure","tags":"[\"wip\"]#Closure","body":""},"/databases/databases#Boyce-Codd-Normal-Form-(BCNF)":{"id":"/databases/databases#Boyce-Codd-Normal-Form-(BCNF)","title":"/databases/databases#Boyce-Codd-Normal-Form-(BCNF)","tags":"[\"wip\"]#Boyce-Codd-Normal-Form-(BCNF)","body":""},"/databases/databases#Multivalued-dependency-(MVD)":{"id":"/databases/databases#Multivalued-dependency-(MVD)","title":"/databases/databases#Multivalued-dependency-(MVD)","tags":"[\"wip\"]#Multivalued-dependency-(MVD)","body":""},"/databases/databases#1NF":{"id":"/databases/databases#1NF","title":"/databases/databases#1NF","tags":"[\"wip\"]#1NF","body":"The first normal form says that table cells should not contain tables or other complex structures.\n"},"/databases/databases#2NF":{"id":"/databases/databases#2NF","title":"/databases/databases#2NF","tags":"[\"wip\"]#2NF","body":""},"/databases/databases#3NF":{"id":"/databases/databases#3NF","title":"/databases/databases#3NF","tags":"[\"wip\"]#3NF","body":""},"/databases/databases#4NF":{"id":"/databases/databases#4NF","title":"/databases/databases#4NF","tags":"[\"wip\"]#4NF","body":""},"/databases/databases#Constraints":{"id":"/databases/databases#Constraints","title":"/databases/databases#Constraints","tags":"[\"wip\"]#Constraints","body":""},"/databases/databases#Triggers":{"id":"/databases/databases#Triggers","title":"/databases/databases#Triggers","tags":"[\"wip\"]#Triggers","body":""},"/databases/databases#Relational-algebra":{"id":"/databases/databases#Relational-algebra","title":"/databases/databases#Relational-algebra","tags":"[\"wip\"]#Relational-algebra","body":""},"/databases/databases#Transactions":{"id":"/databases/databases#Transactions","title":"/databases/databases#Transactions","tags":"[\"wip\"]#Transactions","body":""},"/databases/databases#References":{"id":"/databases/databases#References","title":"/databases/databases#References","tags":"[\"wip\"]#References","body":"{core}:\n    title: JSON Schema: A Media Type for Describing JSON Documents\n    url: https://json-schema.org/draft/2020-12/json-schema-core.html\n"},"/databases/sql#":{"id":"/databases/sql#","title":"/databases/sql#","tags":"[]#","body":"|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Greece|131940|Athens|11000000|EU|EUR|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n|Peru|1285220|Lima|29907003|SA|PEN|\n|Finland|337030|Helsinki|5244000|EU|EUR|\n"},"/databases/sql#CREATE":{"id":"/databases/sql#CREATE","title":"/databases/sql#CREATE","tags":"[]#CREATE","body":"```sql\nCREATE TABLE Countries (\n    name TEXT PRIMARY KEY,\n    capital TEXT NOT NULL,\n    area FLOAT,\n    population INT,\n    continent CHAR(2),\n    currency CHAR(3) NOT NULL\n);\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n"},"/databases/sql#DROP":{"id":"/databases/sql#DROP","title":"/databases/sql#DROP","tags":"[]#DROP","body":"```sql\nDROP TABLE Countries;\n```\n"},"/databases/sql#INSERT-INTO":{"id":"/databases/sql#INSERT-INTO","title":"/databases/sql#INSERT-INTO","tags":"[]#INSERT-INTO","body":"```sql\nINSERT INTO Countries VALUES ('Norway', 123456789, 'Oslo', 987654321, 'EU', 'EUR');\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Greece|131940|Athens|11000000|EU|EUR|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n|Peru|1285220|Lima|29907003|SA|PEN|\n|Finland|337030|Helsinki|5244000|EU|EUR|\n|Norway|123456789|Oslo|987654321|EU|EUR|\n"},"/databases/sql#DELETE-FROM":{"id":"/databases/sql#DELETE-FROM","title":"/databases/sql#DELETE-FROM","tags":"[]#DELETE-FROM","body":"```sql\nDELETE FROM Countries\nWHERE continent = ’EU’;\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Peru|1285220|Lima|29907003|SA|PEN|\n"},"/databases/sql#UPDATE":{"id":"/databases/sql#UPDATE","title":"/databases/sql#UPDATE","tags":"[]#UPDATE","body":"```sql\nUPDATE Countries\nSET population = population + 1\nWHERE name = 'Finland';\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Greece|131940|Athens|11000000|EU|EUR|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n|Peru|1285220|Lima|29907003|SA|PEN|\n|Finland|337030|Helsinki|5244001|EU|EUR|\n"},"/databases/sql#ALTER-TABLE":{"id":"/databases/sql#ALTER-TABLE","title":"/databases/sql#ALTER-TABLE","tags":"[]#ALTER-TABLE","body":""},"/databases/sql#ADD-COLUMN":{"id":"/databases/sql#ADD-COLUMN","title":"/databases/sql#ADD-COLUMN","tags":"[]#ADD-COLUMN","body":"```sql\nALTER TABLE Countries\nADD Test varchar(255);\n```\n|name|area|capital|population|continent|currency|test|\n|-|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS||\n|Greece|131940|Athens|11000000|EU|EUR||\n|Sweden|449964|Stockholm|9555893|EU|SEK||\n|Peru|1285220|Lima|29907003|SA|PEN||\n|Finland|337030|Helsinki|5244000|EU|EUR||\n"},"/databases/sql#DROP-COLUMN":{"id":"/databases/sql#DROP-COLUMN","title":"/databases/sql#DROP-COLUMN","tags":"[]#DROP-COLUMN","body":"```sql\nALTER TABLE Countries\nDROP COLUMN Currency;\n```\n|name|area|capital|population|continent|\n|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|\n|Greece|131940|Athens|11000000|EU|\n|Sweden|449964|Stockholm|9555893|EU|\n|Peru|1285220|Lima|29907003|SA|\n|Finland|337030|Helsinki|5244000|EU|\n"},"/databases/sql#SELECT":{"id":"/databases/sql#SELECT","title":"/databases/sql#SELECT","tags":"[]#SELECT","body":"Select specified columns\n```sql\nSELECT Area, Capital FROM Countries;\n```\n|area|capital|\n|-|-|\n|945087|Dodoma|\n|131940|Athens|\n|449964|Stockholm|\n|1285220|Lima|\n|337030|Helsinki|\nSelect all columns\n```sql\nSELECT * FROM Countries;\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Greece|131940|Athens|11000000|EU|EUR|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n|Peru|1285220|Lima|29907003|SA|PEN|\n|Finland|337030|Helsinki|5244000|EU|EUR|\nSelect with where clause\n```sql\nSELECT * FROM Countries WHERE continent = 'EU';\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Greece|131940|Athens|11000000|EU|EUR|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n|Finland|337030|Helsinki|5244000|EU|EUR|\n"},"/databases/sql#SELECT-DISTINCT":{"id":"/databases/sql#SELECT-DISTINCT","title":"/databases/sql#SELECT-DISTINCT","tags":"[]#SELECT-DISTINCT","body":"```sql\nSELECT DISTINCT currency FROM Countries;\n```\n|currency|\n|-|\n|SEK|\n|PEN|\n|EUR|\n|TZS|\n"},"/databases/sql#WHERE":{"id":"/databases/sql#WHERE","title":"/databases/sql#WHERE","tags":"[]#WHERE","body":""},"/databases/sql#Equality":{"id":"/databases/sql#Equality","title":"/databases/sql#Equality","tags":"[]#Equality","body":"```sql\nSELECT * FROM Countries WHERE name = \"Sweden\";\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n"},"/databases/sql#Inequality":{"id":"/databases/sql#Inequality","title":"/databases/sql#Inequality","tags":"[]#Inequality","body":"```sql\nSELECT * FROM Countries WHERE continent <> ’EU’;\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Tanzania|945087|Dodoma|41892895|AF|TZS|\n|Peru|1285220|Lima|29907003|SA|PEN|\n"},"/databases/sql#Expression":{"id":"/databases/sql#Expression","title":"/databases/sql#Expression","tags":"[]#Expression","body":"```sql\nSELECT * FROM Countries WHERE population/area >= 80;\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Greece|131940|Athens|11000000|EU|EUR|\n"},"/databases/sql#Multiple":{"id":"/databases/sql#Multiple","title":"/databases/sql#Multiple","tags":"[]#Multiple","body":"```sql\nSELECT * FROM Countries WHERE continent = 'EU' AND\n    NOT (currency = 'EUR');\n```\n|name|area|capital|population|continent|currency|\n|-|-|-|-|-|-|\n|Sweden|449964|Stockholm|9555893|EU|SEK|\n"},"/high-performance-computing/distributed-systems#":{"id":"/high-performance-computing/distributed-systems#","title":"/high-performance-computing/distributed-systems#","tags":"[]#","body":""},"/high-performance-computing/distributed-systems#Definition":{"id":"/high-performance-computing/distributed-systems#Definition","title":"/high-performance-computing/distributed-systems#Definition","tags":"[]#Definition","body":"A distributed system is a computing environment in which multiple different components are spread out across multiple computers (computing devices) on a network. Together they split up the work, coordinating  the job to be more effectively executed than if it was to be executed on a single machine.\n"},"/high-performance-computing/distributed-systems#Naming":{"id":"/high-performance-computing/distributed-systems#Naming","title":"/high-performance-computing/distributed-systems#Naming","tags":"[]#Naming","body":"Naming is used to uniquely identify a resource. This could be processes, remote objects etc. Names are mapped to an entity's location using name resolution. An example is an **url** that fetches the IP address, port and file path. An **identifier** is a name that uniquely identify an entity. A **true identifier** refers to at most one entity, each entity is referred to by at most one identifier and an identifier always refers to the same entity.\n"},"/high-performance-computing/distributed-systems#Name-resolution":{"id":"/high-performance-computing/distributed-systems#Name-resolution","title":"/high-performance-computing/distributed-systems#Name-resolution","tags":"[]#Name-resolution","body":"The process of looking up a name is called **name resolution**. There are multiple ways to go from name to entity/machine. Below are four different ways. At its core we have a closure mechanism that is the initial place to start looking for the entity.\n"},"/high-performance-computing/distributed-systems#Broadcasting":{"id":"/high-performance-computing/distributed-systems#Broadcasting","title":"/high-performance-computing/distributed-systems#Broadcasting","tags":"[]#Broadcasting","body":"When broadcasting we send a message to all entities and the entity that is associated with the identifier responds with its current address. This is used in the Address Resolution Protocol (ARP). However it is not scalable to large networks as it floods the network with broadcast messages.\n"},"/high-performance-computing/distributed-systems#Forwarding-pointers":{"id":"/high-performance-computing/distributed-systems#Forwarding-pointers","title":"/high-performance-computing/distributed-systems#Forwarding-pointers","tags":"[]#Forwarding-pointers","body":"Forwarding Pointers enables locating mobile entities. Mobile entities move from one access point to another. When an entity moves from location $ A $ to location $ B $, it leaves behind a reference (in $ A $) to its new location $ B $. The resolve the address we follow up the chain of pointers to reach the entity and we update the entity's reference once the present location is found. Drawbacks to this is of course that long chains lead to long resolution delays and are prone to failure. Every item in the chain must work, if one fails every item after the failing item fails.\n"},"/high-performance-computing/distributed-systems#Home-based-naming":{"id":"/high-performance-computing/distributed-systems#Home-based-naming","title":"/high-performance-computing/distributed-systems#Home-based-naming","tags":"[]#Home-based-naming","body":"Each entity is assigned a home node\n* Home node is typically static (has fixed access point and address)\n* Home node keeps track of current address of the entity\nEntity-home interaction:\n* Entity’s home address is registered at a naming service\n* Entity updates the home about its current address (foreign address) whenever it moves\nName resolution\n* Client contacts the home to obtain the foreign address\n* Client then contacts the entity at the foreign location\n"},"/high-performance-computing/distributed-systems#Distributed-Hash-Table-(DHT)":{"id":"/high-performance-computing/distributed-systems#Distributed-Hash-Table-(DHT)","title":"/high-performance-computing/distributed-systems#Distributed-Hash-Table-(DHT)","tags":"[]#Distributed-Hash-Table-(DHT)","body":"DHT is a class of decentralized distributed system that provides a lookup service similar to a hash table. We have a key-value pair stored in the nodes participating in the DHT and the responsibility to map keys to values are distributed across the nodes.\n"},"/high-performance-computing/distributed-systems#Flat-naming":{"id":"/high-performance-computing/distributed-systems#Flat-naming","title":"/high-performance-computing/distributed-systems#Flat-naming","tags":"[]#Flat-naming","body":"In flat naming identifiers are simply random bits of strings. Flat name does not contain any information on how to locate an entity.\n"},"/high-performance-computing/distributed-systems#Structured-naming":{"id":"/high-performance-computing/distributed-systems#Structured-naming","title":"/high-performance-computing/distributed-systems#Structured-naming","tags":"[]#Structured-naming","body":"Names are arranged in a specific order, e.g. file systems. Structured names are divided into **name spaces**, which is a directed graph consisting of **leaf nodes** and **directory nodes** where each leaf represents an entity and each directory nodes represents a collection of leaf and/or other directory nodes.\n"},"/high-performance-computing/distributed-systems#Name-spaces":{"id":"/high-performance-computing/distributed-systems#Name-spaces","title":"/high-performance-computing/distributed-systems#Name-spaces","tags":"[]#Name-spaces","body":"Name spaces could be divided into three different layers:\n1. **Global layer**. Consists of high-level directories that are managed by different administrations.\n2. **Administrational layer**. Consists of mid-level directories that are managed by an administration.\n3. **Managerial layer**. Consists of low-level directories within a single administration.\n"},"/high-performance-computing/distributed-systems#Attribute-based-naming":{"id":"/high-performance-computing/distributed-systems#Attribute-based-naming","title":"/high-performance-computing/distributed-systems#Attribute-based-naming","tags":"[]#Attribute-based-naming","body":"It could be convenient to look up entities based on their attributed than on their name, but this tends to be expensive by nature. However we could combine this with traditional structured naming to get better performance.\n"},"/high-performance-computing/distributed-systems#Architectures":{"id":"/high-performance-computing/distributed-systems#Architectures","title":"/high-performance-computing/distributed-systems#Architectures","tags":"[]#Architectures","body":"How to we organize our program? There are many different approaches:\n1. **System-oriented** (processes and threads $ \\implies $ inter-process communication)\n2. **Object-based** architectures (problem-oriented)\n3. **Resource-based** architectures\n4. **Event-based** architectures\nBasically we can make a distinction between software and hardware architectures, the latter concerning how a distributed system should be placed on different machines while the former concerns the logical organization of the system. This could be how entities interact with each other, how they are structured, how they can be made independent etc.\n"},"/high-performance-computing/distributed-systems#Placement":{"id":"/high-performance-computing/distributed-systems#Placement","title":"/high-performance-computing/distributed-systems#Placement","tags":"[]#Placement","body":"Placement is important for performance. If a data center is physically closer the performance will increase due to better delay, bandwidth etc. Placement maps entities to actual physical distributed infrastructures. It should be studied carefully depending on need of the application.\n"},"/high-performance-computing/distributed-systems#Communication-paradigm":{"id":"/high-performance-computing/distributed-systems#Communication-paradigm","title":"/high-performance-computing/distributed-systems#Communication-paradigm","tags":"[]#Communication-paradigm","body":"Communication paradigms are different ways of communicating between entities to provide the requested service.\n"},"/high-performance-computing/distributed-systems#Middleware":{"id":"/high-performance-computing/distributed-systems#Middleware","title":"/high-performance-computing/distributed-systems#Middleware","tags":"[]#Middleware","body":"A middleware is a service (library) that sits on the client and the server to make all implementation details easier by abstracting away different concepts.\n"},"/high-performance-computing/distributed-systems#Indirect-communication":{"id":"/high-performance-computing/distributed-systems#Indirect-communication","title":"/high-performance-computing/distributed-systems#Indirect-communication","tags":"[]#Indirect-communication","body":"Indirect communication uses middleware to provide a **one-to-many** communication and to reduce the **space coupling** (we know in advance where the procedure is) as well as the **time coupling** (a process should be explicitly waiting to accept requests for procedure calls on the receiver). Different types of indirect communication is: **group communication**, **publish-subscribe** and **message queues**.\n"},"/high-performance-computing/distributed-systems#Client-server-architecture":{"id":"/high-performance-computing/distributed-systems#Client-server-architecture","title":"/high-performance-computing/distributed-systems#Client-server-architecture","tags":"[]#Client-server-architecture","body":"An important class of organizations of distributed systems is how machines should be divided into clients and servers. A client is an entity that sends requests to a server and expects that the server will produce a result that is returned to the client. The functionality is split up into smaller modules, increasing modularity. Client-server architectures are often centralized. In cases we see a decentralized approach every entity acts both as a server and a client in different situations. There is an equal role between each entity. This is what constitute peer-to-peer systems.\n"},"/high-performance-computing/distributed-systems#Peer-to-peer-(P2P)":{"id":"/high-performance-computing/distributed-systems#Peer-to-peer-(P2P)","title":"/high-performance-computing/distributed-systems#Peer-to-peer-(P2P)","tags":"[]#Peer-to-peer-(P2P)","body":"In peer-to-peer systems the processes are organized into an overlay network which is a logical network where every entity has a list of all the other entities in the network that it may communicate with.\n"},"/high-performance-computing/distributed-systems#Tiered-architecture":{"id":"/high-performance-computing/distributed-systems#Tiered-architecture","title":"/high-performance-computing/distributed-systems#Tiered-architecture","tags":"[]#Tiered-architecture","body":"A tiered architecture is useful to organize the functionality of a service by placing it on different servers. A tiered architecture gives rise to a vertical splitting of services.\n"},"/high-performance-computing/distributed-systems#Layering":{"id":"/high-performance-computing/distributed-systems#Layering","title":"/high-performance-computing/distributed-systems#Layering","tags":"[]#Layering","body":"By partitioning a complex system into different layers we may reduce the overall complexity (hides complexity) of the system making it easier to implement and maintain. A layered approach gives rise to a horizontal splitting of services. Upper layers utilize services of lower layers. Distributed systems can be divided into three different layers: **platform** (provides a common service for the higher layers), **middleware** (provides common models that the application programmer may take advantage of by abstracting away e.g. communication mechanisms) and **applications**.\n"},"/high-performance-computing/distributed-systems#Micro-services":{"id":"/high-performance-computing/distributed-systems#Micro-services","title":"/high-performance-computing/distributed-systems#Micro-services","tags":"[]#Micro-services","body":""},"/high-performance-computing/distributed-systems#Docker":{"id":"/high-performance-computing/distributed-systems#Docker","title":"/high-performance-computing/distributed-systems#Docker","tags":"[]#Docker","body":"The benefits of using docker is the following\n1. Local development environments can be set up that are exact replicas of a live environment/server.\n2. It simplifies collaboration by allowing anyone to work on the same project with the same settings, irrespective of the local host environment.\n3. Multiple development environments can be run from the same host each one having different configurations, operating systems, and software.\n4. Projects can be tested on different servers.\n5. It gives you instant application portability. Build, ship, and run any application as a portable container that can run almost anywhere.\nSo it allows for **ease-of-use** (anyone can package their application on any device and be sure that will run unmodified anywhere else), **speed** (they run on the kernel in a sandboxed environment without simulating the whole operating system), **modularity** (it is easy to break up the application into smaller parts in individual containers) and **scalability** (it is easy to link these containers making it easy to scale and update components independently of each other).\n"},"/high-performance-computing/distributed-systems#Mutual-exclusion":{"id":"/high-performance-computing/distributed-systems#Mutual-exclusion","title":"/high-performance-computing/distributed-systems#Mutual-exclusion","tags":"[]#Mutual-exclusion","body":""},"/high-performance-computing/distributed-systems#Token-ring":{"id":"/high-performance-computing/distributed-systems#Token-ring","title":"/high-performance-computing/distributed-systems#Token-ring","tags":"[]#Token-ring","body":"In the token ring algorithm each resource is associated with a token. The token is circulated between the processes. The process with the token may access the resource. The ring is a logical representing of a \"circular linked list\". When a process has finished accessing a resource or doesn't want to access the resource it passes the token forward to the next process in the ring. The advantages of the algorithm is that is provides a deterministic way of mutual exclusion and it avoids starvation. However it has high message overhead if no process wants to access the resource (each process keeps sending the token to the next process), in the case the token is lost it must be regenerated but it could be difficult to detect if the token is lost and dead process must be deleted from the ring because if one fails the whole rings fails.\n"},"/high-performance-computing/distributed-systems#Election":{"id":"/high-performance-computing/distributed-systems#Election","title":"/high-performance-computing/distributed-systems#Election","tags":"[]#Election","body":"An election in a distributed system is used to elect a leader node. If there are multiple leaders or if the nodes disagree on who is the leader we have inconsistencies. If the leader crashes we have unavailability. The elected leader undertake specialized tasks. The motivation behind the proposal of a leader in a distributed system is that many distributed algorithms require a central coordinator. But it does not matter which node that is the coordinator. To begin an election process we must assume that some properties hold:\n1. After the election algorithm, it should be only one unique leader\n2. Every process may know the ID of the other processes, but may not know if one of the others has crashed\n3. Any process may initiate an election process\n4. Multiple processes may initiate an election process at the same time\nAfter the election one process with the best election attribute is elected as the leader. This could be the highest ID, the fastest CPU, least CPU load, most files, most disk space etc. Two examples of the election algorithm is: **bully algorithm** and **ring algorithm**.\n"},"/high-performance-computing/distributed-systems#Bully-algorithm":{"id":"/high-performance-computing/distributed-systems#Bully-algorithm","title":"/high-performance-computing/distributed-systems#Bully-algorithm","tags":"[]#Bully-algorithm","body":"https://en.wikipedia.org/wiki/Bully_algorithm\nThe algorithm is as follows\n1. A process $ P_i $ initiates the election process when it notices that the existing leader (coordinator) is not responding.\n2. $ P_i $ sends an election message to all other processes with higher process ID.\n3. When process $ P_j, j > i $ receives the message it responds with a take-over message. $ P_i $ is no longer in the election and awaits a victory message from another process.\n4. If no process responds, $ P_i $ wins the election and sends a victory message to every other process announcing itself as the winner.\n"},"/high-performance-computing/distributed-systems#Ring-algorithm":{"id":"/high-performance-computing/distributed-systems#Ring-algorithm","title":"/high-performance-computing/distributed-systems#Ring-algorithm","tags":"[]#Ring-algorithm","body":"https://en.wikipedia.org/wiki/Leader_election#Leader_election_in_rings\nThe algorithm is used in a ring topology and is as follows\n1. A process $ P_i $ initiates the election process when it notices that the existing leader (coordinator) is not responding.\n2. $ P_i $ sends an election message to the next process in the ring and inserts its ID in the message.\n3. When process $ P_j $ receives the message it appends its ID to the message and forwards it to the next process.\n    - If the next node has crashed, $ P_j $ finds the next process after the crashed process.\n4. When the message gets back to the process that initiated the election it elects the process with the highest ID and sends a victory message to the next node announcing the winner.\n"},"/high-performance-computing/distributed-systems#Clocks":{"id":"/high-performance-computing/distributed-systems#Clocks","title":"/high-performance-computing/distributed-systems#Clocks","tags":"[]#Clocks","body":"In an asynchronous distributed system there is no notion of global clock. Events cannot be ordered according to some real order.\nWe can only talk about causal event ordering, that is if one event affects the outcome of another event. Sending always precedes receiving the message. Event ordering is transitive, e.g. if $ a \\to b $ and $ b \\to c $, then $ a \\to c $.\n"},"/high-performance-computing/distributed-systems#Cristian's-algorithm":{"id":"/high-performance-computing/distributed-systems#Cristian's-algorithm","title":"/high-performance-computing/distributed-systems#Cristian's-algorithm","tags":"[]#Cristian's-algorithm","body":"https://en.wikipedia.org/wiki/Cristian%27s_algorithm\nCristian's algorithm is a method for clock synchronization. The algorithm in steps:\n1. $ P $ requests the time from $ S $ a; time $ t_0 $\n2. After receiving the request from $ P $, $ S $ prepares a response and appends the time $ T $ from its own clock\n3. $ P $ receives the response at time $ t_1 $ then sets its time to be $ T + \\frac{RTT}{2} $, where $ RTT = t_1 - t_0 $\n"},"/high-performance-computing/distributed-systems#Berkeley-algorithm":{"id":"/high-performance-computing/distributed-systems#Berkeley-algorithm","title":"/high-performance-computing/distributed-systems#Berkeley-algorithm","tags":"[]#Berkeley-algorithm","body":"https://en.wikipedia.org/wiki/Berkeley_algorithm\nBerkeley algorithm is a method for clock synchronization. The algorithm in steps:\n1. A leader is chosen via an election process\n2. The leader polls the clients who reply with their time in a similar way of Cristian's algorithm\n3. The leader observes the $ RTT $ of the messages and averages the clock times ignoring any value outside some threshold (to avoid extreme outliers)\n4. The leader sends the amount of time each client must adjust to be synchronized to avoid further uncertainty regarding $ RTT $.\n"},"/high-performance-computing/distributed-systems#Consistent-cut":{"id":"/high-performance-computing/distributed-systems#Consistent-cut","title":"/high-performance-computing/distributed-systems#Consistent-cut","tags":"[]#Consistent-cut","body":"A cut is consistent if for any event $ e $ included in the cut, any event $ e' $ that causally precedes $ e $ is also included in the cut.\nWe must know the causal ordering of events to detect an inconsistent cut. Given a global clock in place we check the timestamp of each event $ RC(e) $ and compute the clock condition $ a \\to b \\implies RC(a) < RC(b) $. If there is no global clock we use logical clocks and vector clocks.\n"},"/high-performance-computing/distributed-systems#Logical-clocks":{"id":"/high-performance-computing/distributed-systems#Logical-clocks","title":"/high-performance-computing/distributed-systems#Logical-clocks","tags":"[]#Logical-clocks","body":"Each process keeps a local value of a logical clock that counts how many events in a distributed computation casually precedes the current event at the current process.\n"},"/high-performance-computing/distributed-systems#Active-monitoring":{"id":"/high-performance-computing/distributed-systems#Active-monitoring","title":"/high-performance-computing/distributed-systems#Active-monitoring","tags":"[]#Active-monitoring","body":"Active monitoring or distributed snapshot is when a monitor $ p_0 $ requests a snapshot of all other processes $ p_i, i \\neq 0 $. These processes records its state and stops any ongoing distributed computation. It relays the snapshot message on all its outgoing channels, and starts to record all incoming messages after the first snapshot message. When the process has received snapshot messages from all other processes it stops the recording and sends the snapshot to $ p_0 $.\n"},"/high-performance-computing/distributed-systems#Passive-monitoring":{"id":"/high-performance-computing/distributed-systems#Passive-monitoring","title":"/high-performance-computing/distributed-systems#Passive-monitoring","tags":"[]#Passive-monitoring","body":"In passive monitoring we use processes' local histories to construct consistent global states (cuts).\n"},"/high-performance-computing/distributed-systems#MapReduce":{"id":"/high-performance-computing/distributed-systems#MapReduce","title":"/high-performance-computing/distributed-systems#MapReduce","tags":"[]#MapReduce","body":"https://en.wikipedia.org/wiki/MapReduce\nOne could be tempted to use\n```python\ncount_words(internet):\n    hash_map<string, int> word_count;\n    for each page in internet:\n        for each word in page:\n            word_count[word] += 1\n```\nto count all the words on the internet. However, there are around 20+ billion web pages. If we estimate each web page to be 20KB, that would result in 400+ billion KB just to save all the data. If one computer can read 30-40 MB/sec from disk it would take roughly four months to read the whole web. After reading we want to compute stuff as well with the data increasing the time further. This is where **MapReduce** comes in. It splits the extract phase and computation phase into two functions called `map` and `reduce`. These two algorithms is supposed to be run on thousands of machines. The two functions have the following general form\n```python\nmap(in_key, in_value) -> list(out_key, intermediate_value)\nreduce(out_key, list(intermediate_value)) -> list(out_value)\n```\nThe input to map is the data we are interested in running concurrently on multiple different machines. If we for example have as input a document we have the following map function\n```python\nmap(string input_key, string input_value):\n    # key: document URL\n    # value: document text\n    for each word in input_value:\n        output_intermediate(word, “1”);\n```\nThe intermediate output value is then passed to the reduce function that may be on another machine. The reduce function gets the the intermediate output value for a specific key and begin computations. If we want to calculate the word count in a document with the above `map` function we could have the following `reduce` function\n```python\nreduce(string key, list values):\n    # key: word, same for input and output\n    # values: list of counts\n    int sum = 0;\n    for each v in values:\n        sum += v;\n    output(sum);\n```\nSo the `reduce` function gets the partial value for a specific key and process that value in some way. E.g. one reducer handles the keyword *key1* while another handles *key2*. MapReduce is fault tolerance, that is, if one/many of the machines the whole program should not fail. We often have a master worker that delegate work to other workers. If the master worker fails, we restart the master worker on a different machine. The master keeps track of bad input and asks the workers to skip that input.\n"},"/high-performance-computing/distributed-systems#Consistency-and-replication":{"id":"/high-performance-computing/distributed-systems#Consistency-and-replication","title":"/high-performance-computing/distributed-systems#Consistency-and-replication","tags":"[]#Consistency-and-replication","body":"https://en.wikipedia.org/wiki/Replication_(computing)\nThere are primarily two reasons for replication data, improving performance and improving reliability. Replication is the process of maintaining the data at multiple different computers. However, replication introduces a consistency problem. Whenever a replica is updated it becomes different from every other replica. To keep replicas consistent updates need to be propagated to each replica in a way that temporary inconsistencies are not noticed. In large-scale distributed systems this can massively affect the performance of the system, which is why it is common to relax the constraint. There are multiple consistency models that have different pros and cons, and there is not a single model that works best in all different cases.\nConsistency protocols describe a specific implementation of a consistency model. Replication in computing involves sharing information to ensure consistency between redundant resources (software or hardware components) to improve reliability, performance (cache), scalability (can balance the load between the main server and replicated servers), fault-tolerance (if a minority of the servers are malicious, the non-malicious servers can outvote these servers providing security as well tolerance against faulty servers), or availability (accessibility, if one computer crashes then a replica of the data can still be accessed).\n"},"/high-performance-computing/distributed-systems#Strict-consistency":{"id":"/high-performance-computing/distributed-systems#Strict-consistency","title":"/high-performance-computing/distributed-systems#Strict-consistency","tags":"[]#Strict-consistency","body":"When using strict consistency the data is always fresh.\n1. After a write operation, the update is propagated to all other replicas.\n2. A read operation will result in reading the most recent write.\nIn a system with many writes, this approach will have very poor performance.\n"},"/high-performance-computing/distributed-systems#Loose-consistency":{"id":"/high-performance-computing/distributed-systems#Loose-consistency","title":"/high-performance-computing/distributed-systems#Loose-consistency","tags":"[]#Loose-consistency","body":"When using loose consistency the data might be stale.\n1. After a write operation, we seldom propagate the update to all other replicas.\n2. A read operation may result in reading a value that was written a long time ago.\n3. Replicas are generally out-of-sync.\nThe replicas may synchronize at a specific time, reducing overhead.\n"},"/high-performance-computing/distributed-systems#Data-centric-models":{"id":"/high-performance-computing/distributed-systems#Data-centric-models","title":"/high-performance-computing/distributed-systems#Data-centric-models","tags":"[]#Data-centric-models","body":"These models define how updates of the data are propagated across all replicas to keep them consistent.\n"},"/high-performance-computing/distributed-systems#Consistency-specification-models":{"id":"/high-performance-computing/distributed-systems#Consistency-specification-models","title":"/high-performance-computing/distributed-systems#Consistency-specification-models","tags":"[]#Consistency-specification-models","body":"Models that enable specifying the consistency levels that are tolerable for the application. There should be a mechanism to measure how inconsistent data might be on different replicas. A consistency specification model called continuous consistency model is used to measure inconsistencies and express what inconsistencies can be expected in the system. The level of inconsistency if defined over three different axis\n1. **Numerical deviation**. Deviation in numerical (how many units does a replica deviate from another) values.\n2. **Staleness deviation**. Deviation in the ordering (how many local updates were not propagated) of updates.\n3. **Ordering deviation**. Deviation in the staleness (time since last update) between replicas.\nTo measure consistency we may use a **global observer** and a suitable metric given the use case.\n"},"/high-performance-computing/distributed-systems#Models-for-consistent-ordering-of-operations":{"id":"/high-performance-computing/distributed-systems#Models-for-consistent-ordering-of-operations","title":"/high-performance-computing/distributed-systems#Models-for-consistent-ordering-of-operations","tags":"[]#Models-for-consistent-ordering-of-operations","body":"Models that enable specifying the order in which the data updates are propagated to different replicas.\n"},"/high-performance-computing/distributed-systems#Client-centric-models":{"id":"/high-performance-computing/distributed-systems#Client-centric-models","title":"/high-performance-computing/distributed-systems#Client-centric-models","tags":"[]#Client-centric-models","body":"Client-centric consistency models concentrate on the consistency of the individual client and not the fact that the data may be shared between multiple other clients. We assume here that a client may connect to different replicas during a fixed time interval but that the client should not notice that the replica has changed (transparency). When a client connects to a new replica, that replica is synchronized and updated with data that potentially had been modified by the client which possibly resided at another replica.\nWhen propagating updates different techniques are used depending on different scenarios, namely, **what** should be propagated, **where** should updates be propagated to, **whom** is responsible for the initiated propagation. We then propagate state, operations or notifications. Every replica does not need to be updated immediately and this all depends on the distribution protocol. A choice can be made to either push or pull updates to or from other replicas.\nFour types of client-centric consistency models are\n1. Monotonic reads\n2. Monotonic writes\n3. Read your writes\n4. Write follow reads\n"},"/high-performance-computing/distributed-systems#Monotonic-reads":{"id":"/high-performance-computing/distributed-systems#Monotonic-reads","title":"/high-performance-computing/distributed-systems#Monotonic-reads","tags":"[]#Monotonic-reads","body":"If a client reads the value of data item $ x $, then when the client does it again, it should result in the same or a more recent value of $ x $.\n"},"/high-performance-computing/distributed-systems#Monotonic-writes":{"id":"/high-performance-computing/distributed-systems#Monotonic-writes","title":"/high-performance-computing/distributed-systems#Monotonic-writes","tags":"[]#Monotonic-writes","body":"If a client writes to the data item $ x $, then any successive writes should be performed after the previous write operation has finished by the same process.\n"},"/high-performance-computing/distributed-systems#Read-your-writes":{"id":"/high-performance-computing/distributed-systems#Read-your-writes","title":"/high-performance-computing/distributed-systems#Read-your-writes","tags":"[]#Read-your-writes","body":"The effect of a write operation on data item $ x $ will always be sent by a successive read operation on $ x $ by the same process.\n"},"/high-performance-computing/distributed-systems#Write-follow-reads":{"id":"/high-performance-computing/distributed-systems#Write-follow-reads","title":"/high-performance-computing/distributed-systems#Write-follow-reads","tags":"[]#Write-follow-reads","body":"A write operation on data item $ x $ following a previous read operation on $ x $ by the same process should take place on the same or a more recent value of $ x $.\n"},"/high-performance-computing/distributed-systems#Types-of-ordering":{"id":"/high-performance-computing/distributed-systems#Types-of-ordering","title":"/high-performance-computing/distributed-systems#Types-of-ordering","tags":"[]#Types-of-ordering","body":"Below are three different types of ordering of messages based on different needs.\n"},"/high-performance-computing/distributed-systems#Total-ordering":{"id":"/high-performance-computing/distributed-systems#Total-ordering","title":"/high-performance-computing/distributed-systems#Total-ordering","tags":"[]#Total-ordering","body":"If a process $ P_i $ sends a message $ m_i $ and $ P_j $ send $ m_j $ and if one correct process delivers $ m_i $ before $ m_j $ then every correct process delivers $ m_i $ before $ m_j $.\n"},"/high-performance-computing/distributed-systems#Sequential-ordering":{"id":"/high-performance-computing/distributed-systems#Sequential-ordering","title":"/high-performance-computing/distributed-systems#Sequential-ordering","tags":"[]#Sequential-ordering","body":"If a process $ P_i $ sends a sequence of messages $ m_{(i, 1)}, \\dots, m_{(i, k)}$ and  $ P_j $ sends a sequence of messages $ m_{(j, 1)}, \\dots, m_{(j, k)}$, then messages should be received at the same sequential order at any process.\n"},"/high-performance-computing/distributed-systems#Casual-ordering":{"id":"/high-performance-computing/distributed-systems#Casual-ordering","title":"/high-performance-computing/distributed-systems#Casual-ordering","tags":"[]#Casual-ordering","body":"Causal ordering reflects that operations potentially dependent on other operations are executed in consideration to this dependency. If $ a $ and $ b $ are two events such that $ a $ happened before $ b $, denoted $ a \\to b $. $ C_i(a) $ and $ C_i(b) $ is the logical time event $ a $ and $ b $ is received at process $ P_i $. Then we can deduce that $ a \\to b $ by observing $ C_i(a) < C_i(b) $ that $ a $ and $ b $ is casually related. Vector clocks and logical clocks can implement causality. If process $ P_i $ sends message $ m_i $ and process $ P_j $ sends message $ m_j $, and $ m_i \\to m_j $, then any correct process that delivers $ m_j $ will deliver $ m_i $ before $ m_j $.\n"},"/high-performance-computing/distributed-systems#Sequential-consistency":{"id":"/high-performance-computing/distributed-systems#Sequential-consistency","title":"/high-performance-computing/distributed-systems#Sequential-consistency","tags":"[]#Sequential-consistency","body":"Sequential consistency models ensures that updates are executed in sequential order. We make a distinction between **primary-based** protocols and **replicated-write** protocols.\n"},"/high-performance-computing/distributed-systems#Primary-based-protocols":{"id":"/high-performance-computing/distributed-systems#Primary-based-protocols","title":"/high-performance-computing/distributed-systems#Primary-based-protocols","tags":"[]#Primary-based-protocols","body":"In primary-based protocols we forward all operations to a primary copy that ensures that the update is properly ordered and forwarded.\n"},"/high-performance-computing/distributed-systems#Replicated-write-protocols":{"id":"/high-performance-computing/distributed-systems#Replicated-write-protocols","title":"/high-performance-computing/distributed-systems#Replicated-write-protocols","tags":"[]#Replicated-write-protocols","body":"In replicated-write protocols we forward an update to several replicas at the same time which makes ordering more difficult.\n"},"/high-performance-computing/distributed-systems#Causal-consistency":{"id":"/high-performance-computing/distributed-systems#Causal-consistency","title":"/high-performance-computing/distributed-systems#Causal-consistency","tags":"[]#Causal-consistency","body":"In causal consistency, writes that are casually related must be seen by all processes in the same order. However, concurrent messages may be seen in different order on different machines.\n"},"/high-performance-computing/distributed-systems#Eventual-consistency":{"id":"/high-performance-computing/distributed-systems#Eventual-consistency","title":"/high-performance-computing/distributed-systems#Eventual-consistency","tags":"[]#Eventual-consistency","body":"Eventual consistency is a client centric consistency model. In eventual consistent data stores, data may be inconsistent between replicas at specific time instants, but will converge to the same ordering over time in the absence of updates. **Write-write** conflicts are unusual while **read-write** conflicts are more common.\n"},"/high-performance-computing/distributed-systems#Fault-tolerance":{"id":"/high-performance-computing/distributed-systems#Fault-tolerance","title":"/high-performance-computing/distributed-systems#Fault-tolerance","tags":"[]#Fault-tolerance","body":"https://en.wikipedia.org/wiki/Fault_tolerance\nFailures may occur at all times and can be due to, **hardware faults**, **software bugs**, **operator errors**, **network errors** and **power outage**. A fail is defined as when a system cannot meet its promises. In distributed system we may talk about partial failure, which happens when one component of the system fails that may or may not affect other components in the system. The goal of a fault-tolerant system is to enable the system to continue operating properly in case of failure. Thus, a system is said to be **fault-tolerant** if the system can provide its services even in the presence of **faults**. A robust fault tolerant system requires:\n1. No single point of failure.\n2. Fault isolation of the failing component.\n3. The ability to reverse the faulty instructions.\n"},"/high-performance-computing/distributed-systems#Availability":{"id":"/high-performance-computing/distributed-systems#Availability","title":"/high-performance-computing/distributed-systems#Availability","tags":"[]#Availability","body":"A system is said to be highly available if it most likely works at any given time instant.\n"},"/high-performance-computing/distributed-systems#Reliability":{"id":"/high-performance-computing/distributed-systems#Reliability","title":"/high-performance-computing/distributed-systems#Reliability","tags":"[]#Reliability","body":"A system is said to be highly reliable if it most likely continue to work without interruption during a relatively long period of time.\n"},"/high-performance-computing/distributed-systems#Safety":{"id":"/high-performance-computing/distributed-systems#Safety","title":"/high-performance-computing/distributed-systems#Safety","tags":"[]#Safety","body":"A system that temporarily fails to operate correctly should not result in catastrophic effects.\n"},"/high-performance-computing/distributed-systems#Maintainability":{"id":"/high-performance-computing/distributed-systems#Maintainability","title":"/high-performance-computing/distributed-systems#Maintainability","tags":"[]#Maintainability","body":"A system that is easy to maintain.\n"},"/high-performance-computing/distributed-systems#Fault-masking-with-redundancy":{"id":"/high-performance-computing/distributed-systems#Fault-masking-with-redundancy","title":"/high-performance-computing/distributed-systems#Fault-masking-with-redundancy","tags":"[]#Fault-masking-with-redundancy","body":"A common way to make sure that a system operates correctly in the case of failure is to insert some redundancy into the system. If we are dealing with sending information we may add some extra bits to allow us to recover lost bits, in software we may have extra processes to allow tolerating failed processes, in hardware we may use extra equipment to allow for failed hardware components and in the case of time events we may perform an action twice or more if it is required.\n"},"/high-performance-computing/distributed-systems#Process-resilience":{"id":"/high-performance-computing/distributed-systems#Process-resilience","title":"/high-performance-computing/distributed-systems#Process-resilience","tags":"[]#Process-resilience","body":"The key to tolerating a faulty process is to divide processes into groups based on similar behavior. If one of these processes fail, another in the same group may be able to take over. However, a process may be in multiple different groups at the same time and may come and go to different groups during runtime.\n"},"/high-performance-computing/distributed-systems#Flat-groups":{"id":"/high-performance-computing/distributed-systems#Flat-groups","title":"/high-performance-computing/distributed-systems#Flat-groups","tags":"[]#Flat-groups","body":"1. Could be quorum-based\n2. (+) Symmetrical\n3. (+) No single point of failure\n4. (—) Decision making could be complicated\n"},"/high-performance-computing/distributed-systems#Hierarchical-groups":{"id":"/high-performance-computing/distributed-systems#Hierarchical-groups","title":"/high-performance-computing/distributed-systems#Hierarchical-groups","tags":"[]#Hierarchical-groups","body":"1. Could be active replication\n2. (+) Decision making is easy\n3. (—) Asymmetrical\n4. (—) Single point of failure\n"},"/high-performance-computing/distributed-systems#K-fault-tolerant-system":{"id":"/high-performance-computing/distributed-systems#K-fault-tolerant-system","title":"/high-performance-computing/distributed-systems#K-fault-tolerant-system","tags":"[]#K-fault-tolerant-system","body":"A system is said to be **k-fault-tolerant** if it can survive faults in $ k $ differnet components and still meet its specifications. To achieve a k-fault-tolerant system we must require an agreement protocol that is applied to a process group. Typically this means:\n1. Electing a coordinator.\n2. Deciding whether or not to commit a transaction.\n3. Dividing tasks between workers.\n4. Synchronization.\nThere can be problems in reaching an agreement if communication between processes or processes themselves are not perfect. The goal is to reach consensus on some issue and establish that consensus within a finite number of steps for all non-faulty processes. Reaching an agreement is only possible in the following circumstances\n<table>\n <thead>\n  <tr>\n    <th colspan=\"6\">Message ordering</th>\n  </tr>\n  <tr>\n   <th colspan=\"1\">Process behavior</th>\n   <th colspan=\"2\">Unordered</th>\n   <th colspan=\"2\">Ordered</th>\n   <th colspan=\"1\">Communication delay</th>\n  </tr>\n  </thead>\n  <tbody>\n  <tr>\n    <td>Synchronous</td>\n    <td>X</td>\n    <td>X</td>\n    <td>X</td>\n    <td>X</td>\n    <td>Bounded</td>\n  </tr>\n  <tr>\n    <td>Synchronous</td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>X</td>\n    <td>Unbounded</td>\n  </tr>\n  <tr>\n    <td>Asynchronous</td>\n    <td></td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>Bounded</td>\n  </tr>\n  <tr>\n    <td>Asynchronous</td>\n    <td></td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>Unbounded</td>\n  </tr>\n </tbody>\n <tfoot>\n  <tr>\n   <th></th>\n   <th>Unicast</th>\n   <th>Multicast</th>\n   <th>Unicast</th>\n   <th>Multicast</th>\n   <th></th>\n  </tr>\n  <tr>\n    <th colspan=\"6\">Message transmission</th>\n  </tr>\n </tfoot>\n</table>\nIn practice many distributed systems assume that\n1. Processes are asynchronous\n2. Message transmission is unicast\n3. Communication delays are unbounded\n"},"/high-performance-computing/distributed-systems#Byzantine-agreement-problem":{"id":"/high-performance-computing/distributed-systems#Byzantine-agreement-problem","title":"/high-performance-computing/distributed-systems#Byzantine-agreement-problem","tags":"[]#Byzantine-agreement-problem","body":"- https://en.wikipedia.org/wiki/Quantum_Byzantine_agreement\n- https://en.wikipedia.org/wiki/Byzantine_fault\nIn the byzantine agreement problem we assume that\n1. Processes are synchronous.\n2. Messages are unicast while preserving order.\n3. Communication delay is bounded.\n4. There are $ N $ processes where each process $ i $ will provide a value $ v_i $ to the others.\n5. There are at most $ k $ faulty processes.\n<table>\n <thead>\n  <tr>\n    <th colspan=\"6\">Message ordering</th>\n  </tr>\n  <tr>\n   <th colspan=\"1\">Process behavior</th>\n   <th colspan=\"2\">Unordered</th>\n   <th colspan=\"2\">Ordered</th>\n   <th colspan=\"1\">Communication delay</th>\n  </tr>\n  </thead>\n  <tbody>\n  <tr>\n    <td>Synchronous</td>\n    <td>X</td>\n    <td>X</td>\n    <td style=\"background-color: white; color: black\">X</td>\n    <td>X</td>\n    <td>Bounded</td>\n  </tr>\n  <tr>\n    <td>Synchronous</td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>X</td>\n    <td>Unbounded</td>\n  </tr>\n  <tr>\n    <td>Asynchronous</td>\n    <td></td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>Bounded</td>\n  </tr>\n  <tr>\n    <td>Asynchronous</td>\n    <td></td>\n    <td></td>\n    <td></td>\n    <td>X</td>\n    <td>Unbounded</td>\n  </tr>\n </tbody>\n <tfoot>\n  <tr>\n   <th></th>\n   <th>Unicast</th>\n   <th>Multicast</th>\n   <th>Unicast</th>\n   <th>Multicast</th>\n   <th></th>\n  </tr>\n  <tr>\n    <th colspan=\"6\">Message transmission</th>\n  </tr>\n </tfoot>\n</table>\nThe problem could be expresses as there are $ N $ generals that surround a city. They communicate by courier. Each has an opinion: \"attack\" or \"wait (withdraw)\".\n- In fact, an attack would succeed: the city will fall.\n- Waiting will succeed too: the city will surrender.\n- But if some attack and some wait, disaster ensues\nThis implies that they must reach consensus. Some Generals (f of them) are traitors... It doesn’t matter if they attack or wait, but we must prevent them from disrupting the battle\n- Traitor can send different messages to each\n- Traitor can wait to see what others say\n- Traitor can't forge messages from other generals\nTraitors here are the faulty processes. The basic idea to solve the problem is a two step protocol\n1. Generals sends votes to each other.\n2. Exchange what each general got from the others after all votes have been received.\nBy doing this we hope that we filter out the faulty processes.\n"},"/high-performance-computing/distributed-systems#Process-failure-detection":{"id":"/high-performance-computing/distributed-systems#Process-failure-detection","title":"/high-performance-computing/distributed-systems#Process-failure-detection","tags":"[]#Process-failure-detection","body":"In failure detection a **timeout mechanism** is usually involved, that after a specified period of time will trigger a timeout. However we must be careful to not state that a process has failed because it didn't return the ping within the timeout period, because it may very well be so that the network was very congested at the time being, but if we were to send the ping once again it may reach.\n"},"/high-performance-computing/distributed-systems#CAP-theorem":{"id":"/high-performance-computing/distributed-systems#CAP-theorem","title":"/high-performance-computing/distributed-systems#CAP-theorem","tags":"[]#CAP-theorem","body":"https://en.wikipedia.org/wiki/CAP_theorem\nCAP theorem states that only two of the following three guarantees may hold in a distributed data store.\n1. **Consistency**. Every read receives the most recent write or an error.\n2. **Availability**. Every request receives a (non-error) response, without the guarantee that it contains the most recent write.\n3. **Partition tolerance**. The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes.\nFor example, if a network partition failure happens, it must be decided whether to\n1. Cancel the operation and thus decrease the availability but ensure consistency.\n2. Proceed with the operation and thus provide availability but risk inconsistency.\n"},"/high-performance-computing/distributed-systems#ACID":{"id":"/high-performance-computing/distributed-systems#ACID","title":"/high-performance-computing/distributed-systems#ACID","tags":"[]#ACID","body":"https://en.wikipedia.org/wiki/ACID\nACID stands for **atomicity**, **consistency**, **isolation** and **durability**. Each of these mean the following\n1. **Atomicity**. Operations that are composed together are guaranteed to be executed as a single unit, which either fails completely or succeeds completely. If any of the operations in the composed unit fails the whole unit fails, and the system is rolled back if there were any side effects of the previous operations.\n2. **Consistency**. Ensures that operations bring the system from one valid state into another valid state, maintaining system invariants.\n3. **Isolation**. If operations are executed concurrently isolation ensures that result of the execution is the same as if the operations would have been sequentially. Isolation regulates concurrency control. No operation can see the data from another operation in an 1intermediate state.\n4. **Durability**. Guarantees that once an operation has successfully been executed and committed in the system, it will remain committed even in case of a system failure.\n"},"/high-performance-computing/distributed-systems#The-Eight-Fallacies-of-Distributed-Systems":{"id":"/high-performance-computing/distributed-systems#The-Eight-Fallacies-of-Distributed-Systems","title":"/high-performance-computing/distributed-systems#The-Eight-Fallacies-of-Distributed-Systems","tags":"[]#The-Eight-Fallacies-of-Distributed-Systems","body":"1. The network is reliable\n2. Latency is zero\n3. Bandwidth is infinite\n4. The network is secure\n5. Topology doesn't change\n6. There is one administrator\n7. Transport cost is zero\n8. The network is homogeneous\n"},"/high-performance-computing/distributed-systems#Resources":{"id":"/high-performance-computing/distributed-systems#Resources","title":"/high-performance-computing/distributed-systems#Resources","tags":"[]#Resources","body":"http://csis.pace.edu/~marchese/CS865/\n"},"/machine-learning/collecting-data#":{"id":"/machine-learning/collecting-data#","title":"/machine-learning/collecting-data#","tags":"[]#","body":""},"/machine-learning/collecting-data#Overview":{"id":"/machine-learning/collecting-data#Overview","title":"/machine-learning/collecting-data#Overview","tags":"[]#Overview","body":"It could be of great use to use a already existing data set when creating a new machine learning model.\n- MNIST\n- UCI machine learning repository\n- reserach paper\n- Kaggle\n"},"/machine-learning/collecting-data#Collecting":{"id":"/machine-learning/collecting-data#Collecting","title":"/machine-learning/collecting-data#Collecting","tags":"[]#Collecting","body":"- Scrape from websites\n- Use an open API\nThe properties that hold in the training set should hold for the whole population as well. When collecting data we should be aware of the @(sampling bias)(sampling-bias) and @(nonresponse bias)(nonresponse-bias) to create a well representative data set.\n"},"/machine-learning/collecting-data#Stratification-and-weighting":{"id":"/machine-learning/collecting-data#Stratification-and-weighting","title":"/machine-learning/collecting-data#Stratification-and-weighting","tags":"[]#Stratification-and-weighting","body":"Stratification is adjusting the data set into sub-groups and giving them different weights.\n"},"/machine-learning/collecting-data#Availability-vs.-representativity":{"id":"/machine-learning/collecting-data#Availability-vs.-representativity","title":"/machine-learning/collecting-data#Availability-vs.-representativity","tags":"[]#Availability-vs.-representativity","body":"It is not certain that we can select a representive sample of the data set, in many cases we have to work with what we have. This could be observational/historical data. It could be harder to access different types of medias as well, e.g. fiction vs. news. We also have to keep in mind copyright whatever data we choose to collect (only collecting free data will most likely cause a bias as well).\nSamling effects will create different biases (time, selection, demography etc...).\n"},"/machine-learning/collecting-data#Annotating":{"id":"/machine-learning/collecting-data#Annotating","title":"/machine-learning/collecting-data#Annotating","tags":"[]#Annotating","body":"In the long run it is often useful to create specialized tools for annotating the data to automate the process as much as possible which is greater for scale. It is often easier and less time consuming to annotate with a specialized tool.\nHowever, we might create a biased user interface\n- there might be some easy default\n- how are annotators paid (hour or by quantity)?\n- interest\nThere must be a consistent user manual for annotating the data to get samples from the same \"population\".\n"},"/machine-learning/collecting-data#Semi-automatic-techniques":{"id":"/machine-learning/collecting-data#Semi-automatic-techniques","title":"/machine-learning/collecting-data#Semi-automatic-techniques","tags":"[]#Semi-automatic-techniques","body":"Semi-autmatic techniques are used quite often. They create a bigger data set from a smaller sample. After creation of the bigger data set we could let annotators polish the annotations.\n"},"/machine-learning/collecting-data#Crowdsourcing":{"id":"/machine-learning/collecting-data#Crowdsourcing","title":"/machine-learning/collecting-data#Crowdsourcing","tags":"[]#Crowdsourcing","body":"When using @(crowdsourcing)(crowdsourcing) to annotate the data there are a couple of useful guidelines to keep in mind\n- use easy cognitive tasks\n- use well-defined tasks\n- use concise defintions\n- use a low amount of input\nCrowdsourcing is often most useful for simplier tasks because non-experts annotate the data.\nWe could have more than one annotator per data set to compare the annotations to get better quality annotations. This is called the @(inter-annotator agreement)(inter-annotator-agreement). This is useful for an upper bound of the machine learning model.\n"},"/machine-learning/dimensionality-reduction#":{"id":"/machine-learning/dimensionality-reduction#","title":"/machine-learning/dimensionality-reduction#","tags":"[]#","body":"In short, dimensionality reduction is reducing a high-dimensional dataset into a low-dimensional dataset. This is used for getting a better understanding of the data via visualization, reducing the need for storage, make the algorithms run faster and the learning easier. One famous technique of dimensionality reduction is principle component analysis. It is based on finding new basis vectors that are ordered in a way so that the first principle component has the highest priority (we see most of the variance in that direction). @(Principle component analysis)(principle-component-analysis) (PCA) is implemented using the technique @(Singular value decomposition)(singular-value-decomposition) (SVD). There is more efficient ways to implement this, and Scikit-learn uses a technique called @(low-rank matrix factorization)(low-rank-matrix-factorization). Other techniques involving SGD could be easier to implement in pratice than the low-rank matrix factorization.\n"},"/machine-learning/dimensionality-reduction#t-SNE":{"id":"/machine-learning/dimensionality-reduction#t-SNE","title":"/machine-learning/dimensionality-reduction#t-SNE","tags":"[]#t-SNE","body":"Measures similarities to locals points (local structure). @{tsnegoogle} @{tsne}\n"},"/machine-learning/dimensionality-reduction#Applications":{"id":"/machine-learning/dimensionality-reduction#Applications","title":"/machine-learning/dimensionality-reduction#Applications","tags":"[]#Applications","body":"Recommender systems like the ones used in Netflix, YouTube or Amazon for example.\n"},"/machine-learning/dimensionality-reduction#Recommender-system":{"id":"/machine-learning/dimensionality-reduction#Recommender-system","title":"/machine-learning/dimensionality-reduction#Recommender-system","tags":"[]#Recommender-system","body":"Could be framed in different ways:\n- binary classification\n- regression\n- ranking\nThere are two main approaches for building recommender system:\n- $ content \\space based $  recommend items that are similar to my selected items\n- $ collaborative \\space filtering $ recommend items that are similar to my history\n"},"/machine-learning/dimensionality-reduction#Colloborative-filtering":{"id":"/machine-learning/dimensionality-reduction#Colloborative-filtering","title":"/machine-learning/dimensionality-reduction#Colloborative-filtering","tags":"[]#Colloborative-filtering","body":"We can divide the feedback cycle into two categories:\n- $ explicit $ could be some direct rating on some history item\n- $ implicit $ could be any kind of interaction between items and the user\nOne problem with colloborative filtering is @(cold start)(cold-start). Matrix factorization in colloborative filtering is a bit different than when used in dimensionality reduction. Here it is used to predict and fill the missing cells. E.g. if we have user as a column vector and movies as a row vector we want to map each user to every movie with some probability of likeness.\n"},"/machine-learning/dimensionality-reduction#Word-empeddings":{"id":"/machine-learning/dimensionality-reduction#Word-empeddings","title":"/machine-learning/dimensionality-reduction#Word-empeddings","tags":"[]#Word-empeddings","body":"Two high-level approaches to word empeddings:\n- $ end \\space to \\space end \\space training $ we train the embeddings in with other parts of the model. The embeddings will be specialized for this task.\n- $ pre \\space training $ we train the embeddings in a more general sense so we can use them in other applications\n"},"/machine-learning/dimensionality-reduction#Pre-training":{"id":"/machine-learning/dimensionality-reduction#Pre-training","title":"/machine-learning/dimensionality-reduction#Pre-training","tags":"[]#Pre-training","body":"How can we pre-train word embeddings? In some sense, words that can be represented in similar contexts are assumed to have similar meanings and behave similarly. The model will thus build on this intuition. We could build on statistics, e.g. @(word-word co-occurrence matrix)(word-word-co-occurrence-matrix), and then use a matrix factorization step. GloVe @{glove} is a famous matrix-based word embedding training method.\n"},"/machine-learning/dimensionality-reduction#References":{"id":"/machine-learning/dimensionality-reduction#References","title":"/machine-learning/dimensionality-reduction#References","tags":"[]#References","body":"{tsnegoogle}:\n    title: Visualizing Data Using t-SNE\n    url: https://www.youtube.com/watch?v=RJVL80Gg3lA\n{tsne}:\n    title: t-distributed stochastic neighbor embedding\n    url: https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\n{glove}:\n    url: https://nlp.stanford.edu/projects/glove/\n"},"/machine-learning/ethics#":{"id":"/machine-learning/ethics#","title":"/machine-learning/ethics#","tags":"[]#","body":"[fairness video lecture](https://developers.google.com/machine-learning/crash-course/fairness/video-lecture)\n[fairml](https://fairmlbook.org/introduction.html)\n[fairness introduction google](https://christophm.github.io/interpretable-ml-book/intro.html)\n[interpretability google](https://christophm.github.io/interpretable-ml-book/interpretability.html)\n"},"/machine-learning/evaluation#":{"id":"/machine-learning/evaluation#","title":"/machine-learning/evaluation#","tags":"[]#","body":"There are two types of evaluation @(intrinsic evaluation)(intrinsic-evaluation) and @(extrinsic evaluation)(extrinsic-evaluation). By comparing to a golden standard we do intrinsic evaluation.\n"},"/machine-learning/evaluation#Classifiers":{"id":"/machine-learning/evaluation#Classifiers","title":"/machine-learning/evaluation#Classifiers","tags":"[]#Classifiers","body":"$$\n\\text{accuracy} = \\frac{\\text{number of correct}}{N}\n$$\n$$\n\\text{error rate} = \\frac{\\text{number of incorrect}}{N}\n$$\n"},"/machine-learning/evaluation#Confusion-matrix":{"id":"/machine-learning/evaluation#Confusion-matrix","title":"/machine-learning/evaluation#Confusion-matrix","tags":"[]#Confusion-matrix","body":"Confusion matrix are also one way to measure how the classifer interpret different classes, and their relations with each other @{confusion} @{wikiconfusion}.\n"},"/machine-learning/evaluation#Precision-and-recall":{"id":"/machine-learning/evaluation#Precision-and-recall","title":"/machine-learning/evaluation#Precision-and-recall","tags":"[]#Precision-and-recall","body":"Precision and recall are commonly used in various classifier problems for evaluation. Scikit-learn provides this functionality @{precision} @{recall}.\n$$\nP = \\frac{TP}{TP + FP} \\qquad R = \\frac{TP}{TP + FN}\n$$\n"},"/machine-learning/evaluation#F-score":{"id":"/machine-learning/evaluation#F-score","title":"/machine-learning/evaluation#F-score","tags":"[]#F-score","body":"F-score is a combination of precision and recall @{f1}.\n$$\nF = \\frac{2 \\cdot P \\cdot R}{P + R}\n$$\n"},"/machine-learning/evaluation#Sensitivity-and-specificity":{"id":"/machine-learning/evaluation#Sensitivity-and-specificity","title":"/machine-learning/evaluation#Sensitivity-and-specificity","tags":"[]#Sensitivity-and-specificity","body":"$$\nSen = \\frac{TP}{TP + FN} \\qquad Spe = \\frac{TN}{TN + FP}\n$$\n"},"/machine-learning/evaluation#True-positive-rate-and-false-positive-rate":{"id":"/machine-learning/evaluation#True-positive-rate-and-false-positive-rate","title":"/machine-learning/evaluation#True-positive-rate-and-false-positive-rate","tags":"[]#True-positive-rate-and-false-positive-rate","body":"$$\nTPR = \\frac{TP}{TP + FN} \\qquad FPR = \\frac{FP}{FP + TN}\n$$\n"},"/machine-learning/evaluation#Regressors":{"id":"/machine-learning/evaluation#Regressors","title":"/machine-learning/evaluation#Regressors","tags":"[]#Regressors","body":""},"/machine-learning/evaluation#Mean-squared-error":{"id":"/machine-learning/evaluation#Mean-squared-error","title":"/machine-learning/evaluation#Mean-squared-error","tags":"[]#Mean-squared-error","body":"$$\nMSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat y_i)^2\n$$\n"},"/machine-learning/evaluation#Mean-absolute-error":{"id":"/machine-learning/evaluation#Mean-absolute-error","title":"/machine-learning/evaluation#Mean-absolute-error","tags":"[]#Mean-absolute-error","body":"$$\nMAE = \\frac{1}{N} \\sum_{i=1}^N |y_i - \\hat y_i |\n$$\n"},"/machine-learning/evaluation#Coefficient-of-determination":{"id":"/machine-learning/evaluation#Coefficient-of-determination","title":"/machine-learning/evaluation#Coefficient-of-determination","tags":"[]#Coefficient-of-determination","body":"Both $ MSE $ and $ MAE $ depend on scale which makes it hard to tell if the regressor behaves well, instead we can use the coefficient of determination\n$$\nR^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat y_i)^2}{\\sum_{i=1}^N (y_i - \\bar y)^2}\n$$\n"},"/machine-learning/evaluation#Loss-versus-quality-metric":{"id":"/machine-learning/evaluation#Loss-versus-quality-metric","title":"/machine-learning/evaluation#Loss-versus-quality-metric","tags":"[]#Loss-versus-quality-metric","body":"For regression, $ MSE $ is often used as both the quality metric and the loss function.\nFor classification we often use different metrics. The reason for this is that it is mathematically challenging to optimize the accuracy or the error rate.\n"},"/machine-learning/evaluation#References":{"id":"/machine-learning/evaluation#References","title":"/machine-learning/evaluation#References","tags":"[]#References","body":"{confusion}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n{wikiconfusion}:\n    url: https://en.wikipedia.org/wiki/Confusion_matrix\n{precision}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n{recall}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n{classreport}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n{f1}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n"},"/machine-learning/feature-selection#":{"id":"/machine-learning/feature-selection#","title":"/machine-learning/feature-selection#","tags":"[]#","body":""},"/machine-learning/feature-selection#Large-feature-sets":{"id":"/machine-learning/feature-selection#Large-feature-sets","title":"/machine-learning/feature-selection#Large-feature-sets","tags":"[]#Large-feature-sets","body":"There are some problems arising with having a large set of features:\n- there is a risk of information overload\n- training time is increased\n- more complexity will result in worse generalization\n"},"/machine-learning/feature-selection#Types-of-selection":{"id":"/machine-learning/feature-selection#Types-of-selection","title":"/machine-learning/feature-selection#Types-of-selection","tags":"[]#Types-of-selection","body":"So how do we choose the most useful and important features? The scikit-learn library has a number of different feature selection algorithms @{sklearn}. There are three high-level approaches to feature selection.\n"},"/machine-learning/feature-selection#Filter":{"id":"/machine-learning/feature-selection#Filter","title":"/machine-learning/feature-selection#Filter","tags":"[]#Filter","body":"Is the input informative to the output? We want to apply some scoring functions to measure how well one feature perform in comparison to another. There are different scoring functions for classification and regression. One example of a scoring function is mutual information. It is defined like this\n$$\nI(X;Y) = \\sum_{y} \\sum_{x} p(x, y) \\log \\frac{p(x,y)}{p(x) \\cdot p(y)}\n$$\nThe mutual information function is thus telling us how closely linked the two random variables $ X $ and $ Y $ are. If they are independent from each other the mutual information function will produce a zero. Other scoring functions are derived from statistical tests.\nGiven a scoring function we can select a subset in two different ways:\n- selecting the top $ K $ elements\n- selecting the top 1 percentile\nSee @{sklearn} for more information.\n"},"/machine-learning/feature-selection#Drawbacks":{"id":"/machine-learning/feature-selection#Drawbacks","title":"/machine-learning/feature-selection#Drawbacks","tags":"[]#Drawbacks","body":"There are three main drawbacks:\n- the solution is suboptimal because the algorithm is greedy and will not find the optimal solution\n- even though the algorithm is greedy it can be very costly if there are many features.\n- it can be difficult to find features that are useful when grouped together.\n"},"/machine-learning/feature-selection#Wrapper":{"id":"/machine-learning/feature-selection#Wrapper","title":"/machine-learning/feature-selection#Wrapper","tags":"[]#Wrapper","body":"Pseudo-python code of how the alogorithm work\n```python\nS = {}\nwhile (no improvement):\n    best = find feature F that gives greatest improvement to S\n    if best not None:\n        add F to S\n```\nAdvantages compared to filter-based methods are that the machine learning model is used and involved in choosing features. We will not add any redundant features as well.\n"},"/machine-learning/feature-selection#Embedded":{"id":"/machine-learning/feature-selection#Embedded","title":"/machine-learning/feature-selection#Embedded","tags":"[]#Embedded","body":"Embedded methods are defined by machine learning that have built-in feature selection properties. This is the main characteristic of the decision tree. You could say that decision trees have built-in filter methods (scoring system). Linear models could also have built-in feature selection.\n"},"/machine-learning/feature-selection#Conclusion":{"id":"/machine-learning/feature-selection#Conclusion","title":"/machine-learning/feature-selection#Conclusion","tags":"[]#Conclusion","body":"It is useful to\n- get rid of redudant features\n- consider feature selection as a part of the tuning process\n"},"/machine-learning/feature-selection#References":{"id":"/machine-learning/feature-selection#References","title":"/machine-learning/feature-selection#References","tags":"[]#References","body":"{sklearn}:\n    title: Feature selection\n    url: https://scikit-learn.org/stable/modules/feature_selection.html\n"},"/machine-learning/hyperparameters#":{"id":"/machine-learning/hyperparameters#","title":"/machine-learning/hyperparameters#","tags":"[]#","body":""},"/machine-learning/hyperparameters#Definition":{"id":"/machine-learning/hyperparameters#Definition","title":"/machine-learning/hyperparameters#Definition","tags":"[]#Definition","body":"Hyperparameters control how learning algorithms work. In a decision tree the maximum depth is one hyperparameter. In neural networks two examples are the number of layers and the size of layers. A model often needs extensive tuning in order to work properly.\nScikit-learn provides some useful ways of determining hyperparameters @{sklearn}.\n"},"/machine-learning/hyperparameters#Tuning":{"id":"/machine-learning/hyperparameters#Tuning","title":"/machine-learning/hyperparameters#Tuning","tags":"[]#Tuning","body":"Tuning the hyperparameters could be very time-consuming and involve trial and error. There are however alternatives.\n"},"/machine-learning/hyperparameters#Grid-search":{"id":"/machine-learning/hyperparameters#Grid-search","title":"/machine-learning/hyperparameters#Grid-search","tags":"[]#Grid-search","body":"Grid search is one of them which is a brute force searching algorithm over a finite set of hyperparameter settings. All combinations are tested and the best is selected. This approach belongs to the more time-consuming ones. In a decision tree we could search for the best maximum tree depth.\n"},"/machine-learning/hyperparameters#Random-search":{"id":"/machine-learning/hyperparameters#Random-search","title":"/machine-learning/hyperparameters#Random-search","tags":"[]#Random-search","body":"Random search @{bergstra} finds a set of hyperparameters with good performance a lot quicker than grid search. We define a distribution for each hyperparameter (thus we may need some understanding of how the hyperparameter work). We then iterate while picking samples randomly from each hyperparamter distribution.\n"},"/machine-learning/hyperparameters#Other":{"id":"/machine-learning/hyperparameters#Other","title":"/machine-learning/hyperparameters#Other","tags":"[]#Other","body":"There are more sophisticated methods as well @{snoek}.\n"},"/machine-learning/hyperparameters#References":{"id":"/machine-learning/hyperparameters#References","title":"/machine-learning/hyperparameters#References","tags":"[]#References","body":"{sklearn}:\n    title: Tuning the hyper-parameters of an estimator\n    url: https://scikit-learn.org/stable/modules/grid_search.html\n{bergstra}:\n    author: James Bergstra and Yoshua Bengio\n    year: 2012\n    title: Random Search for Hyper-Parameter Optimization\n    url: https://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf\n{snoek}:\n    author: Jasper Snoek, Hugo Larochelle and Ryan P. Adams\n    year: 2012\n    title: PRACTICAL BAYESIAN OPTIMIZATION OF MACHINE LEARNING ALGORITHMS\n    url: https://arxiv.org/pdf/1206.2944.pdf\n"},"/machine-learning/keywords#":{"id":"/machine-learning/keywords#","title":"/machine-learning/keywords#","tags":"[\"keywords\"]#","body":""},"/machine-learning/keywords#Generalization":{"id":"/machine-learning/keywords#Generalization","title":"/machine-learning/keywords#Generalization","tags":"[\"keywords\"]#Generalization","body":"In machine learning generalization refers to how well a trained model is to classify unseen data.\n"},"/machine-learning/keywords#Generalization-gap":{"id":"/machine-learning/keywords#Generalization-gap","title":"/machine-learning/keywords#Generalization-gap","tags":"[\"keywords\"]#Generalization-gap","body":"Generalization gap is defined as the difference between the model's performance on training data versus unseen data from the same distribution.\n"},"/machine-learning/keywords#Prediction":{"id":"/machine-learning/keywords#Prediction","title":"/machine-learning/keywords#Prediction","tags":"[\"keywords\"]#Prediction","body":"Predictions are machine learning model's way of mapping an input to an output.\n"},"/machine-learning/keywords#Training-data":{"id":"/machine-learning/keywords#Training-data","title":"/machine-learning/keywords#Training-data","tags":"[\"keywords\"]#Training-data","body":"A training set is collected from a distribution very similar to how it will look when the model is put into practive. You usually split the collected data into training data and test data with the majority of that being the training data.\n"},"/machine-learning/keywords#Validation-set":{"id":"/machine-learning/keywords#Validation-set","title":"/machine-learning/keywords#Validation-set","tags":"[\"keywords\"]#Validation-set","body":"The model is evaluated on the validation set, which aims to be unbiased in comparison to the training set, while optimizing the model's hyperparameters. The validation set will become biased eventually because we tune the model to get as good performance as possible on that set.\n"},"/machine-learning/keywords#Test-set":{"id":"/machine-learning/keywords#Test-set","title":"/machine-learning/keywords#Test-set","tags":"[\"keywords\"]#Test-set","body":"The test set is the final evaluation of the model and provides an unbiased final evaluation of the model. After a model is evaluated on the test set it should not be further optimzed because that will introduce bias.\n"},"/machine-learning/keywords#Induction":{"id":"/machine-learning/keywords#Induction","title":"/machine-learning/keywords#Induction","tags":"[\"keywords\"]#Induction","body":"Induction in machine learning is the process of inferring general rules from specific\n"},"/machine-learning/keywords#Regression":{"id":"/machine-learning/keywords#Regression","title":"/machine-learning/keywords#Regression","tags":"[\"keywords\"]#Regression","body":"A machine learning model for regression tries to map inputs to outputs in the continuous space instead of the discrete space which is used in classification.\n"},"/machine-learning/keywords#Classification":{"id":"/machine-learning/keywords#Classification","title":"/machine-learning/keywords#Classification","tags":"[\"keywords\"]#Classification","body":"A machine learning model for classification tries to identify which set of categories an observer belongs to. Thus mapping an input to and output in the discrete space. Binary classification is a special of multiclass classification where there is only two groups.\n"},"/machine-learning/keywords#Ranking":{"id":"/machine-learning/keywords#Ranking","title":"/machine-learning/keywords#Ranking","tags":"[\"keywords\"]#Ranking","body":"It is a type of application of typically supervised, semi-supervised of reinforcement learning wherein the training data has some partial order between each item. The order is often induced by a numerical or ordinal score.\n"},"/machine-learning/keywords#Feature":{"id":"/machine-learning/keywords#Feature","title":"/machine-learning/keywords#Feature","tags":"[\"keywords\"]#Feature","body":"Within machine learning features are some individual measurable properties of a phenomenon. Features could be numberic, but also structural information as strings or graphs. Together they are used to build patterns which the machine learning model learns.\n"},"/machine-learning/keywords#Label":{"id":"/machine-learning/keywords#Label","title":"/machine-learning/keywords#Label","tags":"[\"keywords\"]#Label","body":"In supervised or semi-supervised learning, a label is the corresponding output in the training data.\n"},"/machine-learning/keywords#Loss-function":{"id":"/machine-learning/keywords#Loss-function","title":"/machine-learning/keywords#Loss-function","tags":"[\"keywords\"]#Loss-function","body":"A loss function is formally a function that maps an event or some values to a real number with a cost associated with it, and the optimization algorithm tries to minimize that cost. There are different loss functions depending on the type of model. In regression problems the most common loss functions are @{lossreg}:\n- Mean absolute error (MAE)\n- Mean absolute percentage error (MAPE)\n- Mean squared error (MSE)\n- Root mean squared error (RMSE)\n- Huber loss\n- Log-cosh loss\nFor classification the most common loss functions are @{lossclass}:\n- Cross-entropy loss (or log loss)\n- Hinge loss\n- Squared hinge loss\n"},"/machine-learning/keywords#Parity":{"id":"/machine-learning/keywords#Parity","title":"/machine-learning/keywords#Parity","tags":"[\"keywords\"]#Parity","body":"A parity function is a boolean function whose values are 1 if the input vector has an off number of ones, else 0.\n"},"/machine-learning/keywords#Noise":{"id":"/machine-learning/keywords#Noise","title":"/machine-learning/keywords#Noise","tags":"[\"keywords\"]#Noise","body":"Noise in machine learning can be a wanted property or not depending on the problem. It may increse the complexity of the model and the time of learning which may degrade the performance. However, it may as well help generalize the model as in data augmentation.\n"},"/machine-learning/keywords#Supervised-learning":{"id":"/machine-learning/keywords#Supervised-learning","title":"/machine-learning/keywords#Supervised-learning","tags":"[\"keywords\"]#Supervised-learning","body":"Supervised learning is one of the major learning paradigms in machine learning. It requires that the training data is labeled. Thus a model tries to imitate by examples.\n"},"/machine-learning/keywords#Unsupervised-learning":{"id":"/machine-learning/keywords#Unsupervised-learning","title":"/machine-learning/keywords#Unsupervised-learning","tags":"[\"keywords\"]#Unsupervised-learning","body":"Unsupervised learning is one of the major learning paradigms in machine learning. Unlike supervised machine learning, unsupervised learning does not have any labeled data but must instead discover certain patterns about the data itself.\n"},"/machine-learning/keywords#Semi-supervised-learning":{"id":"/machine-learning/keywords#Semi-supervised-learning","title":"/machine-learning/keywords#Semi-supervised-learning","tags":"[\"keywords\"]#Semi-supervised-learning","body":"Semi-supervised learning could be looked at as a mixture of supervised learning and unsupervised learning, that combines a small amount of labeled data with a large amount of unlabeled data during the training phase.\n"},"/machine-learning/keywords#Reinforcement-learning":{"id":"/machine-learning/keywords#Reinforcement-learning","title":"/machine-learning/keywords#Reinforcement-learning","tags":"[\"keywords\"]#Reinforcement-learning","body":"Reinforcement learning is one of the major learning paradigms in machine learning. It concerns how an agent should take actions in a defined enviroment in order to maximize the cumulative reward. The reward function is here the objective function.\n"},"/machine-learning/keywords#Cross-validation":{"id":"/machine-learning/keywords#Cross-validation","title":"/machine-learning/keywords#Cross-validation","tags":"[\"keywords\"]#Cross-validation","body":"Cross-validation is a technique that is used to reduce the number of samples required for the training process of a model. The technique removes the need of a validation set. Instead one basic approach called k-fold cross-validation splits the training set into k smaller sets called folds. Each of these folds act like the validation set in turns for a total of k times. After cross-validation the model is evaulated on the test set as usual. The technique can be computationally heavy.\n"},"/machine-learning/keywords#Decision-tree":{"id":"/machine-learning/keywords#Decision-tree","title":"/machine-learning/keywords#Decision-tree","tags":"[\"keywords\"]#Decision-tree","body":"A decision tree is a model that orders its weights in tree-based format where leaves represent class labels and branches represent conjuntions of features that lead to the different decisions. It is the branches that are updated in the training process. Decisions trees could be used in regression as well wherin the leaves represent a condition and the the branches usually correspond to yes or no given the validity of the condition. Decision trees are one of the more popular machine learning models because of their simplicity and interpretablility.\n"},"/machine-learning/keywords#Entropy":{"id":"/machine-learning/keywords#Entropy","title":"/machine-learning/keywords#Entropy","tags":"[\"keywords\"]#Entropy","body":"Entropy is the measure of disorder, a measure of purity or homogeneity. Thus, it could be seen as how random the data points are in a distribution. Greater disorder results in lower impurity.\n"},"/machine-learning/keywords#Information-gain":{"id":"/machine-learning/keywords#Information-gain","title":"/machine-learning/keywords#Information-gain","tags":"[\"keywords\"]#Information-gain","body":"Entropy plays an important role in information gain. Information gain is known in information theory as the amount of information gained about a random variable from observing another random variable. In the context of decision trees it is a good measure for deciding whether a feature has relevance, although it is not perfect @{wikiinformationgain}.\n$$\nEntropy = - \\sum_{i=1}^n p_i * \\log_2 (p_i)\n$$\n"},"/machine-learning/keywords#Gini-score":{"id":"/machine-learning/keywords#Gini-score","title":"/machine-learning/keywords#Gini-score","tags":"[\"keywords\"]#Gini-score","body":"As in information gain entropy plays an important role here as well in determining how pure a set of data points are. It ranges between 0-1 where 0 expresses purity, namely, all data points belong to the same class, whereas 1 indicates a random distribution amoong the data points.\n$$\nGini \\space score = 1 - \\sum_{i=1}^n (p_i)^2\n$$\n"},"/machine-learning/keywords#Ensemble":{"id":"/machine-learning/keywords#Ensemble","title":"/machine-learning/keywords#Ensemble","tags":"[\"keywords\"]#Ensemble","body":"An ensemble method take advantage of multiple learning algorithms to obtain a better predictive result that could not otherwise be obtained.\n"},"/machine-learning/keywords#Boosting":{"id":"/machine-learning/keywords#Boosting","title":"/machine-learning/keywords#Boosting","tags":"[\"keywords\"]#Boosting","body":"Boosting is an ensemble technique (meta-algorithm) that involves an incremental build of the ensemble model by training each new model instance in a fashion that will \"correct\" how earlier instances misclassified the data. Boosting has been shown to yield better results than bagging but also tends to overfit to a higher degree. It is used to reduce bias and variance. It converts weak learners to strong learners.\n"},"/machine-learning/keywords#AdaBoost":{"id":"/machine-learning/keywords#AdaBoost","title":"/machine-learning/keywords#AdaBoost","tags":"[\"keywords\"]#AdaBoost","body":"AdaBoost is short for Adaptive Boosting. It focuses on misclassified instances by previous classifiers and tweaks new weak learners to slightly better performance. As long as the performane of each weak learner is better than random guessing even by a little, the final model can be proven to converge to a strong learner. It has no loss function.\n"},"/machine-learning/keywords#Gradient-boosting":{"id":"/machine-learning/keywords#Gradient-boosting","title":"/machine-learning/keywords#Gradient-boosting","tags":"[\"keywords\"]#Gradient-boosting","body":"Like any other boosting method gradient boosting builds the model by stage-wise improvements of weak learners, but generalizes the model with an arbitrary differentiable loss function. What differs the AdaBoost algorithm from gradient boosting is that is does not have a loss function.\n"},"/machine-learning/keywords#Stacking":{"id":"/machine-learning/keywords#Stacking","title":"/machine-learning/keywords#Stacking","tags":"[\"keywords\"]#Stacking","body":"Stacking is an ensemble technique (meta-algorithm) that combines several different learning algorithms to one united. Every other learning algorithm is trained on the available data, and then combined with a combiner algorithm to make the final prediction using the predictions of all the other algorithms as input.\n"},"/machine-learning/keywords#Bagging":{"id":"/machine-learning/keywords#Bagging","title":"/machine-learning/keywords#Bagging","tags":"[\"keywords\"]#Bagging","body":"Bagging or bootstrap aggregation is an ensemble technique (meta-algorithm) that promotes total model variance by having each submodel vote with equal weight. Thus, it is a technique for reducing variances for estimated prediction functions and does so by averaging a number of noisy but approximately unbiased models. Bagging trains each model in the ensemble with a randomly chosen subset of the training set. The samples in bagging are different from each other but replacements are allowed which means that one instance may occur in several samples or none at all.\n"},"/machine-learning/keywords#Random-forest":{"id":"/machine-learning/keywords#Random-forest","title":"/machine-learning/keywords#Random-forest","tags":"[\"keywords\"]#Random-forest","body":"Random forests are an ensemble learning algorithm based on bagging and decision trees. The performance of multiple decision trees are thus combined and usually gives a better performance than one decision tree alone.\n"},"/machine-learning/keywords#Spinning":{"id":"/machine-learning/keywords#Spinning","title":"/machine-learning/keywords#Spinning","tags":"[\"keywords\"]#Spinning","body":"Based on the same idea as bagging and is also called feature bagging or random subspace learning.\n"},"/machine-learning/keywords#Weak-learner":{"id":"/machine-learning/keywords#Weak-learner","title":"/machine-learning/keywords#Weak-learner","tags":"[\"keywords\"]#Weak-learner","body":"A weak learner is a classifier that is only partially correlated with the true classification. It performs better than random guesses but not very much.\n"},"/machine-learning/keywords#Strong-learner":{"id":"/machine-learning/keywords#Strong-learner","title":"/machine-learning/keywords#Strong-learner","tags":"[\"keywords\"]#Strong-learner","body":"A strong learner is a classifier that is very well correlated with the true classification.\n"},"/machine-learning/keywords#Linear-models":{"id":"/machine-learning/keywords#Linear-models","title":"/machine-learning/keywords#Linear-models","tags":"[\"keywords\"]#Linear-models","body":"Linear models base its prediction on linear functions as the name suggests.\n- support vector machine\n- linear classifiers\n- logistic regression\n- lasso\n- elastic net\n- ridge regression\n- committee\n- patch representation\n- bag of words (text representation)\n- shape representation\n- meta features\n- meta algorithm\n- combinatorial transformations\n- logarithmic transformation\n- precision/recall metric\n- accuracy metric\n- f-measure\n- sensitivity/specificity metric\n- ROC curve\n- AUC score\n- development data\n- jack-knifing\n- imbalanced data\n- induced distribution\n- feature selection https://en.wikipedia.org/wiki/Feature_selection\n- predictive model\n- one-hot encoding\n- TF-IDF\n- mutual information\n- hyperparameters\n- grid search\n- black box optimization\n- automated machine learning (AutoML)\n- shallow decision tree\n- hypothesis space\n- linearly separable\n- least-square regression\n- inter-annotator agreement\n- chance-corrected agreement measure\n- chance agreement probability\n- objective function\n- regularizer\n- unconstrained optimization\n- constrained optimization\n- gradient\n- batch\n- early stopping\n- logistic\n- sigmoid\n- tanh\n- ReLu\n- log odds\n- likelihood function\n- log loss\n- maximum a posteriori\n- Gaussian prior\n- Laplace prior\n- one-versus-rest\n- one-versus-one\n- softmax\n- cross-entropy loss\n- margin\n- structural risk minimization theorem\n- input units/nodes\n- hidden units/nodes\n- output units/nodes\n- activation\n- universal approximation theorem\n- minibatch\n- adaptive\n    - adam\n    - adagrad\n    - RMSProp\n- dropout\n- data augmentation\n- pseudo-residual\n- residual\n- learning rate\n- ensemble size\n- measure\n- downstream task\n- word error rate\n- BLEU\n- overlap-based metric\n- humans-in-the-loop\n- true positives\n- false positives\n- true negatives\n- false negatives\n- coefficient of determination\n- confidence score\n- search engine\n- ranking systems\n- precision at k\n- scorer\n- ranker\n- feature extraction\n- SIFT\n- translational invariance\n- spotting patterns\n- convolutinal filters\n- pooling\n- fully connected layers\n- dense layers\n- redidual connections\n- normalizations\n- kernel\n- feature map\n- vanishing gradients\n- exploding gradients\n- mathematical instability\n- batch normalization\n- transfer learning\n- freeze and unfreeze model\n- fine-tune model\n- catastrophic forgetting\n- clustering (flat and hierachical)\n- k-medoids\n- mean shift\n- Gaussian mixture\n- DBSCAN\n- agglomerative (clustering)\n- divisive (clustering)\n- evaluation (internal and external evaluation)\n- silhoutte score\n- purity score\n- inverse purity score\n- residual sum of squares\n- NP-hard\n- elbow method\n- density-based clustering methods\n- core point\n- noise point or outlier\n- matrix factorization\n- low rank matrix factorization\n- autoregressive model (time series)\n- exogenous (ARX)\n- sequence-to-sequence\n- attention model\n- transformer (the BERT model)\n- induction\n- histogram\n- loss function\n  - squared loss\n  - absolute loss\n  - zero/one loss\n- spinning\n- exploration-exploitation dilemma\n"},"/machine-learning/keywords#Bias":{"id":"/machine-learning/keywords#Bias","title":"/machine-learning/keywords#Bias","tags":"[\"keywords\"]#Bias","body":""},"/machine-learning/keywords#Nonresponse-bias":{"id":"/machine-learning/keywords#Nonresponse-bias","title":"/machine-learning/keywords#Nonresponse-bias","tags":"[\"keywords\"]#Nonresponse-bias","body":""},"/machine-learning/keywords#Inductive-bias":{"id":"/machine-learning/keywords#Inductive-bias","title":"/machine-learning/keywords#Inductive-bias","tags":"[\"keywords\"]#Inductive-bias","body":"The preference for one distinction over another. If the inductive bias is too far away from the concept that is being learned, the whole learning might fail.\n"},"/machine-learning/keywords#Normalization":{"id":"/machine-learning/keywords#Normalization","title":"/machine-learning/keywords#Normalization","tags":"[\"keywords\"]#Normalization","body":"Is a good way of keeping the data consistent. There are two basic types of normalization: example and feature normalization.\n"},"/machine-learning/keywords#Feature-normalization":{"id":"/machine-learning/keywords#Feature-normalization","title":"/machine-learning/keywords#Feature-normalization","tags":"[\"keywords\"]#Feature-normalization","body":"Go through every feature and apply the same adjustment across all examples. There are two standard techniques to use: centering and scaling. Centering to keep the data set close around the origin. Scaling to make sure each feature has variance 1 across the training data.\n"},"/machine-learning/keywords#Example-normalization":{"id":"/machine-learning/keywords#Example-normalization","title":"/machine-learning/keywords#Example-normalization","tags":"[\"keywords\"]#Example-normalization","body":"Go through every feature but adjust them individually. The standard technique is to make sure that each feature vector has the length of one. The advantages of example normalization is that comparisons between data sets are more straightforward.\n"},"/machine-learning/keywords#Approximation-error":{"id":"/machine-learning/keywords#Approximation-error","title":"/machine-learning/keywords#Approximation-error","tags":"[\"keywords\"]#Approximation-error","body":"Will measure how well the model family is performing.\n"},"/machine-learning/keywords#Estimation-error":{"id":"/machine-learning/keywords#Estimation-error","title":"/machine-learning/keywords#Estimation-error","tags":"[\"keywords\"]#Estimation-error","body":"Will measure how far off one classifer is from the optimal classifier of that type.\n"},"/machine-learning/keywords#Bias-variance-trade-off":{"id":"/machine-learning/keywords#Bias-variance-trade-off","title":"/machine-learning/keywords#Bias-variance-trade-off","tags":"[\"keywords\"]#Bias-variance-trade-off","body":"The trade-off between approximation and estimation error is usually called the bias/variance trade-off. The bias corresponding to the approximation error and the variance corrsponding to the estimation error.\n"},"/machine-learning/keywords#Imbalanced-data":{"id":"/machine-learning/keywords#Imbalanced-data","title":"/machine-learning/keywords#Imbalanced-data","tags":"[\"keywords\"]#Imbalanced-data","body":"The imbalanced data problem refers to the problem where the distribution from which the data is taken has an imbalance. This is not good because machine learning algorithms will try to minimize the error, and thus, predict in favor of the imbalance majority. They can often achieve really good results by doing nothing. Hence, you probably not care about predicting accuracy.\n"},"/machine-learning/keywords#Feature-selection":{"id":"/machine-learning/keywords#Feature-selection","title":"/machine-learning/keywords#Feature-selection","tags":"[\"keywords\"]#Feature-selection","body":""},"/machine-learning/keywords#Embedded-methods":{"id":"/machine-learning/keywords#Embedded-methods","title":"/machine-learning/keywords#Embedded-methods","tags":"[\"keywords\"]#Embedded-methods","body":"Embedded methods are used to learn which features best contribute to the learning of a model while it is being created. Common methods are regularization methods.\n"},"/machine-learning/keywords#Regularization-methods":{"id":"/machine-learning/keywords#Regularization-methods","title":"/machine-learning/keywords#Regularization-methods","tags":"[\"keywords\"]#Regularization-methods","body":"Regularization methods or penalization methods introduce additional constraints which makes the model bias toward fewer constraints.\n"},"/machine-learning/keywords#Feature-imputation":{"id":"/machine-learning/keywords#Feature-imputation","title":"/machine-learning/keywords#Feature-imputation","tags":"[\"keywords\"]#Feature-imputation","body":"It will try to fill any missing data. We could replace the missing value with a constant (e.g. the mean value), a random value or a prediction from the other values.\n"},"/machine-learning/keywords#The-Widrow-Hoff-algorithm":{"id":"/machine-learning/keywords#The-Widrow-Hoff-algorithm","title":"/machine-learning/keywords#The-Widrow-Hoff-algorithm","tags":"[\"keywords\"]#The-Widrow-Hoff-algorithm","body":"```python\nw = [0, ..., 0]\nfor i in range(N): # N epochs\n    for (x[i], y[i]) in the training set\n        g = w * x[i]\n        error = g - y[i]\n        w = w - learning_rate * error * x[i]\nreturn w\n```\n"},"/machine-learning/keywords#Crowdsourcing":{"id":"/machine-learning/keywords#Crowdsourcing","title":"/machine-learning/keywords#Crowdsourcing","tags":"[\"keywords\"]#Crowdsourcing","body":"A common technique for annotating data. It uses a large pool of non-expert annotators to annotate the data.\n"},"/machine-learning/keywords#Deep-learning":{"id":"/machine-learning/keywords#Deep-learning","title":"/machine-learning/keywords#Deep-learning","tags":"[\"keywords\"]#Deep-learning","body":"Deep learning is a neural network with many hidden layers. The universal approximation theorem states that one hidden layers should be enough to approximate any function, but it is often more practical to stack many hidden layers on each other.\n"},"/machine-learning/keywords#Backpropagation":{"id":"/machine-learning/keywords#Backpropagation","title":"/machine-learning/keywords#Backpropagation","tags":"[\"keywords\"]#Backpropagation","body":"Backpropagation is the trick of using the gradients of the weights of layers occuring later in the hierarchy to compute the gradient when using the chain rule.\n"},"/machine-learning/keywords#Intrinsic-evaluation":{"id":"/machine-learning/keywords#Intrinsic-evaluation","title":"/machine-learning/keywords#Intrinsic-evaluation","tags":"[\"keywords\"]#Intrinsic-evaluation","body":"Intrinsic evaluation is the performance measured in isolation using some metric computed automatically.\n"},"/machine-learning/keywords#Extrinsic-evaluation":{"id":"/machine-learning/keywords#Extrinsic-evaluation","title":"/machine-learning/keywords#Extrinsic-evaluation","tags":"[\"keywords\"]#Extrinsic-evaluation","body":"How does one change to the predictor affect the performance?\n"},"/machine-learning/keywords#F-score":{"id":"/machine-learning/keywords#F-score","title":"/machine-learning/keywords#F-score","tags":"[\"keywords\"]#F-score","body":"The F-score may refer to a clustering method or a classification method.\n"},"/machine-learning/keywords#K-means":{"id":"/machine-learning/keywords#K-means","title":"/machine-learning/keywords#K-means","tags":"[\"keywords\"]#K-means","body":"K-means is probably the most popular technique for clustering and the idea behind it is to find a set of K clusters such that each data point is close to its centroid (mean vector).\n"},"/machine-learning/keywords#Lloyd's-algorithm":{"id":"/machine-learning/keywords#Lloyd's-algorithm","title":"/machine-learning/keywords#Lloyd's-algorithm","tags":"[\"keywords\"]#Lloyd's-algorithm","body":"```python\nwhile clusters don't change:\n    insert x_i to cluster S_k\n    recompute cluster centroids for each S_k\nreturn [S_1...S_k]\n```\n"},"/machine-learning/keywords#The-elbow-method":{"id":"/machine-learning/keywords#The-elbow-method","title":"/machine-learning/keywords#The-elbow-method","tags":"[\"keywords\"]#The-elbow-method","body":"When we use k-means for some clustering problem and want to choose the number of clusters we wish the algorithm should find, the elbow method presumes that there are some natural cluster optima. The loss function will drop quickly until we reach this optima, but increasing the numbers more will have diminishing returns. If we plot the number of clusters and the loss, we know we can apply the elbow method if the curve looks like an elbow.\n"},"/machine-learning/keywords#Principle-component-analysis":{"id":"/machine-learning/keywords#Principle-component-analysis","title":"/machine-learning/keywords#Principle-component-analysis","tags":"[\"keywords\"]#Principle-component-analysis","body":"Principle component analysis (PCA)\n"},"/machine-learning/keywords#Singular-value-decomposition":{"id":"/machine-learning/keywords#Singular-value-decomposition","title":"/machine-learning/keywords#Singular-value-decomposition","tags":"[\"keywords\"]#Singular-value-decomposition","body":"Singular value decomposition (SVD)\n"},"/machine-learning/keywords#Low-rank-matrix-factorization":{"id":"/machine-learning/keywords#Low-rank-matrix-factorization","title":"/machine-learning/keywords#Low-rank-matrix-factorization","tags":"[\"keywords\"]#Low-rank-matrix-factorization","body":"A more space efficient technique for implementing PCA.\n"},"/machine-learning/keywords#Cold-start":{"id":"/machine-learning/keywords#Cold-start","title":"/machine-learning/keywords#Cold-start","tags":"[\"keywords\"]#Cold-start","body":"How to we handle new users and new items in colloborative filtering?\n"},"/machine-learning/keywords#Word-embeddings":{"id":"/machine-learning/keywords#Word-embeddings","title":"/machine-learning/keywords#Word-embeddings","tags":"[\"keywords\"]#Word-embeddings","body":"We represent words for NNs using a low-dimensional representation of real numbers.\n"},"/machine-learning/keywords#Word-word-co-occurrence-matrix":{"id":"/machine-learning/keywords#Word-word-co-occurrence-matrix","title":"/machine-learning/keywords#Word-word-co-occurrence-matrix","tags":"[\"keywords\"]#Word-word-co-occurrence-matrix","body":"We count the occurrence of words occurring together.\n"},"/machine-learning/keywords#Reduction":{"id":"/machine-learning/keywords#Reduction","title":"/machine-learning/keywords#Reduction","tags":"[\"keywords\"]#Reduction","body":"Reduction in machine learning means that we convert a complictated problem into a bunch of simpler problems.\n"},"/machine-learning/keywords#Part-of-speech-tagging":{"id":"/machine-learning/keywords#Part-of-speech-tagging","title":"/machine-learning/keywords#Part-of-speech-tagging","tags":"[\"keywords\"]#Part-of-speech-tagging","body":"Input a sequence of word tokens and output a sequence of grammatical tags corresponding to each token.\n"},"/machine-learning/keywords#Imitation-learning":{"id":"/machine-learning/keywords#Imitation-learning","title":"/machine-learning/keywords#Imitation-learning","tags":"[\"keywords\"]#Imitation-learning","body":"A paradigm in machine learning where the model tries to imitate an \"expert\".\n"},"/machine-learning/keywords#Feedforward-neural-network":{"id":"/machine-learning/keywords#Feedforward-neural-network","title":"/machine-learning/keywords#Feedforward-neural-network","tags":"[\"keywords\"]#Feedforward-neural-network","body":"Consists of connected layers of \"classifiers\" where intermediate classifiers are called hidden units and the final classifier is called output unit. Each hidden unit is computed by\n$$\nh_i = f(\\pmb w_{h_i} \\cdot \\pmb x)\n$$\nand the output is computed by\n$$\ny = f(\\pmb w_o \\cdot \\pmb h)\n$$\n$ f $ is the activation function.\n"},"/machine-learning/keywords#Multilayer-perceptron":{"id":"/machine-learning/keywords#Multilayer-perceptron","title":"/machine-learning/keywords#Multilayer-perceptron","tags":"[\"keywords\"]#Multilayer-perceptron","body":"See [Feedforward neural network](#Feedforward-neural-network).\n"},"/machine-learning/keywords#Recurrent-neural-networks":{"id":"/machine-learning/keywords#Recurrent-neural-networks","title":"/machine-learning/keywords#Recurrent-neural-networks","tags":"[\"keywords\"]#Recurrent-neural-networks","body":"They use states to represent previous events. After each step the state vector is recalculated.\n"},"/machine-learning/keywords#References":{"id":"/machine-learning/keywords#References","title":"/machine-learning/keywords#References","tags":"[\"keywords\"]#References","body":"{lossreg}:\n    url: https://medium.com/analytics-vidhya/a-comprehensive-guide-to-loss-functions-part-1-regression-ff8b847675d6\n{lossclass}:\n    url: https://medium.com/analytics-vidhya/common-loss-functions-in-machine-learning-for-classification-model-931cbf564d42\n{wikiinformationgain}:\n    url: https://en.wikipedia.org/wiki/Information_gain_in_decision_trees#Drawbacks\n"},"/machine-learning/linear-classifiers-regressors#":{"id":"/machine-learning/linear-classifiers-regressors#","title":"/machine-learning/linear-classifiers-regressors#","tags":"[]#","body":""},"/machine-learning/linear-classifiers-regressors#Linear-classifier":{"id":"/machine-learning/linear-classifiers-regressors#Linear-classifier","title":"/machine-learning/linear-classifiers-regressors#Linear-classifier","tags":"[]#Linear-classifier","body":""},"/machine-learning/linear-classifiers-regressors#Binary-linear-classifier":{"id":"/machine-learning/linear-classifiers-regressors#Binary-linear-classifier","title":"/machine-learning/linear-classifiers-regressors#Binary-linear-classifier","tags":"[]#Binary-linear-classifier","body":"A binary linear classifiers is defined as follows\n$$\nscore = \\pmb w \\cdot \\pmb x\n$$\nwhere $ \\pmb x $ is the feature vector we want to classify and $ \\pmb w $ is the vector which the classifier thinks is important. It will returns the first class if the score is greater than zero, else the other class. If a data set is linearly inseparable a linear classifier often has a hard time of optimal learning.\n"},"/machine-learning/linear-classifiers-regressors#Logistic-regression":{"id":"/machine-learning/linear-classifiers-regressors#Logistic-regression","title":"/machine-learning/linear-classifiers-regressors#Logistic-regression","tags":"[]#Logistic-regression","body":"The name is somewhat confusing because it is a classifier. It is a linear classifier that gives probabilistic scores. To get probabilites we need to use a @(logistic)(logistic) or @(sigmoid)(sigmoid) function\n$$\nP(\\text{positive output}|\\pmb x) = \\frac{1}{1 + e^{-score}}\n$$\n$$\nP(\\text{negative output}|\\pmb x) = 1 - \\frac{1}{1 + e^{-score}} = \\frac{1}{1 + e^{score}}\n$$\nIn a linear model with probabilites we can train the model by selecting features that assign a high probability to the data. Therefore, we need to adjust $ \\pmb w $ so that each our output label gets a high probability.\nFormally this is defined by the @(likelihood function)(likelihood-function)\n$$\n\\mathcal{L}(\\pmb w) = P(y_1|\\pmb x_1) \\cdots P(y_m|\\pmb x_m)\n$$\nwhich translate to\n$$\n\\mathcal{L}(\\pmb w) = \\frac{1}{1 + e^{-y_1 \\cdot (\\pmb w \\cdot \\pmb x_1)}} \\cdots \\frac{1}{1 + e^{-y_m \\cdot (\\pmb w \\cdot \\pmb x_m)}}\n$$\nin our case. We can convert this to the @(log loss)(log-loss) function by using log on each side.\n"},"/machine-learning/linear-classifiers-regressors#Multiclass-classification":{"id":"/machine-learning/linear-classifiers-regressors#Multiclass-classification","title":"/machine-learning/linear-classifiers-regressors#Multiclass-classification","tags":"[]#Multiclass-classification","body":"Two main ideas\n- break down the problem into simplier pieces and create a classifer for each piece\n- adjust the model to handle multiclass directly\nThere are two approaches we can use to convert a multiclass problem to a binary problem\n- one-versus-rest @{onevsrest}\n- one-versus-one @{onevsone}\nBuilt in classifiers like the perceptron or logistic regression will to this autoamtically (one-versus-rest).\nInstead of using the sigmoid we use the @(softmax)(softmax) function in the multiclass scenario.\n$$\nP(y_i|\\pmb x) = \\frac{e^{score_i}}{\\sum_k e^{score_k}}\n$$\nwhen training, instead of using the log loss we get the @(cross-entropy loss)(cross-entropy-loss) instead.\n"},"/machine-learning/linear-classifiers-regressors#Linear-regression":{"id":"/machine-learning/linear-classifiers-regressors#Linear-regression","title":"/machine-learning/linear-classifiers-regressors#Linear-regression","tags":"[]#Linear-regression","body":"Similarly like the linear classifier, a linear regression model calculate its score like this\n$$\ny = \\pmb w \\cdot \\pmb x\n$$\nwhere $ \\pmb x $ is the encoded feature vector and $ \\pmb w $ is the weights. The output $ y $ is now numerical.\nIn linear-squares regression with the error function\n$$\n\\pmb w^* =  \\arg \\min_{\\pmb w} \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\pmb w \\cdot \\pmb x_i)^2\n$$\nThe error function finds the weight vector that minmizes the squared error over the training set. For each training instance we look at the predicted value and calculate the distance of it between the labeled value.\nHowever this could be quite expensive which is why stochastic gradient descent is often used in practice. In stochastic gradient descent we consider just a single instance\n$$\nf_i(\\pmb w) = (\\pmb w \\cdot \\pmb x_i - y_i) ^ 2\n$$\nThus, the gradient of the least squared loss with respect to $ \\pmb w $ is\n$$\n\\nabla f_i (\\pmb w) = 2 \\cdot (\\pmb w \\cdot \\pmb x_i - y_i) \\cdot \\pmb x_i\n$$\n"},"/machine-learning/linear-classifiers-regressors#Keeping-the-model-simple":{"id":"/machine-learning/linear-classifiers-regressors#Keeping-the-model-simple","title":"/machine-learning/linear-classifiers-regressors#Keeping-the-model-simple","tags":"[]#Keeping-the-model-simple","body":"We can keep the model simple by adding a regularization term to the linear regression model. By adding this term we can keep the weights small. For example, by penalizing the squared length we achieve\n$$\n\\| \\pmb w \\| ^ 2 = w_1 \\cdot w_1 + \\ldots + w_n \\cdot w_n = \\pmb w \\cdot \\pmb w\n$$\nwhich is called a $ L_2 $ @(regularizer)(regularizer). Another common regularizer is\n$$\n\\| \\pmb w \\| = | w_1 | + \\ldots + | w_n |\n$$\nwhich is aclled a $ L_1 $ regularizer.\nIf we combine the loss function with the regularizer we get\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} \\text{Loss}(\\pmb w, \\pmb x_i, y_i) + \\alpha \\cdot \\text{Regularizer}(\\pmb w)\n$$\n"},"/machine-learning/linear-classifiers-regressors#Bias":{"id":"/machine-learning/linear-classifiers-regressors#Bias","title":"/machine-learning/linear-classifiers-regressors#Bias","tags":"[]#Bias","body":"A linear classifier could be expressed with a bias term and will in such cases look like this\n$$\nscore = \\pmb w \\cdot \\pmb x + b\n$$\nwhere $ b $ is the bias (often also called offset or intercept).\n"},"/machine-learning/linear-classifiers-regressors#Different-models":{"id":"/machine-learning/linear-classifiers-regressors#Different-models","title":"/machine-learning/linear-classifiers-regressors#Different-models","tags":"[]#Different-models","body":""},"/machine-learning/linear-classifiers-regressors#Classifiers":{"id":"/machine-learning/linear-classifiers-regressors#Classifiers","title":"/machine-learning/linear-classifiers-regressors#Classifiers","tags":"[]#Classifiers","body":"- perceptron\n- logistic regression\n"},"/machine-learning/linear-classifiers-regressors#Regressors":{"id":"/machine-learning/linear-classifiers-regressors#Regressors","title":"/machine-learning/linear-classifiers-regressors#Regressors","tags":"[]#Regressors","body":"- linear regression @{linearreg} (no regularization)\n- ridge @{ridge} (the combination of least squares loss with $ L_2 $ regularization)\n- lasso @{lasso} (the combination of least squares loss with $ L_1 $ regularization)\n- linear SVR @{svr}\n"},"/machine-learning/linear-classifiers-regressors#References":{"id":"/machine-learning/linear-classifiers-regressors#References","title":"/machine-learning/linear-classifiers-regressors#References","tags":"[]#References","body":"{onevsrest}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\n{onevsone}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html\n{linearreg}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n{ridge}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n{lasso}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n{svr}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html\n"},"/machine-learning/machine-learning#":{"id":"/machine-learning/machine-learning#","title":"/machine-learning/machine-learning#","tags":"[]#","body":"https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786\n- Perceptron\n@{perceptron}\n- Convolutional Neural Networks\n@{convolution}\n@{convolution1998}\n- Recurrent Neural Networks\n@{rnn}\n- Long / Short Term Memory\n@{lstm}\n- Gated Recurrent Unit\n@{gru}\n- Hopfiled Network\n@{hop}\n- Boltzmann Machine\n@{boltz1}\n@{boltz2}\n- Deep Belief Networks\n@{deep}\n- Autoencoders\n@{auto}\n- Generative Adversarial Networks\n@{gan}\n"},"/machine-learning/machine-learning#References":{"id":"/machine-learning/machine-learning#References","title":"/machine-learning/machine-learning#References","tags":"[]#References","body":"{perceptron}:\n    author: F. ROSENBLATT\n    year: 1958\n    title: THE   PERCEPTRON:   A  PROBABILISTIC  MODEL  FORINFORMATION   STORAGE  AND  ORGANIZATION IN  THE  BRAIN\n    url: https://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf\n{convolution}:\n    url:http://yann.lecun.com/exdb/lenet/\n{convolution1998}:\n    author: Yann LeCun\n    year: 1998\n    title: Gradient-Based Learning Applied to Document Recognition\n    url: http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf\n{rnn}:\n    author: Jeffrey L. Elman\n    year: 1990\n    title: Finding Structure in Time\n    url: https://crl.ucsd.edu/~elman/Papers/fsit.pdf\n{lstm}:\n    author: Sepp Hochreiter and Jurgen Schimidhuber\n    year: 1997\n    title: Long Short-Term Memory\n    url: https://www.bioinf.jku.at/publications/older/2604.pdf\n{gru}:\n    url: https://arxiv.org/pdf/1412.3555v1.pdf\n{hop}:\n    url: https://bi.snu.ac.kr/Courses/g-ai09-2/hopfield82.pdf\n{boltz1}:\n    url: https://papers.cnl.salk.edu/PDFs/Learning%20and%20Relearning%20in%20Boltzmann%20Machines%201986-3239.pdf\n{boltz2}:\n    url: http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf\n{deep}:\n    url: https://papers.nips.cc/paper/2006/file/5da713a690c067105aeb2fae32403405-Paper.pdf\n{auto}:\n    url: https://www.semanticscholar.org/paper/Auto-association-by-multilayer-perceptrons-and-Bourlard-Kamp/f5821548720901c89b3b7481f7500d7cd64e99bd\n{gan}:\n    url: https://arxiv.org/pdf/1406.2661v1.pdf\n"},"/machine-learning/neural-networks#":{"id":"/machine-learning/neural-networks#","title":"/machine-learning/neural-networks#","tags":"[]#","body":"Neural networks are systems that are very useful for automatic learning of abstractions. Before neural network models were popular there were complicated machine learning pipelines which needed complex preprocessing transformation steps.\n"},"/machine-learning/neural-networks#Pros":{"id":"/machine-learning/neural-networks#Pros","title":"/machine-learning/neural-networks#Pros","tags":"[]#Pros","body":"- A neural network model can express more complex relationships e.g. linear models\n- They are better for problems where it is hard to define features, e.g. images.\n"},"/machine-learning/neural-networks#Cons":{"id":"/machine-learning/neural-networks#Cons","title":"/machine-learning/neural-networks#Cons","tags":"[]#Cons","body":"- The training process could be very demanding (because of structure and lots of training data)\n- They can be difficult to train because of the quantity of hyperparameters\n- Finding a solution may require luck because the training is less mathematical stable\n"},"/machine-learning/neural-networks#Linear-model-limitions":{"id":"/machine-learning/neural-networks#Linear-model-limitions","title":"/machine-learning/neural-networks#Linear-model-limitions","tags":"[]#Linear-model-limitions","body":"Some data sets can not be modeled with a linear classifier, a data set must be linearly separable to give perfect classifiction. Linear classifiers have problems predicting the XOR problem. To overcome this we can introduce more features and by applying some nonlinear transformation we can move the output space of the classes to a more or less linearly separable form.\n"},"/machine-learning/neural-networks#Where-neural-networks-enter-the-scene":{"id":"/machine-learning/neural-networks#Where-neural-networks-enter-the-scene","title":"/machine-learning/neural-networks#Where-neural-networks-enter-the-scene","tags":"[]#Where-neural-networks-enter-the-scene","body":"Instead of handcrafting new features to make the problem more linear separable, we could train a classifer using the output of previous \"sub-classifiers\", neurons.\n"},"/machine-learning/neural-networks#Multilayered-model":{"id":"/machine-learning/neural-networks#Multilayered-model","title":"/machine-learning/neural-networks#Multilayered-model","tags":"[]#Multilayered-model","body":"A feedforward neural network consists of connected layers where intermediate nodes are placed in a hidden layer and called hidden neurons. The final layer is the classifier or regressor and is called the output layer where the nodes are output nodes. The first layer is the input layer where the nodes are called the input nodes.\nEach hidden node compute its output based on its own weight vector\n$$\nh_i = f(\\pmb w_{h_i} \\cdot \\pmb x)\n$$\nand the output nodes are computed in a similar fashion, but based on the outputs of the hidden nodes\n$$\ny = f(\\pmb w_o \\cdot \\pmb h)\n$$\nThe function $ f $ is called the @(activation)(activation).\nA neural network learns the nonlinear transformation, and creates a new vector space where the classes are linearly separable. It is the hidden layers that accomplish this.\n"},"/machine-learning/neural-networks#Training":{"id":"/machine-learning/neural-networks#Training","title":"/machine-learning/neural-networks#Training","tags":"[]#Training","body":"Training a neural network consists of finding the optimal weights of each layer, similarly like the linear models. The process consists of an objective function including a loss and possibly a regularizer as well and an optimization algorithm is applied to find the weights that minimizes the objective.\nIf we have the simple neural network like follows\n$$\nh = f_1(w_1 \\cdot x)\n$$\n$$\n\\text{Loss} = f_2(w_2 \\cdot h)\n$$\nwe can compute the gradients with respect to $ w_1 $ and $ w_2 $ using the chain rule like\n$$\n\\frac{\\partial \\text{Loss}}{\\partial w_2} = f_2^{'}(w_2 \\cdot h) \\cdot h\n$$\n$$\n\\frac{\\partial \\text{Loss}}{\\partial w_1} = f_2^{'}(w_2 \\cdot h) \\cdot w_2 \\cdot f_1^{'}(w_1 \\cdot x) \\cdot x\n$$\n"},"/machine-learning/optimization#":{"id":"/machine-learning/optimization#","title":"/machine-learning/optimization#","tags":"[]#","body":""},"/machine-learning/optimization#Optimization-problems":{"id":"/machine-learning/optimization#Optimization-problems","title":"/machine-learning/optimization#Optimization-problems","tags":"[]#Optimization-problems","body":"There are two main types of problems\n- unconstrained optimization\n- constrained optimization\nIn machine learning many of the problems are of the first type.\n"},"/machine-learning/optimization#Unconstrained-optimization":{"id":"/machine-learning/optimization#Unconstrained-optimization","title":"/machine-learning/optimization#Unconstrained-optimization","tags":"[]#Unconstrained-optimization","body":"In unconstrained optimization we try to find the $ x $ that gives us the minimal or maximal value for some function $ f $ like\n$$\n\\min_{x} f(x)\n$$\n"},"/machine-learning/optimization#Constrained-optimization":{"id":"/machine-learning/optimization#Constrained-optimization","title":"/machine-learning/optimization#Constrained-optimization","tags":"[]#Constrained-optimization","body":"In constrained optimization we try to find the $ x $ that gives us the minimal or maximal value for some function $ f $ where $ x $ needs to satisfy some additional conditions like\n$$\n\\min_{x} f(x) \\qquad x \\geq 0\n$$\n"},"/machine-learning/optimization#Gradient-decent":{"id":"/machine-learning/optimization#Gradient-decent","title":"/machine-learning/optimization#Gradient-decent","tags":"[]#Gradient-decent","body":"The idea of gradient decent is that we should take a small step in the direction opposite of the gradient and repeat until the gradient is close to zero. We need to walk in the opposite direction because the gradient will give us the direction of the steepest ascent.\nThe algorithm could be explained in the following pseudocode\n1. set $ x $ to some intial value and select a learning rate $ \\eta $\n2. compute the gradient $ \\nabla f(x) $\n3. if $ \\nabla f(x) $ is close to zero, terminate\n4. else subract the learning rate $ \\eta \\cdot \\nabla f(x) $ from $ x $ and go back to step 2.\nWe will always reach a minimum or maximum if\n- there is a top\n- the steps are short enough\nThere are smarter versions of gradient as well that try to adapt its step size depending on how fast it is going or for have many steps it has already taken. One simple solution which is smarter than the ordinary gradient decent is to start fast with gradually slower steps.\nGradient decent will not make sure that we find the global minimum/maximum but make sure we reach a minimum/maximum global or local if there exists one.\n"},"/machine-learning/optimization#Stochastic-gradient-descent":{"id":"/machine-learning/optimization#Stochastic-gradient-descent","title":"/machine-learning/optimization#Stochastic-gradient-descent","tags":"[]#Stochastic-gradient-descent","body":"Because the gradient depend on every instance in the training set it can be quite expensive to calculate. Thus, a simplified version that onlu computes parts of the training set are used in practice called stochastic gradient descent.\nThe algorithm could be explained in the following pseudocode\n1. set $ w $ to some intial value and select a learning rate $ \\eta $\n2. select a single training sample $ x $\n3. compute the gradient $ \\nabla f(w) $ using $ x $\n4. if $ \\nabla f(w) $ is \"done\"\n5. else subract the learning rate $ \\eta \\cdot \\nabla f(w) $ from $ w $ and go back to step 2.\nPoint four above gives rise to some questions, namely what does \"done\" mean. In gradient descent we stop the iteration process when the gradient is close to zero. In stochastic gradient descent, close to zero does not mean the same thing because we are looking at a small sample of instances which very well could be zero unlike the whole training set. There are a few solutions to this, namely have a fixed number of iterations, stop when we have not seen any improvements for some time, or evaluate the model on some set which determines if we should terminate (early stopping)\n"},"/machine-learning/paradigms#":{"id":"/machine-learning/paradigms#","title":"/machine-learning/paradigms#","tags":"[]#","body":""},"/machine-learning/paradigms#Supervised-learning":{"id":"/machine-learning/paradigms#Supervised-learning","title":"/machine-learning/paradigms#Supervised-learning","tags":"[]#Supervised-learning","body":"Our model tries to imitate examples.\n"},"/machine-learning/paradigms#Unsupervised-learning":{"id":"/machine-learning/paradigms#Unsupervised-learning","title":"/machine-learning/paradigms#Unsupervised-learning","tags":"[]#Unsupervised-learning","body":"In unsupervised learning we do not have the labeled parts. In unsupervised learning we try to discover some patterns about the data: explore, visualize and understand.\nStanford has a good guide @{stanford}.\n"},"/machine-learning/paradigms#Clustering":{"id":"/machine-learning/paradigms#Clustering","title":"/machine-learning/paradigms#Clustering","tags":"[]#Clustering","body":"Clustering @{clusteringwiki} @{clustering} describes data by forming it into groups or hierarchies. The goal of clustering is to discover natural groups in a data set. A natural group is data points which are very much alike but different from other groups. Clustering is hard, because we don't there is typically no right answer and the clustering algorithm may come up with some pattern that is obvious in the dataset but is far from we want.\nTo evaluate similarity there are some different options. For vectorized data it is common to use Euclidean distance. We can divide clustering evaluation into two separate methods: internal and external. Internal evaluation will evaluate how cohesive and well-separated the data points in the cluster are and external evaluation will evaluate how well the algorithm performs to our objective. Is this clustering what we want?\n"},"/machine-learning/paradigms#Flat":{"id":"/machine-learning/paradigms#Flat","title":"/machine-learning/paradigms#Flat","tags":"[]#Flat","body":"- $ Finding \\space representatives $ Each cluster is characterized by a center. We can used different techniques, e.g. @(k-means)(k-means), @(k-medoids)(k-medoids) or @(mean shift)(mean shift), to get a center vector.\n- $ Probabilistic \\space approach $\nEach cluster is represented by a distribution.\n- $ Dense \\space approach $\nFind dense regions with algorithms like @(DBSCAN)(DBSCAN)\n"},"/machine-learning/paradigms#K-means":{"id":"/machine-learning/paradigms#K-means","title":"/machine-learning/paradigms#K-means","tags":"[]#K-means","body":"The formal definition of K-means is to find a partition $ S $ of the dataset, that minimizes the the loss function\n$$\nL(s) = \\sum_{k=1}^K \\sum_{x_i \\in S_k} || x_i - \\text{centroid}(S_k) ||^2\n$$\nwhich is called the residual sum of squares. Finding the partition is NP-hard unfortunately. We use @(Lloyd's algorithm)(lloyd's-algorithm) instead which approximate a solution. It will reach a steady state if iterating for enough cycles. The scikit-learn implementation @{kmeans}.\nHow to we choose the number of clusters?\n- use our specific knowledge about the domain we are working with\n- use approximation methods, e.g. @(the elbow method)(the-elbow-method)\n- apply an evaluation method\n- use some regularization for the loss function\n"},"/machine-learning/paradigms#DBSCAN":{"id":"/machine-learning/paradigms#DBSCAN","title":"/machine-learning/paradigms#DBSCAN","tags":"[]#DBSCAN","body":"In comparison to the k-means cluster method which is in the family of representatives, DBSCAN just operates on raw data points and is in the family of density-based clustering methods. DBSCAN will look for the distances (any kind of distance measure) between data points and how close they are too each other. The algorithm is based on core points and outliers. We could for example say that a core point is a point with 4 points withing reachable range, and any outliers are points that are not reachable from any other points.\nSome advantage over the k-means method is that we don't need to define the number of cluster we want, DBSCAN does not have any assumption about the shape of each cluster, DBSCAN can use any kind of distance metric, and DBSCAN may create noise points. However, DBSCAN is very sensitive to hyperparameter tuning and works poorly if the clusters differ in density.\n"},"/machine-learning/paradigms#Evaluation":{"id":"/machine-learning/paradigms#Evaluation","title":"/machine-learning/paradigms#Evaluation","tags":"[]#Evaluation","body":"How does one evaluate these types of approaches? The silhoutte score is one method.\n"},"/machine-learning/paradigms#Silhoutte-score":{"id":"/machine-learning/paradigms#Silhoutte-score","title":"/machine-learning/paradigms#Silhoutte-score","tags":"[]#Silhoutte-score","body":"The silhoutte score is defined like\n$$\ns_i = \\frac{b_i - a_i}{\\max (a_i, b_i)}\n$$\nwhere $ a_i $ is the average distance to other data points in the same cluster and $ b_i $ is the minimal average distance to another cluster.\n"},"/machine-learning/paradigms#Purity-score":{"id":"/machine-learning/paradigms#Purity-score","title":"/machine-learning/paradigms#Purity-score","tags":"[]#Purity-score","body":"The purity score defines how pure each cluster is in relation to some standard class. It looks like\n$$\n\\text{Purity} = \\frac{1}{N} \\sum_{k=1}^K \\max_{i = 1}^{|C|} | S_k \\cap C_i |\n$$\nOne drawback of this approach is when we put every individual in its own cluster. Then we will get a purity of one.\n"},"/machine-learning/paradigms#Inverse-purity-score":{"id":"/machine-learning/paradigms#Inverse-purity-score","title":"/machine-learning/paradigms#Inverse-purity-score","tags":"[]#Inverse-purity-score","body":"$$\n\\text{Invserse Purity} = \\frac{1}{N} \\sum_{i=1}^{|C|} \\max_{k = 1}^{K} | S_k \\cap C_i |\n$$\n"},"/machine-learning/paradigms#F-score":{"id":"/machine-learning/paradigms#F-score","title":"/machine-learning/paradigms#F-score","tags":"[]#F-score","body":"The @(F-score)(f-score) @{f-score} tries to be a balance of the purity score and the inverse purity score.\n"},"/machine-learning/paradigms#Hierarchical":{"id":"/machine-learning/paradigms#Hierarchical","title":"/machine-learning/paradigms#Hierarchical","tags":"[]#Hierarchical","body":"There are two approaches, @(applomerative)(agglomerative) which is bottom-up and @(divisive)(divisive) which is top-down.\n"},"/machine-learning/paradigms#Statistical-distribution":{"id":"/machine-learning/paradigms#Statistical-distribution","title":"/machine-learning/paradigms#Statistical-distribution","tags":"[]#Statistical-distribution","body":"We want to use our model to find data points that are highly unusual.\n"},"/machine-learning/paradigms#Representation":{"id":"/machine-learning/paradigms#Representation","title":"/machine-learning/paradigms#Representation","tags":"[]#Representation","body":"We want to learn some new representation of the data, e.g. reducing the data set to lower dimensions.\nIt is good for visualization, and reducing the need for storage which makes the algorithm run faster and the learning easier.\n"},"/machine-learning/paradigms#Semisupervised-learning":{"id":"/machine-learning/paradigms#Semisupervised-learning","title":"/machine-learning/paradigms#Semisupervised-learning","tags":"[]#Semisupervised-learning","body":"Follows the same patterns as supervised learning, but we just don't have enough labeled data.\n"},"/machine-learning/paradigms#Reinforcement-learning":{"id":"/machine-learning/paradigms#Reinforcement-learning","title":"/machine-learning/paradigms#Reinforcement-learning","tags":"[]#Reinforcement-learning","body":""},"/machine-learning/paradigms#References":{"id":"/machine-learning/paradigms#References","title":"/machine-learning/paradigms#References","tags":"[]#References","body":"{stanford}:\n    title: Welcome to the Deep Learning Tutorial\n    author: Andrew Ng et al\n    url: http://ufldl.stanford.edu/tutorial/\n{clusteringwiki}:\n    url: https://en.wikipedia.org/wiki/Cluster_analysis\n{clustering}:\n    url: https://scikit-learn.org/stable/modules/clustering.html\n{kmeans}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n{f-score}:\n    url: https://en.wikipedia.org/wiki/F-score\n"},"/machine-learning/preprocessing#":{"id":"/machine-learning/preprocessing#","title":"/machine-learning/preprocessing#","tags":"[]#","body":""},"/machine-learning/preprocessing#Feature-preprocessing":{"id":"/machine-learning/preprocessing#Feature-preprocessing","title":"/machine-learning/preprocessing#Feature-preprocessing","tags":"[]#Feature-preprocessing","body":"An important concept of machine learning like many other problems there is some sort of \"garbage in, garbage out\". Machine learning may seems to magically classify data and solve all sorts of problems but if the data you put in to a machine learning model are out of context you can expect the model to perform out of context as well. One example is to have a very easy feature representation of an image (100x100) where you put every pixel into a 30.000 dimensional vector (three values for every pixel). In doing so we lose all locality information. It is therefore an important aspect to consider when designing learning models, i.e. how robust they are to noisy features. Redundant features is not good either (two features are redudant if they are highly correlated). It is as well important to observe that when the training sample N is small the chance of getting seeminly correlated data is increased even though the data are independent.\nGenerally we need to do some preprocessing for categorical values in a data set, because almost every library uses numerical values. One-hot encoding is a very common way of dealing with categorical values and converting them to numerical ones. A direct integer encoding tends to work poorly in machine learning algorithms. We would give mathematical properties to each value even though there are none. It would create an unnecessary ordering which may mislead the machine learning algorithm.\nMagnitude differences can be a problem, but that depends on which machine learning algorithm that is used. It usually ***strongly*** affects many models like linear models,  neural networks, models based on distance or similarity (kNN, SVC, etc...). However, tree-based predictors will ignore any scaling differences (they will adapt to the new scaling), because they consider thresholds of one feature at a time.\nScikit-learn provides a number of ways to preprocess the data @{sklearn}.\n"},"/machine-learning/preprocessing#Pruning":{"id":"/machine-learning/preprocessing#Pruning","title":"/machine-learning/preprocessing#Pruning","tags":"[]#Pruning","body":"The principle of pruning is as follows, if you have a binary feature that only appears a small number of times $ K $ you can simply remove them from consideration. You have to be careful to not overuse the technique of pruning because before we end up with no interesting data. @(Normalization)(normalization) is also important.\n"},"/machine-learning/preprocessing#Scaling-and-normalization":{"id":"/machine-learning/preprocessing#Scaling-and-normalization","title":"/machine-learning/preprocessing#Scaling-and-normalization","tags":"[]#Scaling-and-normalization","body":""},"/machine-learning/preprocessing#Min-Max-scaling":{"id":"/machine-learning/preprocessing#Min-Max-scaling","title":"/machine-learning/preprocessing#Min-Max-scaling","tags":"[]#Min-Max-scaling","body":"Sqeeze the scale so that it is between zero and one.\n$$\nf_{new} = \\frac{f - f_{min}}{f_{max} - f_{min}}\n$$\n"},"/machine-learning/preprocessing#Standard-scaling":{"id":"/machine-learning/preprocessing#Standard-scaling","title":"/machine-learning/preprocessing#Standard-scaling","tags":"[]#Standard-scaling","body":"Use mean value and standard deviation to scale. After this transformation the mean value will be zero and the standard deviation will be one.\n$$\nf_{new} = \\frac{f - \\overline f}{\\sigma f}\n$$\n"},"/machine-learning/preprocessing#Length-normalization":{"id":"/machine-learning/preprocessing#Length-normalization","title":"/machine-learning/preprocessing#Length-normalization","tags":"[]#Length-normalization","body":"The length of the feature vector will be one after this transformation.\n$$\nx_{new} = \\frac{x}{| x |}\n$$\n"},"/machine-learning/preprocessing#Other-transformations":{"id":"/machine-learning/preprocessing#Other-transformations","title":"/machine-learning/preprocessing#Other-transformations","tags":"[]#Other-transformations","body":"We may try logarithms, square root, etc...\n"},"/machine-learning/preprocessing#Missing-values":{"id":"/machine-learning/preprocessing#Missing-values","title":"/machine-learning/preprocessing#Missing-values","tags":"[]#Missing-values","body":"If there are missing values in some data row or column, we could just remove those instances. This is considered the brute force approach and will work fine if we have a lot of data. A more sophisticated method is @(feature imputation)(feature-imputation).\n"},"/machine-learning/preprocessing#Evaluating":{"id":"/machine-learning/preprocessing#Evaluating","title":"/machine-learning/preprocessing#Evaluating","tags":"[]#Evaluating","body":"It is very fair to say that achieving a high accuracy for a model is you want in most cases, however, in some cases it is better to let a little \"bad\" data through. For spotting problems (X versus not-X) there are better success with a metrics of precision/recall instead of accuracy for this reason. Thus, having a metric producing confidence is probably better in these cases.\n"},"/machine-learning/preprocessing#Debugging":{"id":"/machine-learning/preprocessing#Debugging","title":"/machine-learning/preprocessing#Debugging","tags":"[]#Debugging","body":"- Generalization of test data\n- Train/test data mismatch\n- The learning algorithm\n- Adequate representation\n- Enough data\n"},"/machine-learning/preprocessing#References":{"id":"/machine-learning/preprocessing#References","title":"/machine-learning/preprocessing#References","tags":"[]#References","body":"{sklearn}:\n    title: Preprocessing data\n    url: https://scikit-learn.org/stable/modules/preprocessing.html\n{stdscalar}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n{minmaxscalar}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n"},"/machine-learning/models/CNN#":{"id":"/machine-learning/models/CNN#","title":"/machine-learning/models/CNN#","tags":"[]#","body":"Convolutional neural networks are mainly used for images but works for other kinds of patterns as well. Linear models have a hard time modeling the interactions between features in images; decision trees and tree ensembles do a better job but they need to be very big to achieve good results. We need to find some better solution. This is where CNNs come in.\n"},"/machine-learning/models/CNN#Building-blocks":{"id":"/machine-learning/models/CNN#Building-blocks","title":"/machine-learning/models/CNN#Building-blocks","tags":"[]#Building-blocks","body":"- **convolutinal filters**: used to find patterns\n- **pooling**: used for summarizing or generalizing smaller regions\n- **fully connected layers**\n- **dense layers**\n- **redidual connections**\n- **normalizations**\n"},"/machine-learning/models/CNN#Convolutional-filters":{"id":"/machine-learning/models/CNN#Convolutional-filters","title":"/machine-learning/models/CNN#Convolutional-filters","tags":"[]#Convolutional-filters","body":"Consists of an image and a kernel and results in a feature map. The kernel sweeps over the image and extracts important information and produces a feature map of the results.\n"},"/machine-learning/models/CNN#Pooling":{"id":"/machine-learning/models/CNN#Pooling","title":"/machine-learning/models/CNN#Pooling","tags":"[]#Pooling","body":"Pooling will shrink the region space. The most common pooling technique is max pooling @{pooling}.\n"},"/machine-learning/models/CNN#Transfer-learning":{"id":"/machine-learning/models/CNN#Transfer-learning","title":"/machine-learning/models/CNN#Transfer-learning","tags":"[]#Transfer-learning","body":"The general idea behind transfer learning is that we want to exploit previously learning knowledge to solve new tasks. Thus, we reuse some parts of an earlier model because it can reduce the need for training data for the new task. One common way to do this is in neural networks is to take the weights from the first model and put them in the second model. We start by training some general model to further train on a new specific task. We keep the lower level layers and replace the higher level layers. We can except a good transer learning if the specific task it very similar to the general task.\n"},"/machine-learning/models/CNN#References":{"id":"/machine-learning/models/CNN#References","title":"/machine-learning/models/CNN#References","tags":"[]#References","body":"{pooling}:\n    url: https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer\n"},"/machine-learning/models/LSTM#":{"id":"/machine-learning/models/LSTM#","title":"/machine-learning/models/LSTM#","tags":"[]#","body":"The general idea when working with sequences is to break down the problem into a smaller decisions.\nLSTM blog post @{colah}.\n"},"/machine-learning/models/LSTM#References":{"id":"/machine-learning/models/LSTM#References","title":"/machine-learning/models/LSTM#References","tags":"[]#References","body":"{colah}:\n    author: Christopher Olah\n    title: Understanding LSTM Networks\n    year: 2015\n    url: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"},"/machine-learning/models/decision-tree#":{"id":"/machine-learning/models/decision-tree#","title":"/machine-learning/models/decision-tree#","tags":"[]#","body":""},"/machine-learning/models/decision-tree#What-is-a-decision-tree?":{"id":"/machine-learning/models/decision-tree#What-is-a-decision-tree?","title":"/machine-learning/models/decision-tree#What-is-a-decision-tree?","tags":"[]#What-is-a-decision-tree?","body":"Decision tree @{wiki} is a classic model of learning and well suited for binary classification. The decision tree is made up of guesses where each node represents a guess and the path to each node the binary decision. Each non-terminal node has two children which corresponds to answering \"no\" or \"yes\". The questions can be seen as **_features_** and the rating is called the **_label_**. Decision trees can output probabilities as well.\nScikit-learn has decision tree models @{sklearn} @{sklearnc} @{sklearnr}.\n"},"/machine-learning/models/decision-tree#The-learning-algorithm":{"id":"/machine-learning/models/decision-tree#The-learning-algorithm","title":"/machine-learning/models/decision-tree#The-learning-algorithm","tags":"[]#The-learning-algorithm","body":"The learning algorithm can be simplified to:\n- select the best feature F that corresponds to the best split (creating subsets)\n- create a (sub)tree with F as the root\n- repeat\nTo not get an infinite recursion loop we have some base cases like checking similarity in each subset, checking max depth, etc.\n"},"/machine-learning/models/decision-tree#Best-split":{"id":"/machine-learning/models/decision-tree#Best-split","title":"/machine-learning/models/decision-tree#Best-split","tags":"[]#Best-split","body":"It is best to split each set into homogeneous (little varaiation) subsets. There are a couple of techniques for determining the homogeneity of one set, for classification the most popular are: information gain or the gini score and for regression we can consider the variance (a subset with small variance).\n"},"/machine-learning/models/decision-tree#Drawbacks":{"id":"/machine-learning/models/decision-tree#Drawbacks","title":"/machine-learning/models/decision-tree#Drawbacks","tags":"[]#Drawbacks","body":"Decision trees tend to overfit and thus produce bad generalizations. They are usually not useful on their own because of this. However when used in ensembles e.g. in the popular model random forests they perform well.\n"},"/machine-learning/models/decision-tree#References":{"id":"/machine-learning/models/decision-tree#References","title":"/machine-learning/models/decision-tree#References","tags":"[]#References","body":"{wiki}:\n    title: Decision tree\n    url: https://en.wikipedia.org/wiki/Decision_tree\n{sklearn}:\n    title: Decision Trees\n    url: https://scikit-learn.org/stable/modules/tree.html\n{sklearnc}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n{sklearnr}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n"},"/machine-learning/models/ensembles#":{"id":"/machine-learning/models/ensembles#","title":"/machine-learning/models/ensembles#","tags":"[]#","body":""},"/machine-learning/models/ensembles#What-is-an-ensemble?":{"id":"/machine-learning/models/ensembles#What-is-an-ensemble?","title":"/machine-learning/models/ensembles#What-is-an-ensemble?","tags":"[]#What-is-an-ensemble?","body":"Ensembles @{wiki} are machine learning models that combine several other models. Ensembles often have great accuracy. If an ensemble is built by many different classifiers each with an accuracy of 0.6. The errors of each model are independent. Thus, there is a greater probability that the classifiers (because of diversity) can complement each other. It is often not very realistic to assume that the errors are independent .\nAn ensemble could use the average of all the different models as the final prediction value. It could also use a technique called @(stacking)(stacking).\nScikit-learn has many useful methods for managing ensembles @{sklearn}.\n"},"/machine-learning/models/ensembles#Training":{"id":"/machine-learning/models/ensembles#Training","title":"/machine-learning/models/ensembles#Training","tags":"[]#Training","body":"One idea is called @(bagging)(bagging). In that approach we take the original training set and sample from it. Thus, we get a number of new training sets. It is normally done with replacement which may result in one instance ending up many times in the new sample or not at all. Another useful techique is called @(spinning)(spinning). It craetes new training sets by randomly picking subsets of features. This is often done without replacement. We could combine both ideas.\n"},"/machine-learning/models/ensembles#Boosting":{"id":"/machine-learning/models/ensembles#Boosting","title":"/machine-learning/models/ensembles#Boosting","tags":"[]#Boosting","body":"There are two popular boosting algorithms, @(AdaBoost)(adaboost) and @(gradient boosting)(gradientboosting), where AdaBoost being the most popular. Both are supported by Scikit-learn @{adaboost} @{gradientboostingc} @{gradientboostingr}. AdaBoost works by giving each instances which are misclassified a higher importance after each iteration before the next one. Unlike bagging, we may overfit the model if we add more trees to a boosting algorithm.\n"},"/machine-learning/models/ensembles#References":{"id":"/machine-learning/models/ensembles#References","title":"/machine-learning/models/ensembles#References","tags":"[]#References","body":"{wiki}:\n    title: Ensemble learning\n    url: https://en.wikipedia.org/wiki/Ensemble_learning\n{sklearn}:\n    title: Ensemble methods\n    url: https://scikit-learn.org/stable/modules/ensemble.html\n{adaboost}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n{gradientboostingc}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n{gradientboostingr}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n"},"/machine-learning/models/random-forests#":{"id":"/machine-learning/models/random-forests#","title":"/machine-learning/models/random-forests#","tags":"[]#","body":""},"/machine-learning/models/random-forests#What-is-random-forests?":{"id":"/machine-learning/models/random-forests#What-is-random-forests?","title":"/machine-learning/models/random-forests#What-is-random-forests?","tags":"[]#What-is-random-forests?","body":"Random forests @{wiki} have very similar performance compared to boosting on many problems, but they are easier to train and tune. Trees are usually noisy which is why @(bagging)(bagging) comes in handy. Each tree is identically distributed in bagging. The @(bias)(bias) of the bagged trees will because of that have the same value as the individual trees.\nRandom forests main idea is to improve the variance reduction by reducing the correlation between the trees it is built upon. By letting trees grow through a process of random selection of the input variables this can be achieved.\nRandom forests and tree based models in general have little need for feature normalization. Random forests often work well without complicated setup and provides more robust results than a single decision tree. They work very well for tabulated data but not images, signals or text. They can be computationally heavy depending on how many different trees they are made up of, and are obviously more computationally heavy than a single decision tree. They are as well not as easy to interpret as single decision trees.\nScikit-learn has a random forest classifier @{sklearnc} and a random forest regressor @{sklearnr}.\n"},"/machine-learning/models/random-forests#The-learning-algorithm":{"id":"/machine-learning/models/random-forests#The-learning-algorithm","title":"/machine-learning/models/random-forests#The-learning-algorithm","tags":"[]#The-learning-algorithm","body":"Each tree in the ensemble is trained on its own training set through the technique bagging. Instead of consider all the possible features of the data set we only consider a subset, typically $ \\sqrt{|F_{total}|} $, when we are building a tree branch.\n"},"/machine-learning/models/random-forests#Prediction":{"id":"/machine-learning/models/random-forests#Prediction","title":"/machine-learning/models/random-forests#Prediction","tags":"[]#Prediction","body":"For regression we use the average value as the output.\nFor classification we use voting or averaging of the probabilities as output.\n"},"/machine-learning/models/random-forests#Hyperparameters":{"id":"/machine-learning/models/random-forests#Hyperparameters","title":"/machine-learning/models/random-forests#Hyperparameters","tags":"[]#Hyperparameters","body":"We can choose how many trees we want our model to consist of. More trees result in a slower model but more accurate because we take advantage of the fundamental idea of ensembles in relation to decision trees. We can also choose how many features we should consider when we build new tree nodes. The standard hyperparameters for decision trees apply here as well.\n"},"/machine-learning/models/random-forests#References":{"id":"/machine-learning/models/random-forests#References","title":"/machine-learning/models/random-forests#References","tags":"[]#References","body":"{wiki}:\n    title: Random forest\n    url: https://en.wikipedia.org/wiki/Random_forest\n{sklearnc}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n{sklearnr}:\n    url: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n"},"/machine-learning/models/support-vector-machine#":{"id":"/machine-learning/models/support-vector-machine#","title":"/machine-learning/models/support-vector-machine#","tags":"[]#","body":"A support vector machine (SVM) or support vector classifiers (SVC) maximizes the margin by selecting an appropriate weight vector $ \\pmb w $.\n"},"/math/bayesian-inference#":{"id":"/math/bayesian-inference#","title":"/math/bayesian-inference#","tags":"[]#","body":""},"/math/bayesian-inference#Notation":{"id":"/math/bayesian-inference#Notation","title":"/math/bayesian-inference#Notation","tags":"[]#Notation","body":""},"/math/bayesian-inference#Bayes'-theorem":{"id":"/math/bayesian-inference#Bayes'-theorem","title":"/math/bayesian-inference#Bayes'-theorem","tags":"[]#Bayes'-theorem","body":"Given Bayes formula\n$$\n\\pi(\\theta\\mid y)=\\frac {\\pi(y\\mid \\theta)\\pi(\\theta)}{\\pi(y)}=\\frac {\\pi(y\\mid \\theta)\\pi(\\theta)}{\\int_\\theta \\pi(y\\mid \\theta)\\pi(\\theta) d\\theta}\n$$\nwe we define four different names representing each term: **prior**, **posterior**, **likelihood** and **marginal likelihood**.\n"},"/math/bayesian-inference#Prior":{"id":"/math/bayesian-inference#Prior","title":"/math/bayesian-inference#Prior","tags":"[]#Prior","body":"$$\n\\pi (\\theta)\n$$\nThe prior distribution represents our knowledge about our uncertain quantity (parameters) **before** some evidence is taken into account.\n"},"/math/bayesian-inference#Posterior":{"id":"/math/bayesian-inference#Posterior","title":"/math/bayesian-inference#Posterior","tags":"[]#Posterior","body":"$$\n\\pi (\\theta \\mid y)\n$$\nThe posterior distribution represents our knowledge about our uncertain quantity (parameters) **after** some evidence is taken into account.\n"},"/math/bayesian-inference#Likelihood":{"id":"/math/bayesian-inference#Likelihood","title":"/math/bayesian-inference#Likelihood","tags":"[]#Likelihood","body":"$$\n\\pi (y \\mid \\theta)\n$$\nThe likelihood distribution describes how likely the data is given some uncertain quantity (parameter). It is a function of the parameters of the chosen statistical model, given by our prior, that describes the data we are interested in.\n"},"/math/bayesian-inference#Marginal-likelihood":{"id":"/math/bayesian-inference#Marginal-likelihood","title":"/math/bayesian-inference#Marginal-likelihood","tags":"[]#Marginal-likelihood","body":"$$\n\\pi (y)\n$$\nThe marginal likelihood may be referred to as the evidence.\nWe can see that we get this distribution by marginalizing out theta from $ \\pi (y, \\theta) $ — integrating out theta. Thus we can write\n$$\n\\pi(y) = \\int_\\theta \\pi (y, \\theta) d\\theta = \\int_\\theta \\pi(y\\mid \\theta)\\pi(\\theta) d\\theta\n$$\nIn the case we have updated our prior with our posterior the formula is turned into\n$$\n\\pi(y) = \\int_\\theta \\pi(y\\mid \\theta)\\pi(\\theta \\mid \\bold y) d\\theta\n$$\nwhere $ \\bold y $ represents the old data and $ y $ the data we want to predict.\nThe marginal likelihood is generally difficult to compute, except for a small number of distributions that have the relation conjugate prior. When this is not the case, we could use some kind of numerical integration, discretization and Monte Carlo method among others.\n"},"/math/bayesian-inference#Prior-predictive":{"id":"/math/bayesian-inference#Prior-predictive","title":"/math/bayesian-inference#Prior-predictive","tags":"[]#Prior-predictive","body":"The prior predictive density is the marginal likelihood using the prior\n$$\n\\pi(y) = \\int_\\theta \\pi (y, \\theta) d\\theta = \\int_\\theta \\pi(y\\mid \\theta)\\pi(\\theta) d\\theta\n$$\n"},"/math/bayesian-inference#Posterior-predictive":{"id":"/math/bayesian-inference#Posterior-predictive","title":"/math/bayesian-inference#Posterior-predictive","tags":"[]#Posterior-predictive","body":"The posterior predictive density is the marginal likelihood using the posterior\n$$\n\\pi(y \\mid \\bold y) = \\int_\\theta \\pi(y\\mid \\theta)\\pi(\\theta \\mid \\bold y) d\\theta\n$$\nBoth the prior predictive and the posterior predictive has a simple closed form if we have a conjugacy.\n"},"/math/bayesian-inference#Conjugacy":{"id":"/math/bayesian-inference#Conjugacy","title":"/math/bayesian-inference#Conjugacy","tags":"[]#Conjugacy","body":"If the posterior and the prior is of the same probability distribution family we say that we have a conjugacy and the prior and posterior distributions are called conjugate distributions. The prior is called a conjugate prior for the likelihood function.\nSome of the most common conjugacies:\n- Beta-Binomial\n- Exponential-Gamma\n- Multinomial-Dirichlet\n- Poisson-Gamma\n- Normal-Gamma\n- Normal-Normal\n"},"/math/bayesian-inference#Proportionality":{"id":"/math/bayesian-inference#Proportionality","title":"/math/bayesian-inference#Proportionality","tags":"[]#Proportionality","body":"When calculating the posterior we can write\n$$\n\\pi(\\theta\\mid y)=\\frac {\\pi(y\\mid \\theta)\\pi(\\theta)}{\\pi(y)} \\propto_\\theta \\pi(y\\mid \\theta)\\pi(\\theta)\n$$\nwhere $ \\propto_\\theta $ means proportional to theta to express that two expressions are identical ignoring any factor not involving theta. This is very useful because as we have concluded, $ \\pi(y) $ can be tricky to compute. We could do this trick because the posterior will always integrate to 1, so there would be no loss in information if we multiply or divide by factors that do not depend on $ \\theta $. These factors could be inserted again at the end of our proportional to calculations to fulfill the requirement that the posterior should integrate to 1.\n"},"/math/calculus#":{"id":"/math/calculus#","title":"/math/calculus#","tags":"[]#","body":""},"/math/calculus#Taylor-expansion":{"id":"/math/calculus#Taylor-expansion","title":"/math/calculus#Taylor-expansion","tags":"[]#Taylor-expansion","body":"The Taylor series of a real or complex-valued function $ f(x) $ that is infinitely differentiable at a real or complex number $ a $ is the power series @{taylorwiki}\n$$\n\\sum_{n=0}^\\infin \\frac{f^{(n)}(a)}{n!}(x - a)^n = f(a) + \\frac{f'(a)}{1!}(x - a) + \\frac{f''(a)}{2!}(x - a)^2 + \\frac{f'''(a)}{3!}(x - a)^3 + \\dots\n$$\nThe taylor polynomial for any polynomial is the polynomial itself. When $ a = 0 $ the series is also called the a **Maclaurin series**. The series is very useful to approximate a function at $ a $ as a polynomial. Here we approximate $ \\text{sin} $ at $ a = 0 $\n$$\n\\text{sin} (x) \\approx x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + O(x^9)\n$$\nwhere $ O(x^9) $ is the error term.\n"},"/math/calculus#Differentiability-class":{"id":"/math/calculus#Differentiability-class","title":"/math/calculus#Differentiability-class","tags":"[]#Differentiability-class","body":"The function $ f $ is said to be of differentiability class $ C^k $ if the derivatives $ f^{(1)}, f^{(2)}, \\dots, f^{(k)} $ exist and are continous.\n"},"/math/calculus#Gradient":{"id":"/math/calculus#Gradient","title":"/math/calculus#Gradient","tags":"[]#Gradient","body":"Suppose that $ f: \\R^n \\to \\R $ is a function and that $ f \\in C^1 $ we can define the gradient $ \\nabla f $ as\n$$\n\\nabla f =\n\\begin{bmatrix}\n    \\frac{\\partial f}{\\partial x_1}  \\\\\n    \\frac{\\partial f}{\\partial x_2}  \\\\\n    \\vdots  \\\\\n    \\frac{\\partial f}{\\partial x_n}  \\\\\n\\end{bmatrix}\n$$\n"},"/math/calculus#Hessian":{"id":"/math/calculus#Hessian","title":"/math/calculus#Hessian","tags":"[]#Hessian","body":"Suppose that $ f: \\R^n \\to \\R $ is a function taking as input a vector $ \\bold x \\in \\R^n $ and output a scalar $ f(\\bold x) \\in \\R $. If $ f \\in C^2 $ then the **Hessian** matrix $ \\bold H $ of $ f $ is a square $ n \\times n $ matrix defined as follows\n$$\n\\bold H =\n\\begin{bmatrix}\n    \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2f}{\\partial x_1 \\partial x_n} \\\\\n    \\frac{\\partial^2f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_n} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    \\frac{\\partial^2f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2f}{\\partial x_n^2} \\\\\n\\end{bmatrix}\n$$\n"},"/math/calculus#Matrix-calculus":{"id":"/math/calculus#Matrix-calculus","title":"/math/calculus#Matrix-calculus","tags":"[]#Matrix-calculus","body":"https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n"},"/math/calculus#References":{"id":"/math/calculus#References","title":"/math/calculus#References","tags":"[]#References","body":"{taylorwiki}:\n    url: https://en.wikipedia.org/wiki/Taylor_series\n"},"/math/distributions#":{"id":"/math/distributions#","title":"/math/distributions#","tags":"[]#","body":""},"/math/distributions#Poisson-distribution":{"id":"/math/distributions#Poisson-distribution","title":"/math/distributions#Poisson-distribution","tags":"[]#Poisson-distribution","body":"If $ x \\in \\{0,1,2,...\\} $ has  Poisson  distribution  with  parameter $ \\lambda >0 $  then  the  probability  mass function is\n$$\n\\text{Poisson}(x; \\lambda)= \\Pr(X{=}x)= \\frac{\\lambda^x e^{-\\lambda}}{x!}\n$$\nWe write $ x | \\lambda ∼ \\text{Poisson}( \\lambda )$ and $ \\pi (x| \\lambda) = \\text{Poisson}(x;\\lambda) $.\n"},"/math/keywords#":{"id":"/math/keywords#","title":"/math/keywords#","tags":"[\"keywords\"]#","body":"- hypothesis testing\n- paired t-test\n- bootstrapping\n- p-value\n- t-test\n- parametric test\n- gaussian distribution\n- confidence interval\n- chi squared test\n- convex\n- concave\n- gradient descent\n- gradient ascent\n- time series analysis\n- hyperplane\n- half-space\n"},"/math/keywords#Null-Hypothesis":{"id":"/math/keywords#Null-Hypothesis","title":"/math/keywords#Null-Hypothesis","tags":"[\"keywords\"]#Null-Hypothesis","body":""},"/math/keywords#Statistically-Significant":{"id":"/math/keywords#Statistically-Significant","title":"/math/keywords#Statistically-Significant","tags":"[\"keywords\"]#Statistically-Significant","body":"The result is probably not due to random luck.\n"},"/math/keywords#Vector-norm":{"id":"/math/keywords#Vector-norm","title":"/math/keywords#Vector-norm","tags":"[\"keywords\"]#Vector-norm","body":"The vector norm is denoted\n$$\n\\| \\bold x \\|\n$$\nand may represent any vector norm.\n"},"/math/keywords#Absolute-value-norm":{"id":"/math/keywords#Absolute-value-norm","title":"/math/keywords#Absolute-value-norm","tags":"[\"keywords\"]#Absolute-value-norm","body":"$$\n\\| \\bold x \\| = \\| \\bold x \\|_1 = \\sum_{j=1}^{n} | x_j |\n$$\n"},"/math/keywords#Euclidean-norm":{"id":"/math/keywords#Euclidean-norm","title":"/math/keywords#Euclidean-norm","tags":"[\"keywords\"]#Euclidean-norm","body":"$$\n\\| \\bold x \\| = \\| \\bold x \\|_2 = \\sqrt{\\sum_{j=1}^{n} x_j^2}\n$$\n"},"/math/keywords#Probability-space":{"id":"/math/keywords#Probability-space","title":"/math/keywords#Probability-space","tags":"[\"keywords\"]#Probability-space","body":"The probability space consists of three elements: the sample space, the event space and a probability function. The probability function assigns each event in the event space a probability between 0 and 1 where each event maps to a set of outcomes in the sample space.\n"},"/math/keywords#Parametric-family":{"id":"/math/keywords#Parametric-family","title":"/math/keywords#Parametric-family","tags":"[\"keywords\"]#Parametric-family","body":"A parametric family is a family whose differences only depend in the set of parameters used.\n"},"/math/keywords#Point-process":{"id":"/math/keywords#Point-process","title":"/math/keywords#Point-process","tags":"[\"keywords\"]#Point-process","body":"A spatial Poisson process is a special case of a point process.\n"},"/math/keywords#Stochastic-calculus":{"id":"/math/keywords#Stochastic-calculus","title":"/math/keywords#Stochastic-calculus","tags":"[\"keywords\"]#Stochastic-calculus","body":"Stochastic calculus is a branch of mathematics that operates on stochastic processes.\n"},"/math/keywords#Hoeffding's-inequality":{"id":"/math/keywords#Hoeffding's-inequality","title":"/math/keywords#Hoeffding's-inequality","tags":"[\"keywords\"]#Hoeffding's-inequality","body":"Hoeffding's inequality is an upper bound on the probability that the sum of independent random variables differs by a certain amount with regards to its expected value.\n"},"/math/keywords#Boole's-inequality":{"id":"/math/keywords#Boole's-inequality","title":"/math/keywords#Boole's-inequality","tags":"[\"keywords\"]#Boole's-inequality","body":"Boole's inequality is also known as the **union bound**. It states that for any finite set of events the probability that at least one of the events happens is no greater than the sum of the probabilities of the individual events.\n"},"/math/linear-algebra#":{"id":"/math/linear-algebra#","title":"/math/linear-algebra#","tags":"[]#","body":"Elements $ \\bold v \\in \\R^n $ are referred to as **vectors**\n$$\n\\bold v =\n\\begin{bmatrix}\n    v_1 \\\\\n    v_2 \\\\\n    \\vdots \\\\\n    v_n \\\\\n\\end{bmatrix}\n$$\nwhere $ v_i $ is a real number and $ \\bold v^\\intercal = (v_1, v_2, \\dots, v_n) $ , the $ ^\\intercal $ denotes the transpose operator. For two vectors $ \\bold a = (a_1, a_2, \\dots, a_n)^\\intercal \\in \\R^n$ and $ \\bold b = (b_1, b_2, \\dots, b_n)^\\intercal \\in \\R^n $ , we define the following properties:\n- addition: $ \\bold {a+b} = (a_1+b_1, a_2+b_2, \\dots, a_n+b_n)^\\intercal \\in \\R^n $\n- multiplication by scalar: $ \\alpha \\bold a = (\\alpha a_1, \\alpha a_2, \\dots, \\alpha a_n)^\\intercal \\in \\R^n $\n- scalar product: $ \\bold a ^\\intercal \\bold b = \\sum_{i=1}^n a_i b_i \\in \\R^n $\nA **linear subspace** $ L \\sube \\R^n $ is a set that holds:\n- for every $ \\bold a, \\bold b \\in L $ it holds that $ \\bold a + \\bold b \\in L $\n- for every $ \\alpha \\in \\R, \\bold a \\in L $ it holds that $ \\alpha \\bold a \\in L $\nAn **affine subspace** $ A \\sube \\R^n $ is a set that is represented as:\n- $ \\bold v + L = \\{\\bold v + \\bold x | \\bold x \\in L\\} $ for some vector $ \\bold v \\in \\R^n $ and linear subspace $ L \\sube \\R^n $\n"},"/math/linear-algebra#Rank":{"id":"/math/linear-algebra#Rank","title":"/math/linear-algebra#Rank","tags":"[]#Rank","body":"The rank of a matrix $ A $ is the dimension spanned by its columns. Thus, the maximal number of linearly independent columns in $ A $, which in turn, is equal to the dimension spanned by its rows. The column rank and the row rank are always equal.\n"},"/math/linear-algebra#Trace":{"id":"/math/linear-algebra#Trace","title":"/math/linear-algebra#Trace","tags":"[]#Trace","body":"The trace @{trace} of a square matrix $ A $, is the sum of the elements of the main diagonal, e.g. $ I^3 $ where $ I $ is the identity matrix with three dimension has the trace of $ 3 $.\n$$\n\\text{tr}(I^3) = 3\n$$\n"},"/math/linear-algebra#References":{"id":"/math/linear-algebra#References","title":"/math/linear-algebra#References","tags":"[]#References","body":"{trace}:\n    title: Trace\n    url: https://en.wikipedia.org/wiki/Trace_(linear_algebra)\n"},"/math/nonlinear-optimization#":{"id":"/math/nonlinear-optimization#","title":"/math/nonlinear-optimization#","tags":"[]#","body":""},"/math/nonlinear-optimization#General-optimization-problem-definition":{"id":"/math/nonlinear-optimization#General-optimization-problem-definition","title":"/math/nonlinear-optimization#General-optimization-problem-definition","tags":"[]#General-optimization-problem-definition","body":"$$\n\\boxed{\n    \\begin{aligned}\n    \\qquad\\underset{\\bold x \\in S}{\\text{minimize}} \\qquad & f(\\bold x),  \\\\\n    \\text{subject to} \\qquad & g_i(\\bold x) \\leq 0, \\qquad i \\in \\mathcal{I} \\qquad \\\\\n    & h_i(\\bold x) = 0, \\qquad i \\in \\mathcal{E} \\\\\n    & \\bold x \\in \\Chi\n    \\end{aligned}\n}\n$$\n"},"/math/nonlinear-optimization#Classification":{"id":"/math/nonlinear-optimization#Classification","title":"/math/nonlinear-optimization#Classification","tags":"[]#Classification","body":""},"/math/nonlinear-optimization#Linear-programming-(LP)":{"id":"/math/nonlinear-optimization#Linear-programming-(LP)","title":"/math/nonlinear-optimization#Linear-programming-(LP)","tags":"[]#Linear-programming-(LP)","body":"For linear problems of the sort\n$$\n\\begin{aligned}\n\\text{min} \\qquad & \\bold c^\\mathsf{T} \\bold x \\\\\n\\text{s.t.} \\qquad & \\bold x \\in P \\\\\n\\end{aligned}\n$$\nwe can use the Simplex method to solve for an optimal solution. We first convert to standard form:\n$$\n\\begin{aligned}\n\\text{min} \\qquad & \\bold c^\\mathsf{T} \\bold x \\\\\n\\text{s.t.} \\qquad & A \\bold x = \\bold b \\\\\n& \\bold x \\geq 0\n\\end{aligned}\n$$\nwhere $ \\bold b \\geq 0 $.\n"},"/math/nonlinear-optimization#Nonlinear-programming-(NLP)":{"id":"/math/nonlinear-optimization#Nonlinear-programming-(NLP)","title":"/math/nonlinear-optimization#Nonlinear-programming-(NLP)","tags":"[]#Nonlinear-programming-(NLP)","body":"- Some functions $ f, g_i, i \\in \\mathcal{I} \\cup \\mathcal{E}   $ are nonlinear.\n"},"/math/nonlinear-optimization#Unconstrained-optimization":{"id":"/math/nonlinear-optimization#Unconstrained-optimization","title":"/math/nonlinear-optimization#Unconstrained-optimization","tags":"[]#Unconstrained-optimization","body":"1. Begin by finding a descent direction. The vector $ \\bold p_k $ is a descent direction if $ f(\\bold x_k + \\alpha \\bold p_k) < f(\\bold x_k) $ for all $ \\alpha \\in [0, \\delta] $ for some $ \\delta > 0 $.\n"},"/math/nonlinear-optimization#Constrained-optimization":{"id":"/math/nonlinear-optimization#Constrained-optimization","title":"/math/nonlinear-optimization#Constrained-optimization","tags":"[]#Constrained-optimization","body":"- $ \\mathcal{I} \\cup \\mathcal{E} \\not = \\empty $\n- $ \\Chi \\sub \\R^n $\n"},"/math/nonlinear-optimization#Integer-programming-(IP)":{"id":"/math/nonlinear-optimization#Integer-programming-(IP)","title":"/math/nonlinear-optimization#Integer-programming-(IP)","tags":"[]#Integer-programming-(IP)","body":"- $ \\Chi \\sub \\Z^n $ or $ \\Chi \\sube \\{0,1\\}^n $\n"},"/math/nonlinear-optimization#Convex-programming-(CP)":{"id":"/math/nonlinear-optimization#Convex-programming-(CP)","title":"/math/nonlinear-optimization#Convex-programming-(CP)","tags":"[]#Convex-programming-(CP)","body":"- $ f, g_i, i \\in \\mathcal{I} $ are convex functions\n- $ g_i, i \\in \\mathcal{E} $ are affine\n- $ \\Chi $ is closed and convex\n"},"/math/nonlinear-optimization#Modeling":{"id":"/math/nonlinear-optimization#Modeling","title":"/math/nonlinear-optimization#Modeling","tags":"[]#Modeling","body":""},"/math/nonlinear-optimization#Formulating-the-problem":{"id":"/math/nonlinear-optimization#Formulating-the-problem","title":"/math/nonlinear-optimization#Formulating-the-problem","tags":"[]#Formulating-the-problem","body":"1. Define what **sets** the problem requires\n2. Acknowledge what **parameters** the problem has and to what set it belongs to\n3. What type of **descision variables** is suitable for the problem\n"},"/math/nonlinear-optimization#Convexity":{"id":"/math/nonlinear-optimization#Convexity","title":"/math/nonlinear-optimization#Convexity","tags":"[]#Convexity","body":""},"/math/nonlinear-optimization#Convex-set":{"id":"/math/nonlinear-optimization#Convex-set","title":"/math/nonlinear-optimization#Convex-set","tags":"[]#Convex-set","body":"A set $ S \\sube \\R^n $ is convex if\n$$\n\\bold x_1, \\bold x_2 \\in S, \\lambda \\in (0,1) \\implies \\lambda \\bold x_1 + (1 - \\lambda) \\bold x_2 \\in S\n$$\n"},"/math/nonlinear-optimization#Affine-hull":{"id":"/math/nonlinear-optimization#Affine-hull","title":"/math/nonlinear-optimization#Affine-hull","tags":"[]#Affine-hull","body":"The affine hull of a finite set $ V = \\{\\bold v^1, \\bold v^2, \\dots, \\bold v^k\\} $ is defined as\n$$\n\\text{aff}\\, V := \\bigg \\{ \\lambda_1 \\bold v^1 + \\cdots + \\lambda_k \\bold v^k \\bigg | \\lambda_1, \\dots, \\lambda_k \\in \\R, \\sum_{i=1}^{k} \\lambda_i = 1 \\bigg \\}\n$$\n"},"/math/nonlinear-optimization#Convex-hull":{"id":"/math/nonlinear-optimization#Convex-hull","title":"/math/nonlinear-optimization#Convex-hull","tags":"[]#Convex-hull","body":"The convex hull of a finite set $ V = \\{\\bold v^1, \\bold v^2, \\dots, \\bold v^k\\} $ is defined as\n$$\n\\text{conv}\\, V := \\bigg \\{ \\lambda_1 \\bold v^1 + \\cdots + \\lambda_k \\bold v^k \\bigg | \\lambda_1, \\dots, \\lambda_k \\geq 0, \\sum_{i=1}^{k} \\lambda_i = 1 \\bigg \\}\n$$\n"},"/math/nonlinear-optimization#Affine-combination":{"id":"/math/nonlinear-optimization#Affine-combination","title":"/math/nonlinear-optimization#Affine-combination","tags":"[]#Affine-combination","body":"An affine combination of the points $ \\{\\bold v_1, \\dots, \\bold v_n\\} $ is a vector satisfying\n$$\n\\bold v = \\sum_{i=1}^{n} \\lambda_i \\bold v_i\n$$\nwhere $ \\sum_{i=1}^{n} \\lambda_i = 1 $\n"},"/math/nonlinear-optimization#Convex-combination":{"id":"/math/nonlinear-optimization#Convex-combination","title":"/math/nonlinear-optimization#Convex-combination","tags":"[]#Convex-combination","body":"A convex combination of the points $ \\{\\bold v_1, \\dots, \\bold v_n\\} $ is a vector satisfying\n$$\n\\bold v = \\sum_{i=1}^{n} \\lambda_i \\bold v_i\n$$\nwhere $ \\sum_{i=1}^{n} \\lambda_i = 1 $ and $ \\lambda_i \\geq 0 $ for every $ i = 1, \\dots, n $\n"},"/math/nonlinear-optimization#Polytype":{"id":"/math/nonlinear-optimization#Polytype","title":"/math/nonlinear-optimization#Polytype","tags":"[]#Polytype","body":"A set $ P \\sub \\R^n $ is a **polytype** if it is the convex hull of finitely many points in $ \\R^n $.\n"},"/math/nonlinear-optimization#Polyhedron":{"id":"/math/nonlinear-optimization#Polyhedron","title":"/math/nonlinear-optimization#Polyhedron","tags":"[]#Polyhedron","body":"A set $ P \\sub \\R^n $ is a **polyhedron** if there exists a matrix $ A \\in \\R^{m \\times n} $ and a vector $ \\bold b \\in \\R^m $ such that\n$$\nP = \\{\\bold x \\in \\R^n | \\bold A \\bold x \\leq \\bold b\\}\n$$\nThe set $ P $ is the intersection of $ m $ half-spaces. Polyhedrons may be unbounded.\n"},"/math/nonlinear-optimization#Cone":{"id":"/math/nonlinear-optimization#Cone","title":"/math/nonlinear-optimization#Cone","tags":"[]#Cone","body":"A set $ C \\sube \\R^n $ is a **cone** if $ \\lambda \\bold x \\in C $ whenever $ \\bold x \\in C $ and $ \\lambda > 0 $.\n"},"/math/nonlinear-optimization#Polyhedral-cone":{"id":"/math/nonlinear-optimization#Polyhedral-cone","title":"/math/nonlinear-optimization#Polyhedral-cone","tags":"[]#Polyhedral-cone","body":"The set $ \\{\\bold x \\in \\R^n | \\bold A \\bold x \\leq \\bold 0^m\\} $ where $ \\bold A \\in \\R^{m \\times n} $ is a cone but also a polyhedron, which is why it is usually called a **polyhedral cone**.\n"},"/math/nonlinear-optimization#Half-space":{"id":"/math/nonlinear-optimization#Half-space","title":"/math/nonlinear-optimization#Half-space","tags":"[]#Half-space","body":"A **half space** is the set the cuts the space in two parts\n$$\n\\{ \\bold x \\in \\R^n | a_i \\bold x \\leq b_i \\}\n$$\n"},"/math/nonlinear-optimization#Convex-function":{"id":"/math/nonlinear-optimization#Convex-function","title":"/math/nonlinear-optimization#Convex-function","tags":"[]#Convex-function","body":"Suppose that $ S \\sube \\R^n $ is a convex set, then a function $ f: \\R^n \\to \\R $ is convex on $ S $ if\n$$\n\\bold x^1, \\bold x^2 \\in S, \\lambda \\in (0,1) \\implies f(\\lambda \\bold x^1 + (1 - \\lambda) \\bold x^2) \\leq \\lambda f(\\bold x^1) + (1 - \\lambda) f(\\bold x^2)\n$$\n- A function is **strictly convex** if the inequality is strict.\n- A function $ f $ is **concave** if $ -f $ is convex.\nNote that linear functions are both convex and concave.\n"},"/math/nonlinear-optimization#Carathéodory's-Theorem":{"id":"/math/nonlinear-optimization#Carathéodory's-Theorem","title":"/math/nonlinear-optimization#Carathéodory's-Theorem","tags":"[]#Carathéodory's-Theorem","body":"Let $ \\bold x \\in \\text{conv}\\, V $ where $  V \\sube \\R^n $. Then $ \\bold x $ can be expressed as a convex combination of $ n + 1 $ or fewer points of $ V $.\n"},"/math/nonlinear-optimization#Representation-Theorem":{"id":"/math/nonlinear-optimization#Representation-Theorem","title":"/math/nonlinear-optimization#Representation-Theorem","tags":"[]#Representation-Theorem","body":"The Representation Theorem states that every polyhedron that has at least one extreme point is the sum of a polytope and a polyhedral cone.\n"},"/math/nonlinear-optimization#Farkas'-Lemma":{"id":"/math/nonlinear-optimization#Farkas'-Lemma","title":"/math/nonlinear-optimization#Farkas'-Lemma","tags":"[]#Farkas'-Lemma","body":"Let $ \\bold A \\in \\R^{m \\times n} $ and $ \\bold b \\in \\R^m $. Then exactly one of the systems has a feasible solution\n$$\n\\begin{aligned}\n\\bold A \\bold x &= \\bold b \\\\\n\\bold x &\\geq 0\n\\end{aligned}\n$$\nand\n$$\n\\begin{aligned}\n\\bold A^\\mathsf{T} \\bold y &\\leq 0  \\\\\n\\bold b^\\mathsf{T} \\bold y &> 0 \\\\\n\\end{aligned}\n$$\nand the other one is inconsistent.\n"},"/math/nonlinear-optimization#Existence-of-optimal-solutions":{"id":"/math/nonlinear-optimization#Existence-of-optimal-solutions","title":"/math/nonlinear-optimization#Existence-of-optimal-solutions","tags":"[]#Existence-of-optimal-solutions","body":""},"/math/nonlinear-optimization#Notation":{"id":"/math/nonlinear-optimization#Notation","title":"/math/nonlinear-optimization#Notation","tags":"[]#Notation","body":"- We say that a set $ S \\sube \\R^n $ is **open** if for every $ x \\in S $ there exists an $ \\epsilon > 0 $ such that $ B_\\epsilon (\\bold x) := \\{\\bold y \\in \\R^n |\\, \\|\\bold y - \\bold x \\| < \\epsilon \\} \\sub S $.\n- A set $ S \\sube \\R^n $ is **closed** if $ \\R^n \\backslash S $ is open.\n- A **limit point** of a set $ S \\sube \\R^n$ is a point $ \\bold x $ such that there exists a sequence $ \\{\\bold x_k\\}_{k=1}^\\infin \\sub S $ fulfilling $ \\bold x_k \\to \\bold x $.\n- We can then define a closed set as a set which contains all its limit points.\n- We say that a set $ S \\sube \\R^n $ is **bounded** if there exists a constant $ C > 0 $ such that $ \\| \\bold x \\| \\leq C $ for all $ \\bold x \\in S $.\n- If a set is both closed and bounded, we call it **compact**.\n"},"/math/nonlinear-optimization#Definition":{"id":"/math/nonlinear-optimization#Definition","title":"/math/nonlinear-optimization#Definition","tags":"[]#Definition","body":""},"/math/nonlinear-optimization#Weakly-coercive-function":{"id":"/math/nonlinear-optimization#Weakly-coercive-function","title":"/math/nonlinear-optimization#Weakly-coercive-function","tags":"[]#Weakly-coercive-function","body":"A function $ f $ is said to be **weakly coercive** with respect to the set $ S $ if either $ S $ is bounded or\n$$\n\\underset{\\substack{\\| \\bold x \\| \\to \\infin \\\\ \\bold x \\in S}}{\\text{lim}} f(\\bold x) = \\infin\n$$\n"},"/math/nonlinear-optimization#Lower-semi-continuity":{"id":"/math/nonlinear-optimization#Lower-semi-continuity","title":"/math/nonlinear-optimization#Lower-semi-continuity","tags":"[]#Lower-semi-continuity","body":"A function $ f $ is said to be **lower semi-continuous** at $ \\bold x $ if the value $ f(\\bold x) $ is less than or equal to every limit of $ f $ as $ \\bold x_k \\to \\bold x $\n$$\n\\bold x_k \\to \\bold x \\implies f(\\bold x) \\leq \\underset{k \\to \\infin}{\\text{lim inf}} \\, f(\\bold x_k)\n$$\n"},"/math/nonlinear-optimization#Feasible-direction":{"id":"/math/nonlinear-optimization#Feasible-direction","title":"/math/nonlinear-optimization#Feasible-direction","tags":"[]#Feasible-direction","body":"Let $ \\bold x \\in S $. A vector $ \\bold p \\in \\R^n $ defines a **feasible direction** at $ \\bold x $ if\n$$\n\\exist \\delta > 0: \\qquad \\bold x + \\alpha \\bold p \\in S, \\qquad \\forall \\alpha \\in [0, \\delta].\n$$\nThe feasible direction is therefore a direction at a point where we can move without becoming infeasible.\n"},"/math/nonlinear-optimization#Descent-direction":{"id":"/math/nonlinear-optimization#Descent-direction","title":"/math/nonlinear-optimization#Descent-direction","tags":"[]#Descent-direction","body":"Let $ \\bold x \\in \\R^n $. A vector $ \\bold p \\in \\R^n $ defines a **descent direction** with respect to $ f $ at $ \\bold x $ if\n$$\n\\exist \\delta > 0: \\qquad f(\\bold x + \\alpha \\bold p) < f(\\bold x), \\qquad \\forall \\alpha \\in (0, \\delta].\n$$\n"},"/math/nonlinear-optimization#Normal-cone":{"id":"/math/nonlinear-optimization#Normal-cone","title":"/math/nonlinear-optimization#Normal-cone","tags":"[]#Normal-cone","body":"Suppose the set $ S $ is closed and convex. Let $ \\bold x \\in S $. Then the **normal cone** to $ S $ at $ \\bold x $ is the set\n$$\nN_s(\\bold x):= \\{\\bold p \\in \\R^n \\, | \\, \\bold p^\\mathsf{T} (\\bold y - \\bold x) \\leq 0, \\, \\bold y \\in S\\}\n$$\n"},"/math/nonlinear-optimization#Weierstrass'-Theorem":{"id":"/math/nonlinear-optimization#Weierstrass'-Theorem","title":"/math/nonlinear-optimization#Weierstrass'-Theorem","tags":"[]#Weierstrass'-Theorem","body":"Consider the problem where $ S $ is a nonempty and closed set and $ f $ is lower semi-continuous on $ S $. If $ f $ is weakly coercive with respect to $ S $, then there exists a nonempty, closed and bounded (compact) set of optimal solutions to the problem.\n"},"/math/nonlinear-optimization#Optimality-conditions-(S-equal-R^n)":{"id":"/math/nonlinear-optimization#Optimality-conditions-(S-equal-R^n)","title":"/math/nonlinear-optimization#Optimality-conditions-(S-equal-R^n)","tags":"[]#Optimality-conditions-(S-equal-R^n)","body":"When $ S = \\R^n $ (unconstrained optimization problem), the following theorem holds\n"},"/math/nonlinear-optimization#Necessary-condition-for-optimality-1":{"id":"/math/nonlinear-optimization#Necessary-condition-for-optimality-1","title":"/math/nonlinear-optimization#Necessary-condition-for-optimality-1","tags":"[]#Necessary-condition-for-optimality-1","body":"Suppose that $ S \\sube \\R^n $ and that $ f \\in C^1 $ on $ S $.\na) If $ \\bold x^* \\in S $ is a local minimum of $ f $ over $ S $ then\n$$\n\\nabla f(\\bold x^*)^\\mathsf{T} \\bold p \\geq 0\n$$\nholds for all feasible directions $ \\bold p $ at $ \\bold x^* $.\nb) Suppose that $ S $ is convex. If $ \\bold x^* $ is a local minimum of $ f $ over $ S $ then\n$$\n\\nabla f(\\bold x^*)^\\mathsf{T} (\\bold x - \\bold x^*) \\geq 0, \\qquad \\bold x \\in S\n$$\n"},"/math/nonlinear-optimization#Necessary-condition-for-optimality-2":{"id":"/math/nonlinear-optimization#Necessary-condition-for-optimality-2","title":"/math/nonlinear-optimization#Necessary-condition-for-optimality-2","tags":"[]#Necessary-condition-for-optimality-2","body":"If $ f \\in C^2 $ on $ \\R^n $ then\n$$\n\\bold x^* \\, \\text{is a local minimum of} \\, f \\, \\text{on} \\, \\R^n \\implies\n\\begin{cases}\n\\nabla f(\\bold x^*) = \\bold 0 \\\\\n\\nabla^2 f(\\bold x^*) \\geq 0\n\\end{cases}\n$$\n"},"/math/nonlinear-optimization#Sufficient-condition-for-optimality-2":{"id":"/math/nonlinear-optimization#Sufficient-condition-for-optimality-2","title":"/math/nonlinear-optimization#Sufficient-condition-for-optimality-2","tags":"[]#Sufficient-condition-for-optimality-2","body":"If $ f \\in C^2 $ on $ \\R^n $ then\n$$\n\\begin{cases}\n\\nabla f(\\bold x^*) = \\bold 0 \\\\\n\\nabla^2 f(\\bold x^*) > 0\n\\end{cases}\n\\implies \\bold x^* \\, \\text{is a strict local minimum of} \\, f \\, \\text{on} \\, \\R^n\n$$\n"},"/math/nonlinear-optimization#Necessary-and-sufficient-condition-for-optimality-1":{"id":"/math/nonlinear-optimization#Necessary-and-sufficient-condition-for-optimality-1","title":"/math/nonlinear-optimization#Necessary-and-sufficient-condition-for-optimality-1","tags":"[]#Necessary-and-sufficient-condition-for-optimality-1","body":"If $ f \\in C^1 $ is convex on $ \\R^n $ then\n$$\n\\bold x^* \\, \\text{is a global minimum of} \\, f \\, \\text{on} \\, \\R^n\n\\iff\n\\nabla f(\\bold x^*) = \\bold 0\n$$\n"},"/math/nonlinear-optimization#Optimality-conditions-(S-sub-R^n)":{"id":"/math/nonlinear-optimization#Optimality-conditions-(S-sub-R^n)","title":"/math/nonlinear-optimization#Optimality-conditions-(S-sub-R^n)","tags":"[]#Optimality-conditions-(S-sub-R^n)","body":""},"/math/nonlinear-optimization#Neecssary-and-sufficient-conditions-for-optimality-1":{"id":"/math/nonlinear-optimization#Neecssary-and-sufficient-conditions-for-optimality-1","title":"/math/nonlinear-optimization#Neecssary-and-sufficient-conditions-for-optimality-1","tags":"[]#Neecssary-and-sufficient-conditions-for-optimality-1","body":"Suppose that $ S \\sube \\R^n $ is a convex nonempty set and that $ f \\in C^1 $ is a convex function on $ S $ then\n$$\n\\bold x^* \\, \\text{is a global minimum of} \\, f \\, \\text{over} \\, S\n\\iff\n\\nabla f(\\bold x^*)^\\mathsf{T} (\\bold x - \\bold x^*) \\geq 0, \\qquad \\bold x \\in S\n$$\nWhen $ S = \\R^n $ the expression can be reduced to $ \\nabla f(\\bold x^*) = \\bold 0 $, because then we don't need to worry about boundary points.\n"},"/math/nonlinear-optimization#Stationary-point-in-optimality-condition":{"id":"/math/nonlinear-optimization#Stationary-point-in-optimality-condition","title":"/math/nonlinear-optimization#Stationary-point-in-optimality-condition","tags":"[]#Stationary-point-in-optimality-condition","body":"If $ S $ is convex and $ f \\in C^1 $ a point $ \\bold x \\in S $ fulfilling the four equivalent statements a)-d) are called a **stationary point**.\na)\n$$\n\\nabla f(\\bold x^*)^\\mathsf{T} (\\bold x - \\bold x^*) \\geq 0, \\qquad \\bold x \\in S\n$$\nb)\n$$\n\\underset{\\bold x \\in S}{\\text{min}} \\nabla f(\\bold x^*)^\\mathsf{T} (\\bold x - \\bold x^*) = 0\n$$\nc)\n$$\n\\bold x^* = \\text{Proj}_S [\\bold x^* - \\nabla f(\\bold x^*)]\n$$\nd)\n$$\n-\\nabla f(\\bold x^*) \\in N_S(\\bold x^*)\n$$\nwhere $ \\text{Proj}_S $ is the projection onto the set $ S $, and $ N_s $ is the normal cone.\n"},"/math/nonlinear-optimization#Steepest-descent-direction":{"id":"/math/nonlinear-optimization#Steepest-descent-direction","title":"/math/nonlinear-optimization#Steepest-descent-direction","tags":"[]#Steepest-descent-direction","body":"$$\n\\bold p_k = - \\nabla f(\\bold x_k)\n$$\n"},"/math/nonlinear-optimization#Newton's-search-direction":{"id":"/math/nonlinear-optimization#Newton's-search-direction","title":"/math/nonlinear-optimization#Newton's-search-direction","tags":"[]#Newton's-search-direction","body":"$$\n\\nabla^2 f(\\bold x_k) \\bold p_k = - \\nabla f(\\bold x_k)\n$$\n"},"/math/nonlinear-optimization#Lewenberg-Marquardt":{"id":"/math/nonlinear-optimization#Lewenberg-Marquardt","title":"/math/nonlinear-optimization#Lewenberg-Marquardt","tags":"[]#Lewenberg-Marquardt","body":"$$\n[\\nabla^2 f(\\bold x_k) + \\lambda I] \\bold p_k = - \\nabla f(\\bold x_k)\n$$\n2. Then choose step length\n"},"/math/nonlinear-optimization#Exact-line-search":{"id":"/math/nonlinear-optimization#Exact-line-search","title":"/math/nonlinear-optimization#Exact-line-search","tags":"[]#Exact-line-search","body":"$$\n\\begin{aligned}\n\\text{min} & \\qquad f(\\bold x_k + \\alpha \\bold p_k)\\\\\ns.t. & \\qquad \\alpha > 0\n\\end{aligned}\n$$\n"},"/math/nonlinear-optimization#Newton's-method":{"id":"/math/nonlinear-optimization#Newton's-method","title":"/math/nonlinear-optimization#Newton's-method","tags":"[]#Newton's-method","body":"$$\n\\bold x_{k+1} = \\bold x_k - \\frac{\\varphi ' (\\bold x_k)}{\\varphi '' (\\bold x_k)}\n$$\n"},"/math/nonlinear-optimization#Armijo-rule":{"id":"/math/nonlinear-optimization#Armijo-rule","title":"/math/nonlinear-optimization#Armijo-rule","tags":"[]#Armijo-rule","body":"$$\nf(\\bold x_k + \\alpha \\bold p_k) \\approx f(\\bold x_k) + \\alpha \\nabla f(\\bold x_k)^\\mathsf{T} \\bold p_k\n$$\nthen keep decreasing $ \\alpha = \\alpha / 2 $ until the following holds\n$$\nf(\\bold x_k + \\alpha \\bold p_k) - f(\\bold x_k)  \\leq  \\mu \\alpha \\nabla f(\\bold x_k)^\\mathsf{T} \\bold p_k\n$$\n3. Stop the algorithm when at least two of the following holds\n$$\n\\begin{aligned}\n|| \\nabla f(\\bold x_k) || & \\leq \\epsilon_1 (1 + f(\\bold x_k)) \\\\\nf(\\bold x_{k-1}) - f(\\bold x_k) & \\leq \\epsilon_2 (1 + f(\\bold x_k)) \\\\\n|| \\bold x_{k-1} - \\bold x_k || & \\leq \\epsilon_3 (1 + ||\\bold x_k||) \\\\\n\\end{aligned}\n$$\n"},"/math/nonlinear-optimization#Different-cone-sets":{"id":"/math/nonlinear-optimization#Different-cone-sets","title":"/math/nonlinear-optimization#Different-cone-sets","tags":"[]#Different-cone-sets","body":""},"/math/nonlinear-optimization#Cone-of-feasible-directions":{"id":"/math/nonlinear-optimization#Cone-of-feasible-directions","title":"/math/nonlinear-optimization#Cone-of-feasible-directions","tags":"[]#Cone-of-feasible-directions","body":"$$\nR_s(\\bold x) = \\{\\bold p \\in \\R^n \\,|\\, \\exists \\delta > 0 , \\bold x + \\alpha \\bold p \\in S, \\forall \\alpha \\in [0, \\delta]\\}\n$$\n"},"/math/nonlinear-optimization#Tangent-cone":{"id":"/math/nonlinear-optimization#Tangent-cone","title":"/math/nonlinear-optimization#Tangent-cone","tags":"[]#Tangent-cone","body":"$$\nT_s(\\bold x) = \\{\\bold p \\in \\R^n \\,|\\, \\exists \\{ \\bold x_k \\}_{k=0}^\\infty \\sub S , \\{ \\lambda_k \\}_{k=0}^\\infty \\sub (0, \\infty), \\text{ such that } \\underset{k \\to \\infty}{\\text{lim}} \\bold x_k = \\bold x, \\underset{k \\to \\infty}{\\text{lim}} \\lambda_k (\\bold x_k - \\bold x) = \\bold p \\}\n$$\n"},"/math/nonlinear-optimization#Cone-of-descent-directions":{"id":"/math/nonlinear-optimization#Cone-of-descent-directions","title":"/math/nonlinear-optimization#Cone-of-descent-directions","tags":"[]#Cone-of-descent-directions","body":"$$\nF^o(\\bold x) = \\{\\bold p \\in \\R^n \\,|\\, \\nabla f(\\bold x)^\\mathsf{T} \\bold p < 0\\}\n$$\n"},"/math/nonlinear-optimization#Active-constraints":{"id":"/math/nonlinear-optimization#Active-constraints","title":"/math/nonlinear-optimization#Active-constraints","tags":"[]#Active-constraints","body":"$$\nI(\\bold x ) = \\{i \\in 1,...,m \\,|\\, g_i(\\bold x) = 0\\}\n$$\n"},"/math/nonlinear-optimization#Inner-gradient-cone":{"id":"/math/nonlinear-optimization#Inner-gradient-cone","title":"/math/nonlinear-optimization#Inner-gradient-cone","tags":"[]#Inner-gradient-cone","body":"$$\nG^o(\\bold x) = \\{\\bold p \\in \\R^n \\,|\\, \\nabla g_i(\\bold x)^\\mathsf{T} \\bold p < 0, \\forall i \\in I(\\bold x)\\}\n$$\n"},"/math/nonlinear-optimization#Gradient-cone":{"id":"/math/nonlinear-optimization#Gradient-cone","title":"/math/nonlinear-optimization#Gradient-cone","tags":"[]#Gradient-cone","body":"$$\nG(\\bold x) = \\{\\bold p \\in \\R^n \\,|\\, \\nabla g_i(\\bold x)^\\mathsf{T} \\bold p \\leq 0, \\forall i \\in I(\\bold x)\\}\n$$\n"},"/math/nonlinear-optimization#Nicely-behaving-set":{"id":"/math/nonlinear-optimization#Nicely-behaving-set","title":"/math/nonlinear-optimization#Nicely-behaving-set","tags":"[]#Nicely-behaving-set","body":"$$\nG^o(\\bold x) \\sube R_s (\\bold x) \\sube T_s(\\bold x) \\sube G(\\bold x)\n$$\n"},"/math/nonlinear-optimization#Fritz-John-conditions":{"id":"/math/nonlinear-optimization#Fritz-John-conditions","title":"/math/nonlinear-optimization#Fritz-John-conditions","tags":"[]#Fritz-John-conditions","body":"$$\nx^* \\, \\text{local min} \\implies F^o (\\bold x) \\cap G^o (\\bold x) = \\empty\n$$\n"},"/math/nonlinear-optimization#Constraint-qualification-(CQ)":{"id":"/math/nonlinear-optimization#Constraint-qualification-(CQ)","title":"/math/nonlinear-optimization#Constraint-qualification-(CQ)","tags":"[]#Constraint-qualification-(CQ)","body":"Defines some regularity over the set\n"},"/math/nonlinear-optimization#Abadie's-CQ":{"id":"/math/nonlinear-optimization#Abadie's-CQ","title":"/math/nonlinear-optimization#Abadie's-CQ","tags":"[]#Abadie's-CQ","body":"Holds at a point $ \\bold x \\in S $ if $ T_s(\\bold x) = G(\\bold x) $\n"},"/math/nonlinear-optimization#Linear-independence-CQ-(LICQ)":{"id":"/math/nonlinear-optimization#Linear-independence-CQ-(LICQ)","title":"/math/nonlinear-optimization#Linear-independence-CQ-(LICQ)","tags":"[]#Linear-independence-CQ-(LICQ)","body":"We say that LICQ holds at $ \\bold x $ if the gradients $ \\nabla g_i (\\bold x), i \\in I(\\bold x) $ for the active constraints are linearly independent.\n"},"/math/nonlinear-optimization#Affine-CQ":{"id":"/math/nonlinear-optimization#Affine-CQ","title":"/math/nonlinear-optimization#Affine-CQ","tags":"[]#Affine-CQ","body":"We say that the Affine CQ holds if all the constraints $ g_i $ are affine.\n"},"/math/nonlinear-optimization#Slater-CQ":{"id":"/math/nonlinear-optimization#Slater-CQ","title":"/math/nonlinear-optimization#Slater-CQ","tags":"[]#Slater-CQ","body":"We say that Slater's CQ holds if all $ g_i $ are convex and an inner point exists.\n"},"/math/nonlinear-optimization#Karush-Kuhn-Tucker-conditions-(KKT)":{"id":"/math/nonlinear-optimization#Karush-Kuhn-Tucker-conditions-(KKT)","title":"/math/nonlinear-optimization#Karush-Kuhn-Tucker-conditions-(KKT)","tags":"[]#Karush-Kuhn-Tucker-conditions-(KKT)","body":"Assume that Abadie's CQ holds at a point $ \\bold x^* $ which is feasible in (P), then\n$$\nx^* \\, \\text{local min} \\implies\n\\begin{cases}\n\\nabla f(\\bold x^*) + \\sum_{i=1}^m \\mu_i \\nabla g_i (\\bold x^*) &= \\bold 0 \\\\\n\\mu_i g_i(\\bold x^*) &= 0, i=1,...,m \\\\\n\\mu_i &\\geq 0, i=1,...,m\n\\end{cases}\n$$\n"},"/math/nonlinear-optimization#Sufficiency-of-KKT-conditions":{"id":"/math/nonlinear-optimization#Sufficiency-of-KKT-conditions","title":"/math/nonlinear-optimization#Sufficiency-of-KKT-conditions","tags":"[]#Sufficiency-of-KKT-conditions","body":"If the objective function $ f $ is convex and all constraint functions $ g_i $ are convex, the the following holds\n$$\n\\bold x^* \\, \\text{KKT point} \\implies \\bold x^* \\, \\text{global optimum}\n$$\n"},"/math/nonlinear-optimization#Lagrangian-duality/relaxation":{"id":"/math/nonlinear-optimization#Lagrangian-duality/relaxation","title":"/math/nonlinear-optimization#Lagrangian-duality/relaxation","tags":"[]#Lagrangian-duality/relaxation","body":"A relaxation to\n$$\n\\begin{aligned}\n\\text{min} & \\qquad f(\\bold x) \\\\\ns.t. & \\qquad \\bold x \\in S\n\\end{aligned}\n$$\nis\n$$\n\\begin{aligned}\n\\text{min} & \\qquad f_R(\\bold x) \\\\\ns.t. & \\qquad \\bold x \\in S_R\n\\end{aligned}\n$$\nwhere $ S \\sube S_R $ and $ f_R(\\bold x) \\leq f(\\bold x), \\,\\, \\forall \\bold x \\in S $\n"},"/math/nonlinear-optimization#Relaxation-Theorem":{"id":"/math/nonlinear-optimization#Relaxation-Theorem","title":"/math/nonlinear-optimization#Relaxation-Theorem","tags":"[]#Relaxation-Theorem","body":"$$\n\\begin{aligned}\na)& \\, f_R^* \\leq f^*\\\\\nb)& \\, \\text{If the relaxed problem is infeasible, the original is as well} \\\\\nc)& \\, \\text{If the relaxed problem has an optimal solution } \\bold x_R^* \\text{ for which it holds that } \\bold x_R^* \\in S \\text{ and } f_R^*(\\bold x_R^*) = f(\\bold x_R^*) \\text{ then } \\bold x_R^* \\text{ is also optimal in the original problem.}\n\\end{aligned}\n$$\n"},"/math/nonlinear-optimization#Lagrangian-relaxation":{"id":"/math/nonlinear-optimization#Lagrangian-relaxation","title":"/math/nonlinear-optimization#Lagrangian-relaxation","tags":"[]#Lagrangian-relaxation","body":"This is the primal problem\n$$\n\\begin{aligned}\n\\text{inf} \\qquad & f(\\bold x) \\\\\n\\text{s.t.} \\qquad & g_i(\\bold x) \\leq 0, \\qquad i=1,...,m \\\\\n& \\bold x \\in X\n\\end{aligned}\n$$\nand this is the dual problem\n"},"/math/nonlinear-optimization#Lagrangian-dual-function":{"id":"/math/nonlinear-optimization#Lagrangian-dual-function","title":"/math/nonlinear-optimization#Lagrangian-dual-function","tags":"[]#Lagrangian-dual-function","body":"$$\n\\begin{aligned}\n\\underset{\\bold x \\in X}{\\text{min}} \\, L(\\bold x, \\bold \\mu) = q(\\bold \\mu) = \\text{inf} \\qquad & [f(\\bold x + \\sum_{i=1}^m \\mu_i g_i (\\bold x)) ] \\\\\n\\text{s.t.} \\qquad & \\bold x \\in X\n\\end{aligned}\n$$\n"},"/math/nonlinear-optimization#Weak-duality":{"id":"/math/nonlinear-optimization#Weak-duality","title":"/math/nonlinear-optimization#Weak-duality","tags":"[]#Weak-duality","body":"For any $ \\bold \\mu \\geq 0 $ and any feasible $ \\bold x $ to the primal problem, it holds that\n$$\nq(\\bold \\mu) \\leq f(\\bold x)\n$$\n"},"/math/nonlinear-optimization#Lagrangian-dual-problem":{"id":"/math/nonlinear-optimization#Lagrangian-dual-problem","title":"/math/nonlinear-optimization#Lagrangian-dual-problem","tags":"[]#Lagrangian-dual-problem","body":"The dual function $ q $ is concave and its effective domain is convex.\n$$\n\\boxed{\n\\begin{aligned}\nq^* = \\text{sup} \\qquad & q(\\bold \\mu) \\\\\n\\text{s.t.} \\qquad & \\bold \\mu \\geq 0\\\\\n\\end{aligned}\n}\n$$\n"},"/math/nonlinear-optimization#Lagrange-multiplier":{"id":"/math/nonlinear-optimization#Lagrange-multiplier","title":"/math/nonlinear-optimization#Lagrange-multiplier","tags":"[]#Lagrange-multiplier","body":"$ \\bold \\mu^* $ is a Lagrange multiplier if $ q(\\bold \\mu^*) = f^*$\n"},"/math/nonlinear-optimization#Strong-duality":{"id":"/math/nonlinear-optimization#Strong-duality","title":"/math/nonlinear-optimization#Strong-duality","tags":"[]#Strong-duality","body":"Assume that there exists a inner pint to the primal problem, and that $ f^* \\geq - \\inf $, that $ f $ is a convex function, that $ g_i, \\,q i=1,...,m $ are convex functions and that $ X $ is a convex set. Then the following holds\n$$\nq^* = f^*\n$$\n"},"/math/nonlinear-optimization#Basic-solution":{"id":"/math/nonlinear-optimization#Basic-solution","title":"/math/nonlinear-optimization#Basic-solution","tags":"[]#Basic-solution","body":"A point $ \\bold x $ is a basic solution if $ A \\bold x = \\bold b $ and the columns of A corresponding to non-zero elements of $ \\bold x $ are linearly independent.\n"},"/math/nonlinear-optimization#Basic-feasible-solution-(BFS)":{"id":"/math/nonlinear-optimization#Basic-feasible-solution-(BFS)","title":"/math/nonlinear-optimization#Basic-feasible-solution-(BFS)","tags":"[]#Basic-feasible-solution-(BFS)","body":"A point $ \\bold x $ is a BFS if $ \\bold x \\geq 0 $, $ A \\bold x = \\bold b $ and the columns of A corresponding to non-zero elements in $ \\bold x $ are linearly independent.\n"},"/math/nonlinear-optimization#Degenerate-BFS":{"id":"/math/nonlinear-optimization#Degenerate-BFS","title":"/math/nonlinear-optimization#Degenerate-BFS","tags":"[]#Degenerate-BFS","body":"Consider a BFS with $ \\bold x = [\\bold x_B \\, \\bold x_N]^\\mathsf{T} $. By definition $ \\bold x_N = \\bold 0 $ and $ \\bold x_B = B^{-1} \\bold b $. If some elements of $ \\bold x_B $ are zero the BFS is called degenerate.\n"},"/math/nonlinear-optimization#Simplex-method":{"id":"/math/nonlinear-optimization#Simplex-method","title":"/math/nonlinear-optimization#Simplex-method","tags":"[]#Simplex-method","body":"Consider\n$$\n\\begin{aligned}\n\\text{min} \\qquad & \\bold c^\\mathsf{T} \\bold x \\\\\n\\text{s.t.} \\qquad & \\bold x \\in P \\\\\n\\end{aligned}\n$$\nConvert this problem to standard form. To find an initial BFS solve the Phase I problem. That is add as many artificial variables as you need to form the initial base vector as the identity matrix and consider minimizing the artificial variables. Use the Simplex method to move out all artificial variables from the base vector. When this is achieved we have solved the Phase I problem. If we can form the identity matrix without artificial variables go directly to the Phase II problem with this as the base. When we have an initial BFS we solve the Phase II problem, that is the original problem. For each iteration begin by determining $ \\bold x_B = B^{-1} \\bold b $ and $ \\bold x_N = \\bold 0 $, e.g. we could have $  \\bold x_B = [x_1 \\, x_2]^\\mathsf{T} $ and $  \\bold x_N = [s_1 \\, s_2]^\\mathsf{T} $. We also calculate $ B $ and $ N $ which corresponds to the same variables for the partition in $ A $, as well as $ \\bold c_B $ and $ \\bold c_N $ in a similar manner. Then we calculate the incoming variable (from $ N $) with the following formula:\n$$\n\\tilde \\bold c_N^\\mathsf{T} = \\bold c_N^\\mathsf{T} - \\bold c_B^\\mathsf{T} B^{-1} N\n$$\nThen we need to calculate the outgoing variable (from $ B $). We do this by\n$$\n\\underset{k:(B^{-1}N_j)_k > 0}{\\text{arg min}} = \\frac{(B^{-1} \\bold b)_k}{(B^{-1} N_j)_k}\n$$\nWe update the variables and go back and start over. We need to check that $ B^{-1} \\bold b \\geq 0 $ for feasible solution, that $ B^{-1} N_j \\geq 0 $ so that we do not have an unbounded solution. We terminate the algorithm when our cost vector $ c_N^\\mathsf{T} \\geq 0 $.\n"},"/math/nonlinear-optimization#LP-duality":{"id":"/math/nonlinear-optimization#LP-duality","title":"/math/nonlinear-optimization#LP-duality","tags":"[]#LP-duality","body":"This problem is called the primal (P)\n$$\n\\begin{aligned}\nz^* = \\text{inf} \\qquad & \\bold c^\\mathsf{T} \\bold x \\\\\n\\text{s.t.} \\qquad & A \\bold x = \\bold b \\\\\n& \\bold x \\geq 0\n\\end{aligned}\n$$\nand this is the corresponding dual problem (D)\n$$\n\\begin{aligned}\nq^* = \\text{sup} \\qquad & \\bold b^\\mathsf{T} \\bold y \\\\\n\\text{s.t.} \\qquad & A^\\mathsf{T} \\bold y \\leq \\bold c \\\\\n& \\bold y \\in \\R^n\n\\end{aligned}\n$$\nThe following relation holds for the primal and dual\n| | Primal | | Dual |\n|-|-|-|-|\n| Objective | min | | max |\n| Variables | $ \\geq 0 $ (canonical) | Constraints | $ \\leq $ |\n| | $ \\leq 0 $ (non-canonical) | | $ \\geq $ |\n| | free | | $ = $ |\n| Constraints | $ \\geq $ (canonical) | Variables | $ \\geq 0 $ |\n| | $ \\leq $ (non-canonical) | | $ \\leq 0 $ |\n| | $ = $  | | free |\n"},"/math/nonlinear-optimization#Weak-duality-theorem":{"id":"/math/nonlinear-optimization#Weak-duality-theorem","title":"/math/nonlinear-optimization#Weak-duality-theorem","tags":"[]#Weak-duality-theorem","body":"If $ \\bold x $ is a feasible point in (P) and $ \\bold y $ is a feasible point in (D) then\n$$\n\\bold c^\\mathsf{T} \\bold x  \\geq \\bold b^\\mathsf{T} \\bold y\n$$\n"},"/math/nonlinear-optimization#Strong-duality-theorem":{"id":"/math/nonlinear-optimization#Strong-duality-theorem","title":"/math/nonlinear-optimization#Strong-duality-theorem","tags":"[]#Strong-duality-theorem","body":"If both (P) and (D) are feasible then\n1. There exists $ \\bold x^* $ optimal in (P) and $ \\bold y^* $ optimal in (D)\n2. $ \\bold c^\\mathsf{T} \\bold x^* = \\bold b^\\mathsf{T} \\bold y^* $ (meaning $ z^* = q^* $)\n"},"/math/nonlinear-optimization#Possibilities-in-(P)-and-(D)":{"id":"/math/nonlinear-optimization#Possibilities-in-(P)-and-(D)","title":"/math/nonlinear-optimization#Possibilities-in-(P)-and-(D)","tags":"[]#Possibilities-in-(P)-and-(D)","body":"| P\\D | Finite optima | Unbounded | Infeasible |\n|-|-|-|-|\n| Finite optima | X | | |\n| Unbounded | | | X |\n| Infeasible | | X | X |\n"},"/math/nonlinear-optimization#Perturbation":{"id":"/math/nonlinear-optimization#Perturbation","title":"/math/nonlinear-optimization#Perturbation","tags":"[]#Perturbation","body":"A perturbation is a small change to either $ A, \\bold c  $ or $ \\bold b $.\n"},"/math/nonlinear-optimization#Subgradient-method":{"id":"/math/nonlinear-optimization#Subgradient-method","title":"/math/nonlinear-optimization#Subgradient-method","tags":"[]#Subgradient-method","body":"For convex problems we can relax the differentiability assumption and use something like the subgradient method. Let $ S \\sube \\R^n $ be a nonempty convex set and let $ f: S \\to \\R $ be a convex function. The $ \\bold p \\in \\R^n $ is called a subgradient of $ f $ at $ \\bar{\\bold x} \\in S $ if\n$$\nf(\\bold x) \\geq f(\\bar{\\bold x}) + \\bold p^\\mathsf{T} (\\bold x - \\bar{\\bold x}), \\qquad \\text{for any } \\bold x \\in S.\n$$\nThe set of all subgradients to $ f $ at $ \\bar{\\bold x} $ is called the subdifferential of $ f $ and is defined as\n$$\n\\partial f(\\bar{\\bold x}) = \\{ \\bold p \\in \\R^n \\, | \\, f(\\bold x) \\geq f(\\bar{\\bold x}) + \\bold p^\\mathsf{T} (\\bold x - \\bar{\\bold x}), \\text{for all } \\bold x \\in S \\}\n$$\n"},"/math/nonlinear-optimization#Integer-Linear-Programming-(ILP)":{"id":"/math/nonlinear-optimization#Integer-Linear-Programming-(ILP)","title":"/math/nonlinear-optimization#Integer-Linear-Programming-(ILP)","tags":"[]#Integer-Linear-Programming-(ILP)","body":""},"/math/nonlinear-optimization#Logical-constraints":{"id":"/math/nonlinear-optimization#Logical-constraints","title":"/math/nonlinear-optimization#Logical-constraints","tags":"[]#Logical-constraints","body":"- if $ x $ then $ y \\implies x \\leq y$\n- xor $ \\implies x + y = 1$\n- or $ \\implies x + y \\geq 1 $\n- exactly one $ \\implies \\sum_{i=1}^n x_i = 1$\n- at least one $ \\implies \\sum_{i=1}^n x_i \\geq 1$\n"},"/math/nonlinear-optimization#Disjoint-feasible-sets":{"id":"/math/nonlinear-optimization#Disjoint-feasible-sets","title":"/math/nonlinear-optimization#Disjoint-feasible-sets","tags":"[]#Disjoint-feasible-sets","body":"$$\n\\begin{aligned}\n0 \\leq x \\leq 1 \\cup 5 & \\leq x \\leq 8  \\implies \\\\\nx \\geq 0 \\\\\nx \\leq 8 \\\\\nx \\leq 1 + 7 y \\\\\nx \\geq 5y \\\\\ny = \\{0, 1\\}\n\\end{aligned}\n$$\n"},"/math/nonlinear-optimization#Feasible-direction-methods":{"id":"/math/nonlinear-optimization#Feasible-direction-methods","title":"/math/nonlinear-optimization#Feasible-direction-methods","tags":"[]#Feasible-direction-methods","body":"These methods are just as local as unconstrained methods, but we find search direction in different ways and termination criteria is often based on KKT. For general sets it could be tricky to find search directions and step lengths. Three well known methods are the **Frank-Wolfe method**, **Simplicial decomposition** and the **Gradient projection algorithm**. These method apply on polyhedron.\n"},"/math/nonlinear-optimization#Frank-Wolfe-method":{"id":"/math/nonlinear-optimization#Frank-Wolfe-method","title":"/math/nonlinear-optimization#Frank-Wolfe-method","tags":"[]#Frank-Wolfe-method","body":"The idea of the Frank-Wolfe method is to calculate the direction of a linear approximation at a point $ x $, find the nearest extreme point with the simplex method and go in the direction of the extreme point.\n"},"/math/nonlinear-optimization#Simplicial-decomposition":{"id":"/math/nonlinear-optimization#Simplicial-decomposition","title":"/math/nonlinear-optimization#Simplicial-decomposition","tags":"[]#Simplicial-decomposition","body":"It works like the Frank-Wolfe algorithm but it remembers previous extreme points and searches in the convex hull of these points for the next iterations.\n"},"/math/nonlinear-optimization#Gradient-projection-algorithm":{"id":"/math/nonlinear-optimization#Gradient-projection-algorithm","title":"/math/nonlinear-optimization#Gradient-projection-algorithm","tags":"[]#Gradient-projection-algorithm","body":"Based on the idea that this holds at a local min:\n$$\n\\bold x^* = \\text{Proj}_X [ \\bold x^* - \\nabla f(\\bold x^*) ]\n$$\nFor every iteration choose the next $ x_{k+1} $ as follows\n$$\n\\bold x_{k+1}  = \\text{Proj}_X [ \\bold x_k - \\alpha_k f(\\bold x_k) ]\n$$\nwhere $ \\alpha_k > 0 $ for some feasible direction.\n"},"/math/nonlinear-optimization#Penalty-methods":{"id":"/math/nonlinear-optimization#Penalty-methods","title":"/math/nonlinear-optimization#Penalty-methods","tags":"[]#Penalty-methods","body":"The idea of penalty methods is to transform a constrained problem to a unconstrained problem.\n$$\n\\boxed{\n    \\begin{aligned}\n    \\text{min} \\qquad & f(\\bold x) \\\\\n    \\text{s.t.} \\qquad & \\bold x \\in S \\\\\n    \\end{aligned}\n}\n\\iff\n\\boxed{\n    \\begin{aligned}\n    \\text{min} \\qquad & f(\\bold x) + \\chi_S (\\bold x) \\\\\n    \\text{s.t.} \\qquad & \\bold x \\in \\R^n \\\\\n    \\end{aligned}\n}\n$$\nwhere $ \\chi_S (\\bold x) = \\begin{cases}\n0 &\\text{if } \\bold x \\in S \\\\\n+\\infty &\\text{otherwise}\n\\end{cases} $\n"},"/math/nonlinear-optimization#Exterior-penalty-method":{"id":"/math/nonlinear-optimization#Exterior-penalty-method","title":"/math/nonlinear-optimization#Exterior-penalty-method","tags":"[]#Exterior-penalty-method","body":"Suppose that\n$$\n\\begin{aligned}\n\\qquad\\underset{\\bold x \\in S}{\\text{minimize}} \\qquad & f(\\bold x),  \\\\\n\\text{subject to} \\qquad & g_i(\\bold x) \\leq 0, \\qquad i \\in \\mathcal{I} \\qquad \\\\\n& h_i(\\bold x) = 0, \\qquad i \\in \\mathcal{E} \\\\\n& \\bold x \\in \\Chi\n\\end{aligned}\n$$\nChoose a penalty method, e.g.\n$$\n\\begin{aligned}\n\\psi_1 (s) = | s | \\\\\n\\psi_2 (s) =  s^2 \\\\\n\\end{aligned}\n$$\nApproximate the indicator function $ \\chi_s (\\bold x) $\n$$\n\\chi_s (\\bold x) \\approx \\nu \\bar \\chi_s (\\bold x) = \\nu \\Big [\\sum_{i=1}^m \\psi (\\text{max}(0, g_i(\\bold x))) + \\sum_{j=1}^l \\psi (h_j(\\bold x)) \\Big ]\n$$\n"},"/math/nonlinear-optimization#Interior-penalty-method":{"id":"/math/nonlinear-optimization#Interior-penalty-method","title":"/math/nonlinear-optimization#Interior-penalty-method","tags":"[]#Interior-penalty-method","body":"Suppose that\n$$\n\\begin{aligned}\n\\qquad\\underset{\\bold x \\in S}{\\text{minimize}} \\qquad & f(\\bold x),  \\\\\n\\text{subject to} \\qquad & g_i(\\bold x) \\leq 0, \\qquad i \\in \\mathcal{I} \\qquad \\\\\n& \\bold x \\in \\Chi\n\\end{aligned}\n$$\nAssume that $ g_i(\\bar \\bold x) < 0, \\,\\, i=1,...,m, \\, \\exists \\bar \\bold x \\in \\R^n $ (an interior point should exist)\nChoose a penalty method, e.g.\n$$\n\\begin{aligned}\n\\phi_1 (s) &= - \\frac{1}{s} \\\\\n\\phi_2 (s) &=  - \\text{log}(\\text{min} (1, -s)) \\\\\n\\end{aligned}\n$$\nApproximate the indicator function $ \\chi_s (\\bold x) $\n$$\n\\chi_s (\\bold x) \\approx \\nu \\bar \\chi_s (\\bold x) =\n\\begin{cases}\n\\nu \\sum_{i=1}^m \\phi (g_i (\\bold x)) & \\text{if } g_i(\\bold x) < 0, i=1,...,m \\\\\n+ \\infty & \\text{otherwise}\n\\end{cases}\n$$\n"},"/math/number-theory#":{"id":"/math/number-theory#","title":"/math/number-theory#","tags":"[]#","body":""},"/math/number-theory#Greatest-common-divisor-(GCD)":{"id":"/math/number-theory#Greatest-common-divisor-(GCD)","title":"/math/number-theory#Greatest-common-divisor-(GCD)","tags":"[]#Greatest-common-divisor-(GCD)","body":"The greatest common divisor between two or more integers, is the largest positive integer that divides each of the integers. A common approach of calculating the greatest common divisor is to use Euclidean algorithm\n```r\nfunction gcd(a, b)\n    if b == 0\n        return a\n    else\n        return gcd(b, a mod b)\n```\n"},"/math/probability-theory#":{"id":"/math/probability-theory#","title":"/math/probability-theory#","tags":"[]#","body":""},"/math/probability-theory#Random-variable":{"id":"/math/probability-theory#Random-variable","title":"/math/probability-theory#Random-variable","tags":"[]#Random-variable","body":"A random variable is a variable whose outcome depends on a random event. In probability theory a random variable is understood as a measurable function defined on the @(probability space)(probability-space). A random variable maps from the sample space to any measurable space with some probability.\n"},"/math/probability-theory#Probability-mass-function":{"id":"/math/probability-theory#Probability-mass-function","title":"/math/probability-theory#Probability-mass-function","tags":"[]#Probability-mass-function","body":"The probability mass function, also known as the discrete density function, is a function that gives the exact probability of a discrete random variable to some value. It differs from the probability density function in that it is associated with discrete random variables instead of continuous random variables.\n"},"/math/probability-theory#Probability-density-function":{"id":"/math/probability-theory#Probability-density-function","title":"/math/probability-theory#Probability-density-function","tags":"[]#Probability-density-function","body":"The probability density function (PDF) must be integrated over an interval to yield the probability. It is defined as follows\n$$\n\\Pr (a \\leq X \\leq b) = \\int_a^b f_X (x) dx\n$$\nIn the continuous case the probability of a point always gives the probability 0, $ \\Pr(X = x) = 0 $, which is why we need to evaluate it over an interval instead.\n"},"/math/probability-theory#Stochastic-process":{"id":"/math/probability-theory#Stochastic-process","title":"/math/probability-theory#Stochastic-process","tags":"[]#Stochastic-process","body":"A stochastic process is a random process that is usually defined as a family of random variables.\nThus, each random variable takes the value from the same mathematical space known as the @(state space)(state-space).\nThere are two types of stochastic processes, that is, @(discrete-time)(discrete-time) and @(continuous-time)(continuous-time) stochastic processes.\nExamples of stochastic processes are the Bernoulli process @{bernoulli} and random walk among others. The Bernoulli process can be looked as flipping a coin multiple times where the sequence of flipped coins represents several independent and identically distributed (i.i.d) Bernoulli random variables.\n"},"/math/probability-theory#Statistical-inference":{"id":"/math/probability-theory#Statistical-inference","title":"/math/probability-theory#Statistical-inference","tags":"[]#Statistical-inference","body":"Statistical inference is the process of inferring properties of an underlying distribution of probability using data analysis.\nCreating logical claims that is justified by the data.\n"},"/math/probability-theory#Classical-inference":{"id":"/math/probability-theory#Classical-inference","title":"/math/probability-theory#Classical-inference","tags":"[]#Classical-inference","body":"In classical inference (Frequentist) parameters are fixed or non-random quantities and the probability only concerns the data. For a Frequentist the probability of an event is the proportion of that event in the long run.\n"},"/math/probability-theory#Bayesian-inference":{"id":"/math/probability-theory#Bayesian-inference","title":"/math/probability-theory#Bayesian-inference","tags":"[]#Bayesian-inference","body":"Bayesian inference is a method used to update the probability of a model using Bayes' theorem\n$$\n\\Pr(A\\mid B)=\\frac {\\Pr(B\\mid A)\\Pr(A)}{\\Pr(B)}\n$$\nContrary to how classical inference work, Bayesian inference take into account the uncertainty of the parameters when creating the model. The parameters themselves are random variables. The Bayesian approach bases its decision on prior knowledge.\n"},"/math/probability-theory#Kolmogorov-axioms":{"id":"/math/probability-theory#Kolmogorov-axioms","title":"/math/probability-theory#Kolmogorov-axioms","tags":"[]#Kolmogorov-axioms","body":"The Kolmogorov axioms consist of of three axioms that is the foundation of probability theory.\n"},"/math/probability-theory#First-axiom":{"id":"/math/probability-theory#First-axiom","title":"/math/probability-theory#First-axiom","tags":"[]#First-axiom","body":"The probability of an event is always positive.\n$$\n\\Pr(E) \\in \\R_+, \\qquad \\forall E \\in F\n$$\nwhere $ F $ is the event space.\n"},"/math/probability-theory#Second-axiom":{"id":"/math/probability-theory#Second-axiom","title":"/math/probability-theory#Second-axiom","tags":"[]#Second-axiom","body":"The probability that at least one of outcomes in the sample space will occur has the probability of 1.\n$$\n\\Pr(\\Omega) = 1\n$$\nwhere $ \\Omega $ is the sample space.\n"},"/math/probability-theory#Third-axiom":{"id":"/math/probability-theory#Third-axiom","title":"/math/probability-theory#Third-axiom","tags":"[]#Third-axiom","body":"Any countable sequence of mutually exclusive events $ E_1, E_2, ... $ satisfies\n$$\n\\Pr\\left(\\bigcup _{i=1}^{\\infty }E_{i}\\right)=\\sum _{i=1}^{\\infty }\\Pr(E_{i}).\n$$\n"},"/math/probability-theory#Conditional-probability":{"id":"/math/probability-theory#Conditional-probability","title":"/math/probability-theory#Conditional-probability","tags":"[]#Conditional-probability","body":"The conditional probability of event $ A $ occurring after event $ B $ is defined as\n$$\n\\Pr(A \\mid B) = \\frac{\\Pr(A \\cap B)}{\\Pr(B)}\n$$\n"},"/math/probability-theory#Independent-events":{"id":"/math/probability-theory#Independent-events","title":"/math/probability-theory#Independent-events","tags":"[]#Independent-events","body":"Two events are independent if\n$$\n\\Pr (A \\cap B) = \\Pr(A)\\Pr(B)\n$$\nThus the following holds for conditional independent events\n$$\n\\Pr(A \\mid B) = \\frac{\\Pr(A \\cap B)}{\\Pr(B)} = \\frac{\\Pr(A)\\Pr(B)}{\\Pr(B)} = \\Pr(A)\n$$\n"},"/math/probability-theory#Total-law-of-probability":{"id":"/math/probability-theory#Total-law-of-probability","title":"/math/probability-theory#Total-law-of-probability","tags":"[]#Total-law-of-probability","body":"Given an event $ A $, what is the probability of $ A $ given $ B $ every single $ B $?\nThe total law of probability states that if we have a sequence of events $ B_n $ that partitions the sample space the following holds\n$$\n P(A)=\\sum _{n}P(A\\cap B_{n}) =\\sum _{n}P(A\\mid B_{n})P(B_{n})\n$$\n"},"/math/probability-theory#Joint-distributions":{"id":"/math/probability-theory#Joint-distributions","title":"/math/probability-theory#Joint-distributions","tags":"[]#Joint-distributions","body":"Given multiple different random variables $ X_1, \\dots, X_n $ defined on the same probability space is a probability distribution that gives the probability that each random variable falls into a particular set of values.\n$$\np_{X_1, \\dots, X_n} (x_1, \\dots, x_n) = \\Pr (X_1 = x_1, \\dots, X_n = x_n)\n$$\nIt could be written in terms of conditional probabilities with the chain rule property\n$$\n {\n\\begin{aligned}\np_{X_{1},\\ldots ,X_{n}}(x_{1},\\ldots ,x_{n})&=\\mathrm {\\Pr} (X_{1}=x_{1})\\cdot \\mathrm {\\Pr} (X_{2}=x_{2}\\mid X_{1}=x_{1})\\\\\n&\\cdot \\mathrm {\\Pr} (X_{3}=x_{3}\\mid X_{1}=x_{1},X_{2}=x_{2})\\\\\n&\\dots\\\\\n&\\cdot \\Pr(X_{n}=x_{n}\\mid X_{1}=x_{1},X_{2}=x_{2},\\dots ,X_{n-1}=x_{n-1})\n\\end{aligned}}\n$$\n"},"/math/probability-theory#Chain-rule":{"id":"/math/probability-theory#Chain-rule","title":"/math/probability-theory#Chain-rule","tags":"[]#Chain-rule","body":"The chain rule of probabilities can be described by the following example\n$$\n{\\begin{aligned}\n\\mathrm {Pr} (X_{4},X_{3},X_{2},X_{1})&=\\mathrm {Pr} (X_{4}\\mid X_{3},X_{2},X_{1})\\cdot \\mathrm {Pr} (X_{3},X_{2},X_{1})\\\\&=\\mathrm {Pr} (X_{4}\\mid X_{3},X_{2},X_{1})\\cdot \\mathrm {Pr} (X_{3}\\mid X_{2},X_{1})\\cdot \\mathrm {Pr} (X_{2},X_{1})\\\\&=\\mathrm {Pr} (X_{4}\\mid X_{3},X_{2},X_{1})\\cdot \\mathrm {Pr} (X_{3}\\mid X_{2},X_{1})\\cdot \\mathrm {Pr} (X_{2}\\mid X_{1})\\cdot \\mathrm {Pr} (X_{1})\n\\end{aligned}}\n$$\n"},"/math/probability-theory#Expectation":{"id":"/math/probability-theory#Expectation","title":"/math/probability-theory#Expectation","tags":"[]#Expectation","body":"Expectation is the expected value a distribution takes on, the most common outcome.\n"},"/math/probability-theory#Discrete":{"id":"/math/probability-theory#Discrete","title":"/math/probability-theory#Discrete","tags":"[]#Discrete","body":"$$\nE[X] = \\sum_x x \\Pr (X = x)\n$$\n"},"/math/probability-theory#Continuous":{"id":"/math/probability-theory#Continuous","title":"/math/probability-theory#Continuous","tags":"[]#Continuous","body":"$$\nE[X] = \\int_x x \\Pr (X = x) dx\n$$\n"},"/math/probability-theory#Conditional-discrete":{"id":"/math/probability-theory#Conditional-discrete","title":"/math/probability-theory#Conditional-discrete","tags":"[]#Conditional-discrete","body":"$$\nE[X \\mid Y = y] = \\sum_x x \\Pr (X = x \\mid y)\n$$\n"},"/math/probability-theory#Conditional-continuous":{"id":"/math/probability-theory#Conditional-continuous","title":"/math/probability-theory#Conditional-continuous","tags":"[]#Conditional-continuous","body":"$$\nE[X \\mid Y = y] = \\int_x x \\Pr (X = x \\mid y) dx\n$$\n"},"/math/probability-theory#Total-law-of-expectation-discrete":{"id":"/math/probability-theory#Total-law-of-expectation-discrete","title":"/math/probability-theory#Total-law-of-expectation-discrete","tags":"[]#Total-law-of-expectation-discrete","body":"$$\nE[X] = \\sum_y E[X \\mid Y = y] \\Pr(X = x)\n$$\n"},"/math/probability-theory#Total-law-of-expectation-continuous":{"id":"/math/probability-theory#Total-law-of-expectation-continuous","title":"/math/probability-theory#Total-law-of-expectation-continuous","tags":"[]#Total-law-of-expectation-continuous","body":"$$\nE[X] = \\int_y E[X \\mid Y = y] \\Pr(X = x) dy\n$$\nIn both the discrete and the continuous case they could be written as\n$$\nE[X] = E[E[X \\mid Y]]\n$$\n"},"/math/probability-theory#Variance":{"id":"/math/probability-theory#Variance","title":"/math/probability-theory#Variance","tags":"[]#Variance","body":"Variance is defined as\n$$\n\\text{Var} (X) = E[X^2] - E[X]^2\n$$\n"},"/math/probability-theory#Total-law-of-variance":{"id":"/math/probability-theory#Total-law-of-variance","title":"/math/probability-theory#Total-law-of-variance","tags":"[]#Total-law-of-variance","body":"$$\n\\text{Var} (X) = E[\\text{Var} (X \\mid Y) ] + \\text{Var} (E[X \\mid Y])\n$$\n"},"/math/probability-theory#Covariance":{"id":"/math/probability-theory#Covariance","title":"/math/probability-theory#Covariance","tags":"[]#Covariance","body":"Covariance is defined as\n$$\n \\begin{aligned}\\operatorname {cov} (X,Y)&=\\operatorname {E} \\left[\\left(X-\\operatorname {E} \\left[X\\right]\\right)\\left(Y-\\operatorname {E} \\left[Y\\right]\\right)\\right]\\\\&=\\operatorname {E} \\left[XY-X\\operatorname {E} \\left[Y\\right]-\\operatorname {E} \\left[X\\right]Y+\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]\\right]\\\\&=\\operatorname {E} \\left[XY\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]+\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right]\\\\&=\\operatorname {E} \\left[XY\\right]-\\operatorname {E} \\left[X\\right]\\operatorname {E} \\left[Y\\right],\\end{aligned}\n$$\nHowever this is susceptible to catastrophic cancellation @{catastrophic}, which means that subtracting good approximations of two nearby numbers may yield a bad approximation to the difference of the original numbers.\n"},"/math/probability-theory#Correlation":{"id":"/math/probability-theory#Correlation","title":"/math/probability-theory#Correlation","tags":"[]#Correlation","body":"Correlation is defined as\n$$\n \\rho _{X,Y}=\\operatorname {corr} (X,Y)={\\operatorname {cov} (X,Y) \\over \\sigma _{X}\\sigma _{Y}}={\\operatorname {E} [(X-\\mu _{X})(Y-\\mu _{Y})] \\over \\sigma _{X}\\sigma _{Y}}\n$$\nwhere $ \\mu_X = E[X] $, $ \\mu_Y = E[Y] $, $ \\sigma_X$ and $ \\sigma_Y $ represents the standard deviation.\n"},"/math/probability-theory#Order-statistics":{"id":"/math/probability-theory#Order-statistics","title":"/math/probability-theory#Order-statistics","tags":"[]#Order-statistics","body":"The kth order statistic of a statistical sample is equal to its kth-smallest value.\n"},"/math/probability-theory#Hoeffding-inequality":{"id":"/math/probability-theory#Hoeffding-inequality","title":"/math/probability-theory#Hoeffding-inequality","tags":"[]#Hoeffding-inequality","body":"https://en.wikipedia.org/wiki/Hoeffding%27s_inequality\nHoeffding inequality states an upper bound on the probability that the sum\n$$\n{\\displaystyle {\\begin{aligned}\\operatorname {P} \\left(S_{n}-\\mathrm {E} \\left[S_{n}\\right]\\geq t\\right)&\\leq \\exp \\left(-{\\frac {2t^{2}}{\\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\\right)\\\\\\operatorname {P} \\left(\\left|S_{n}-\\mathrm {E} \\left[S_{n}\\right]\\right|\\geq t\\right)&\\leq 2\\exp \\left(-{\\frac {2t^{2}}{\\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\\right)\\end{aligned}}}\n$$\n"},"/math/probability-theory#Boole's-inequality":{"id":"/math/probability-theory#Boole's-inequality","title":"/math/probability-theory#Boole's-inequality","tags":"[]#Boole's-inequality","body":"Boole's inequality is also known as the **union bound**. It states that for any finite set of events the probability that at least one of the events happens is no greater than the sum of the probabilities of the individual events.\n$$\n {\\mathbb {P} }\\left(\\bigcup _{i=1}^{\\infty }A_{i}\\right)\\leq \\sum _{i=1}^{\\infty }{\\mathbb {P} }(A_{i}).\n$$\n"},"/math/probability-theory#References":{"id":"/math/probability-theory#References","title":"/math/probability-theory#References","tags":"[]#References","body":"{bernoulli}:\n    title: Bernoulli process\n    url: https://en.wikipedia.org/wiki/Bernoulli_process\n{catastrophic}:\n    title: Catastrophic cancellation\n    url: https://en.wikipedia.org/wiki/Catastrophic_cancellation\n"},"/math/series#":{"id":"/math/series#","title":"/math/series#","tags":"[]#","body":""},"/math/series#Arithmetic-sum":{"id":"/math/series#Arithmetic-sum","title":"/math/series#Arithmetic-sum","tags":"[]#Arithmetic-sum","body":"The arithmetic sum of a sequence of numbers is\n$$\n\\frac{n(a_1 + a_n)}{2}\n$$\nwhere $ a_1 $ is the smallest value in the sequence and $ a_n $ is the biggest value in the sequence.\n"},"/math/series#Geometric-sum":{"id":"/math/series#Geometric-sum","title":"/math/series#Geometric-sum","tags":"[]#Geometric-sum","body":"When $ r \\neq 1 $, the sum of the first $ n + 1 $ terms is\n$$\na+ar+ar^{2}+ar^{3}+\\cdots +ar^{n}=\\sum _{k=0}^{n}ar^{k}=a\\left({\\frac {1-r^{n+1}}{1-r}}\\right)\n$$\n"},"/math/series#Geometric-sum-for-probabilities":{"id":"/math/series#Geometric-sum-for-probabilities","title":"/math/series#Geometric-sum-for-probabilities","tags":"[]#Geometric-sum-for-probabilities","body":"When $ r $ is between $ [0,1] $ we can write the geometric sum as\n$$\n\\sum _{k=0}^{\\infty } ar^k = \\frac{a}{(1 - r)}\n$$\n"},"/math/statistics#":{"id":"/math/statistics#","title":"/math/statistics#","tags":"[]#","body":""},"/math/stochastic-processes#":{"id":"/math/stochastic-processes#","title":"/math/stochastic-processes#","tags":"[]#","body":""},"/math/stochastic-processes#Markov-chains":{"id":"/math/stochastic-processes#Markov-chains","title":"/math/stochastic-processes#Markov-chains","tags":"[]#Markov-chains","body":"A markov chain is a sequence of random variables, $ X_0, X_1, \\dots $, with the following property\n$$\n\\Pr(X_{n+1} = j \\mid X_0 = x_0,\\dots, X_n = i) = \\Pr(X_{n+1} = j \\mid X_n = i)\n$$\nfor all $ x_0,\\dots,i,j $ that is included in the @(state space)(state-space) of the Markov chain. The state space is a discrete set.\n"},"/math/stochastic-processes#Stochastic-matrix":{"id":"/math/stochastic-processes#Stochastic-matrix","title":"/math/stochastic-processes#Stochastic-matrix","tags":"[]#Stochastic-matrix","body":"A stochastic matrix is a square matrix, $ P $, that satisfy\n1. $ P_{ij} \\geq 0 $ for all $ i, j $\n2. For each row $ i, \\sum_j P_{ij} = 1 $\n"},"/math/stochastic-processes#N-step-transition-matrix":{"id":"/math/stochastic-processes#N-step-transition-matrix","title":"/math/stochastic-processes#N-step-transition-matrix","tags":"[]#N-step-transition-matrix","body":"Let $ X_0, X_1, \\dots $ be a Markov chain with transition matrix $ P $. Then $ P^n $ is the n-step transition matrix and we can calculate the probability that we go from state $ i $ to state $ j $ in n steps\n$$\nP_{ij}^n = \\Pr(X_n = j \\mid X_0 = i), \\qquad \\text{for all} \\,\\, i, j\n$$\n"},"/math/stochastic-processes#Distribution-of-Markov-chains":{"id":"/math/stochastic-processes#Distribution-of-Markov-chains","title":"/math/stochastic-processes#Distribution-of-Markov-chains","tags":"[]#Distribution-of-Markov-chains","body":"The sequence of random variables $ X_0, X_1, \\dots $ is generally not identically distributed random variables in the Markov chain. If our Markov chains has the transition matrix $ P $ and the initial distribution $ \\alpha $, the distribution for $ X_n $ is\n$$\n\\alpha P^n\n$$\nNamely,\n$$\n\\Pr(X_n = j) = (\\alpha P^n)_j, \\qquad \\text{for all } j \\text{ and } n \\geq 0\n$$\n"},"/math/stochastic-processes#Markov-property":{"id":"/math/stochastic-processes#Markov-property","title":"/math/stochastic-processes#Markov-property","tags":"[]#Markov-property","body":"The Markov property states that the past and future is independent given the present. The present here could be looked as the most recent past. Let $ X_0, X_1, \\dots $ be a Markov chain. Then for all $ m < n $\n$$\n\\begin{aligned}\n\\Pr(X_{n+1} = j \\mid X_0 = x_0, \\dots, X_{n-m} = i) &= \\Pr(X_{n+1} = j \\mid X_{n-m} = i) \\\\\n&= \\Pr(X_{m+1} = j \\mid X_0 = i) \\\\\n&= P_{ij}^{m+1}\n\\end{aligned}\n$$\nfor all $ x_0,\\dots, i,j $ and $ n \\geq 0 $\n"},"/math/stochastic-processes#Joint-distribution":{"id":"/math/stochastic-processes#Joint-distribution","title":"/math/stochastic-processes#Joint-distribution","tags":"[]#Joint-distribution","body":"The marginal distributions of Markov chains are determined by the initial distribution $ \\alpha $ and the transition matrix $ P $. If we consider the join probability of\n$$\n\\Pr(X_5 = i, X_6 = j, X_9 = k) \\text{ for some states } i,j,k\n$$\nThe resulting event is then moving to $ i $ in five steps, then to $ j $ in one step and then to $ k $ in three steps. The resulting probability is calculated with\n$$\n(\\alpha P^5)_i P_{ij} P_{jk}^3\n$$\nThis is obtained by combining the Markov property with conditional probability and time-homogeneity. Formally, let $ X_0, X_1, \\dots $ be a Markov chain with transition matrix $ P $ and initial distribution $ \\alpha $. Then for all $ 0 \\leq n_1 < \\dots < n_k $ and states $ i_1, \\dots, i_k $\n$$\n\\Pr(X_{n_1} = i_1, X_{n_k} = i_k) = (\\alpha P^{n_1})_{i_1} \\cdots P^{n_k - n_{k - 1}}_{i_{k-1}i_k}\n$$\n"},"/math/stochastic-processes#Stationary-distribution":{"id":"/math/stochastic-processes#Stationary-distribution","title":"/math/stochastic-processes#Stationary-distribution","tags":"[]#Stationary-distribution","body":"A stationary distribution is such a distribution $ \\pi $, that if the distribution over states at step $ k $ is $ \\pi $, then also the distribution over states at step $ k+1 $ is $ \\pi $. That is,\n$$\n\\pi = \\pi P\n$$\nTo find a stationary distribution, the above equation is redundant, and we must use the fact that $ \\pi_1, \\dots, \\pi_n = 1 $. Then we are able to obtained the unique solution.\n"},"/math/stochastic-processes#Limiting-distribution":{"id":"/math/stochastic-processes#Limiting-distribution","title":"/math/stochastic-processes#Limiting-distribution","tags":"[]#Limiting-distribution","body":"The limiting distribution for undirected weighted graphs is given by the balance functions. In the following example it is\n$$\n(\\frac{w_1 + w_2 + w_4}{W}, \\frac{w_1 + w_3 + w_5}{W}, \\frac{w_2 + w_3 + w_6}{W})\n$$\nwhere $ W = w_1 + w_2 + w_4 + w_1 + w_3 + w_5 + w_2 + w_3 + w_6 $. Thus, the sum of all the edges from each node divided by the sum of the total number of edges.\n"},"/math/stochastic-processes#Positive-matrix":{"id":"/math/stochastic-processes#Positive-matrix","title":"/math/stochastic-processes#Positive-matrix","tags":"[]#Positive-matrix","body":"A matrix $ M $ is said to be **positive** if all the entries of the matrix is **positive**.\n"},"/math/stochastic-processes#Regular-transition-matrix":{"id":"/math/stochastic-processes#Regular-transition-matrix","title":"/math/stochastic-processes#Regular-transition-matrix","tags":"[]#Regular-transition-matrix","body":"A transition matrix $ P $ is said to be **regular** if some power of $ P $ is **positive**.\n"},"/math/stochastic-processes#Limit-theorem-for-regular-Markov-chains":{"id":"/math/stochastic-processes#Limit-theorem-for-regular-Markov-chains","title":"/math/stochastic-processes#Limit-theorem-for-regular-Markov-chains","tags":"[]#Limit-theorem-for-regular-Markov-chains","body":"If the transition matrix is regular, a limiting distribution exists. It is unique as well. All of the limiting probabilities are positive.\n"},"/math/stochastic-processes#Communication-class":{"id":"/math/stochastic-processes#Communication-class","title":"/math/stochastic-processes#Communication-class","tags":"[]#Communication-class","body":"If a Markov chain has exactly one communication class, all states communicate with each other. Think of it as if every state can eventually communicate with each other. If we have multiple communication classes one state may not be able to communicate with another state in $ n $ steps.\n"},"/math/stochastic-processes#Closed-communication-class":{"id":"/math/stochastic-processes#Closed-communication-class","title":"/math/stochastic-processes#Closed-communication-class","tags":"[]#Closed-communication-class","body":"A communication class is closed if it consists of all recurrent states.\n"},"/math/stochastic-processes#Irreducibility":{"id":"/math/stochastic-processes#Irreducibility","title":"/math/stochastic-processes#Irreducibility","tags":"[]#Irreducibility","body":"A Markov chain is called **irreducible** if it has exactly one communication class. Thus, if the matrix is regular we know it is also irreducible. Finite irreducible Markov chains have unique positive stationary distributions if it is aperiodic as well.\n"},"/math/stochastic-processes#Limit-theorem-for-finite-irreducible-Markov-chains":{"id":"/math/stochastic-processes#Limit-theorem-for-finite-irreducible-Markov-chains","title":"/math/stochastic-processes#Limit-theorem-for-finite-irreducible-Markov-chains","tags":"[]#Limit-theorem-for-finite-irreducible-Markov-chains","body":"Let $ \\mu_j = E[T_j \\mid X_0 = j] $ be the expected return time to j. Then $ \\mu_j < \\infty $ and the vector $ v $ with $ v_j = \\frac{1}{\\mu_j} $ is a stationary distribution. All finite regular Markov chains are finite irreducible Markov chains.\nFurthermore,\n$$\nv_j = \\underset{n \\to \\infty}{\\lim} \\frac{1}{n} \\sum_{m=0}^{n-1} (P^m)_{ij}\n$$\n"},"/math/stochastic-processes#Recurrent-state":{"id":"/math/stochastic-processes#Recurrent-state","title":"/math/stochastic-processes#Recurrent-state","tags":"[]#Recurrent-state","body":"A recurrent state has the property that a Markov chain starting at this state eventually returns to that state.\n"},"/math/stochastic-processes#-Transient-state":{"id":"/math/stochastic-processes#-Transient-state","title":"/math/stochastic-processes#-Transient-state","tags":"[]#-Transient-state","body":"A transient state has the property that a Markov chain starting at this state has a positive probability of never returning to this state.\n"},"/math/stochastic-processes#Periodicity":{"id":"/math/stochastic-processes#Periodicity","title":"/math/stochastic-processes#Periodicity","tags":"[]#Periodicity","body":"The states of a communication class all have the same period. The period of a state is defined as\n$$\nd(i) = \\gcd(n > 0 : P_{ij}^n > 0)\n$$\nThus, if a Markov chain is irreducible and all states have a period greater to one, the Markov chain is **periodic**.\n"},"/math/stochastic-processes#Aperiodic":{"id":"/math/stochastic-processes#Aperiodic","title":"/math/stochastic-processes#Aperiodic","tags":"[]#Aperiodic","body":"When the period is $ d(i) = 1 $ the state is said to be **aperiodic**. Thus, if a Markov chain is irreducible and all states have a period equal to one, the Markov chain is **aperiodic**.\n"},"/math/stochastic-processes#Ergodic":{"id":"/math/stochastic-processes#Ergodic","title":"/math/stochastic-processes#Ergodic","tags":"[]#Ergodic","body":"A Markov chain is said to be **ergodic** if it is irreducible, aperiodic and all states have finite expected return times (all states are positive recurrent). Ergodic Markov chains have positive limiting distributions. That is, let $ X_0, X_1, \\dots $ be an ergodic Markov chain. Then there exists a unique positive stationary distribution which also is the limiting distribution for the Markov chain.\n"},"/math/stochastic-processes#Fundamental-limit-theorem-of-ergodic-Markov-chains":{"id":"/math/stochastic-processes#Fundamental-limit-theorem-of-ergodic-Markov-chains","title":"/math/stochastic-processes#Fundamental-limit-theorem-of-ergodic-Markov-chains","tags":"[]#Fundamental-limit-theorem-of-ergodic-Markov-chains","body":"There exists a unique positive stationary distribution that is the limiting distribution of the Markov chain.\n"},"/math/stochastic-processes#Time-reversibility":{"id":"/math/stochastic-processes#Time-reversibility","title":"/math/stochastic-processes#Time-reversibility","tags":"[]#Time-reversibility","body":"A continuous-time Markov chain with generator matrix $ Q $ and a **unique** stationary distribution $ \\pi $ is time reversible if\n$$\n\\pi_i q_{ij} = \\pi_j q_{ji} \\qquad \\text{ for all } i,j\n$$\nThis is called the **local balance** or **detailed balance** equations, and the states that the long-term transition rate from $ i $ to $ j $ is equal to the long-term transition rate from $ j $ to $ i $.\n"},"/math/stochastic-processes#Absorbing-chains":{"id":"/math/stochastic-processes#Absorbing-chains","title":"/math/stochastic-processes#Absorbing-chains","tags":"[]#Absorbing-chains","body":"A Markov chain is called an absorbing chain if it has at least one absorbing state, that is, a state that is $ P_{ii} = 1 $. When dealing with absorbing Markov chains we usually split the matrix into different partitions and write it like\n$$\nP=\n\\left({\\begin{array}{c|c}\nQ & R\\\\\n\\hline\n{\\mathbf {0}} & I\n\\end{array}}\n\\right)\n$$\nwhere $ Q $ is a $ t \\times t $ matrix, $ R $ is a $ t \\times (k - t) $ matrix, $ \\mathbf{0} $ is a $ (k - t) \\times t $ matrix full of 0s, and $ I $ is a $ (k -t) \\times (k - t) $ identity matrix.\n"},"/math/stochastic-processes#Fundamental-matrix":{"id":"/math/stochastic-processes#Fundamental-matrix","title":"/math/stochastic-processes#Fundamental-matrix","tags":"[]#Fundamental-matrix","body":"The fundamental matrix for continuous-time Markov chain is defined as\n$$\nF = -V^{-1}\n$$\n"},"/math/stochastic-processes#Absorption-probability":{"id":"/math/stochastic-processes#Absorption-probability","title":"/math/stochastic-processes#Absorption-probability","tags":"[]#Absorption-probability","body":"The probability that the Markov chain is absorbed in state $ j $ when starting in state $ i $ is given by\n$$\n(FR)_{ij}\n$$\n"},"/math/stochastic-processes#Absorption-time":{"id":"/math/stochastic-processes#Absorption-time","title":"/math/stochastic-processes#Absorption-time","tags":"[]#Absorption-time","body":"The expected number of steps until the Markov chain is absorbed when starting in state $ i $ is given by\n$$\n(F1)_i\n$$\n"},"/math/stochastic-processes#First-hitting-time-for-irreducible-chain":{"id":"/math/stochastic-processes#First-hitting-time-for-irreducible-chain","title":"/math/stochastic-processes#First-hitting-time-for-irreducible-chain","tags":"[]#First-hitting-time-for-irreducible-chain","body":"First hitting time for irreducible chain is given by modifying the transition matrix $ P $ so that the we are interested in, is an absorbing state.\n"},"/math/stochastic-processes#Continuous-Markov-chains":{"id":"/math/stochastic-processes#Continuous-Markov-chains","title":"/math/stochastic-processes#Continuous-Markov-chains","tags":"[]#Continuous-Markov-chains","body":""},"/math/stochastic-processes#Markov-Property":{"id":"/math/stochastic-processes#Markov-Property","title":"/math/stochastic-processes#Markov-Property","tags":"[]#Markov-Property","body":"A continuous-time stochastic process $ (X_t)_{t \\geq 0} $ with discrete state space, $ S $, is a continuous-time Markov chain if\n$$\n\\Pr(X_{t+s} = j \\mid X_s = i, X_u = u, 0 \\leq u < s) = \\Pr(X_{t+s} = j \\mid X_s = i)\n$$\nfor all $ s,t \\geq 0, i,j,x_u \\in S, 0 \\leq u < s$. If the process does not depend on $ s $ it is said to be **time-homogeneous**.\n$$\n\\Pr(X_{t+s} = j \\mid X_s = i) = \\Pr(X_{t} = j \\mid X_0 = i)\n$$\nfor $ s \\geq 0 $.\n"},"/math/stochastic-processes#Transition-function":{"id":"/math/stochastic-processes#Transition-function","title":"/math/stochastic-processes#Transition-function","tags":"[]#Transition-function","body":"The transition probabilities can be arranged in a matrix function for each $ t \\geq 0 $ that is called the transition function\n$$\nP_{ij} (t) = \\Pr(X_t = j \\mid X_0 = i)\n$$\n"},"/math/stochastic-processes#Champman-Kolmogorov-Equations":{"id":"/math/stochastic-processes#Champman-Kolmogorov-Equations","title":"/math/stochastic-processes#Champman-Kolmogorov-Equations","tags":"[]#Champman-Kolmogorov-Equations","body":"For a continuous Markov chain $ (X_t)_{t \\geq 0} $ with transition $ \\bold P(t) $,\n$$\n\\bold P(s + t) = \\bold P(s) \\bold P(t)\n$$\nfor $ s,t \\geq 0 $.\n"},"/math/stochastic-processes#Holding-times":{"id":"/math/stochastic-processes#Holding-times","title":"/math/stochastic-processes#Holding-times","tags":"[]#Holding-times","body":"The holding time, $ T_i $ at a state $ i $ is the length of time that a continuous-time Markov chain stays in $ i $ before transitioning to a new state. $ T_i $ has an exponential distribution.\n"},"/math/stochastic-processes#Absorbing-state":{"id":"/math/stochastic-processes#Absorbing-state","title":"/math/stochastic-processes#Absorbing-state","tags":"[]#Absorbing-state","body":"For each state $ i $, let $ q_i $ be the parameter of the exponential distribution for the holding time $ T_i  $. If $ q_i $ is defined to be in the interval $ (0, \\infty) $, a continuous-time process with $ q_i = 0 $, $ i $ is said to be an **absorbing state**. This is because when the process visits state $ i $ it never leaves.\n"},"/math/stochastic-processes#Explosive":{"id":"/math/stochastic-processes#Explosive","title":"/math/stochastic-processes#Explosive","tags":"[]#Explosive","body":"For each state $ i $, let $ q_i $ be the parameter of the exponential distribution for the holding time $ T_i  $. If $ q_i $ is defined to be in the interval $ (0, \\infty) $, a continuous-time process with $ q_i = \\infty $ is said to be an **explosive**. This is because the process may visit state $ i $ infinitely many times at one time instant.\n"},"/math/stochastic-processes#Embedded-chain":{"id":"/math/stochastic-processes#Embedded-chain","title":"/math/stochastic-processes#Embedded-chain","tags":"[]#Embedded-chain","body":"The embedded chain in a continuous-time Markov chain is the discrete-time Markov chain with the transition probabilities for each state. The transition matrix $ \\widetilde P $ for the embedded chain is a stochastic matrix with diagonal entries 0.\n"},"/math/stochastic-processes#Transition-rates":{"id":"/math/stochastic-processes#Transition-rates","title":"/math/stochastic-processes#Transition-rates","tags":"[]#Transition-rates","body":"The $ q_{ij} $ is called the transition rates for a continuous-time process. With the transition rates we may obtain the embedded chain transition probabilities and the holding time parameters.\n"},"/math/stochastic-processes#Absorbing-chain":{"id":"/math/stochastic-processes#Absorbing-chain","title":"/math/stochastic-processes#Absorbing-chain","tags":"[]#Absorbing-chain","body":"In a continuous-time Markov chain we write the $ Q $ matrix in the following form\n$$\nQ = \\left({\\begin{array}{c|c}\n0 & \\mathbf{0}\\\\\n\\hline\n* & V\n\\end{array}}\n\\right)\n$$\nwhere $ V $ is a $ (k - 1) \\times (k - 1) $ matrix.\n"},"/math/stochastic-processes#Mean-time-until-absorption":{"id":"/math/stochastic-processes#Mean-time-until-absorption","title":"/math/stochastic-processes#Mean-time-until-absorption","tags":"[]#Mean-time-until-absorption","body":"The mean time until absorption for a chain that started in $ i $ is\n$$\na_i = (F1)_i = \\sum_{j} F_{ij}\n$$\n"},"/math/stochastic-processes#Stationary-distribution-with-generator-matrix":{"id":"/math/stochastic-processes#Stationary-distribution-with-generator-matrix","title":"/math/stochastic-processes#Stationary-distribution-with-generator-matrix","tags":"[]#Stationary-distribution-with-generator-matrix","body":"A continuous-time Markov chain has a stationary distribution $ \\pi $ if and only if\n$$\n\\pi Q = 0\n$$\nTo compute this we need to use fact that $ \\sum_i \\pi_i = 1 $. One of the equations in $ \\pi Q = 0 $ is therefore redundant and we may remove whichever.\n"},"/math/stochastic-processes#Global-balance":{"id":"/math/stochastic-processes#Global-balance","title":"/math/stochastic-processes#Global-balance","tags":"[]#Global-balance","body":"If $ \\pi $ is a stationary distribution of a continuous-time Markov chain. From $ \\pi Q = 0 $ we get\n$$\n\\sum_{i \\neq j} \\pi_i q_{ij} = \\pi_j q_j \\qquad \\text{for all } j\n$$\nThis is called the **global balance** equations. They say that the transition rates in and out from any state are the same when stationary.\n"},"/math/stochastic-processes#Little's-formula":{"id":"/math/stochastic-processes#Little's-formula","title":"/math/stochastic-processes#Little's-formula","tags":"[]#Little's-formula","body":"In a queueing system we can describe the long-term properties by the following formula\n$$\nL = \\lambda W\n$$\nwhere $ L $ is the long-term average number of customers in the system, $ \\lambda $ is the rate of arrivals, $ W $ is the long-term average time that a customer spends in the system.\n"},"/math/stochastic-processes#Branching-process":{"id":"/math/stochastic-processes#Branching-process","title":"/math/stochastic-processes#Branching-process","tags":"[]#Branching-process","body":"In a branching process all nonzero states are transient.\n"},"/math/stochastic-processes#Mean-generation-size":{"id":"/math/stochastic-processes#Mean-generation-size","title":"/math/stochastic-processes#Mean-generation-size","tags":"[]#Mean-generation-size","body":"In a branching process the size of the nth generation is the sum of the individuals in the previous generation.\n$$\nZ_n = \\sum_{i=1}^{Z_{n-1}} X_i\n$$\nThe long-term generation size could be divided into three cases\n$$\n\\underset{n \\to \\infty}{\\lim} E(Z_n) = \\underset{n \\to \\infty}{\\lim} \\mu^n =\n\\begin{cases}\n0, & \\text{if} \\,\\, \\mu < 1\\\\\n1, & \\text{if} \\,\\,\\mu = 1\\\\\n\\infty, & \\text{if} \\,\\, \\mu > 1\\\\\n\\end{cases}\n$$\n"},"/math/stochastic-processes#Variance-of-the-generation-size":{"id":"/math/stochastic-processes#Variance-of-the-generation-size","title":"/math/stochastic-processes#Variance-of-the-generation-size","tags":"[]#Variance-of-the-generation-size","body":"By the total law of variance the following holds\n$$\n\\text{Var} (Z_n) = E[\\text{Var} (Z_n \\mid Z_{n-1}) ] + \\text{Var} (E[Z_n \\mid Z_{n-1}])\n$$\n"},"/math/stochastic-processes#Probability-generating-function":{"id":"/math/stochastic-processes#Probability-generating-function","title":"/math/stochastic-processes#Probability-generating-function","tags":"[]#Probability-generating-function","body":"In the discrete case, the probability generating function of the discrete random variable $ X $ is\n$$\nG(s) = E [s^X] = \\sum_{k=0}^{\\infty} s^k \\Pr(X = k)\n$$\nWe can see that $ G(1) = 1 $. If we do successive differentiations we obtain\n$$\n\\begin{aligned}\nG(0) &= \\Pr(X = 0) \\\\\nG'(0) &= \\Pr(X = 1) \\\\\nG''(0) &= 2\\Pr(X = 2) \\\\\nG^{(j)}(0) &= j!\\Pr(X = j) \\\\\n\\end{aligned}\n$$\nThis is useful for computing the probability given the generating function\n$$\n\\Pr(X = j) = \\frac{G^{(j)}(0)}{j!}\n$$\nSo if we know the generating function of a distribution we can use this to find out what distribution we have.\n"},"/math/stochastic-processes#Sums-of-independent-random-variables":{"id":"/math/stochastic-processes#Sums-of-independent-random-variables","title":"/math/stochastic-processes#Sums-of-independent-random-variables","tags":"[]#Sums-of-independent-random-variables","body":"If we let $ Z = X_1 + \\dots + X_n $, the probability generating function of $ Z $ is\n$$\nG_Z(s) = E[s^Z] = E[s^{X_1 + \\dots + X_n}] = E(\\prod_{k = 1}^n s^{X_k}) =\\prod_{k = 1}^n E(s^{X_k}) = G_{X_1}(s) \\cdots G_{X_n}(s)\n$$\nIf $ X_k $ also is identically distributed we can simplify\n$$\nG_Z(s) = |G_X(s)|^n\n$$\n"},"/math/stochastic-processes#Moments":{"id":"/math/stochastic-processes#Moments","title":"/math/stochastic-processes#Moments","tags":"[]#Moments","body":"We may find the mean and the variance with the probability generating function\n$$\n\\begin{aligned}\nG'(1) &= E[X] \\\\\nG''(1) &= E[X^2] - E[X]\n\\end{aligned}\n$$\nwhich gives\n$$\n\\begin{aligned}\nE[X] &= G'(1) \\\\\n\\text{Var}(X) &= G''(1) + G'(1) - G'(1)^2 \\\\\n\\end{aligned}\n$$\n"},"/math/stochastic-processes#Extinction-forever":{"id":"/math/stochastic-processes#Extinction-forever","title":"/math/stochastic-processes#Extinction-forever","tags":"[]#Extinction-forever","body":"We can find the probability that a branching process may go extinct in the case $ \\mu > 1 $, (when $ \\mu \\leq 1 $ the probability of going extinct is 1)\nIn general we can write the generating function for the nth generation as\n$$\nG_n(s) = G(G_{n-1}(s))\n$$\nHowever it is not as useful in practical terms, only for proving that the probability of eventual extinction is the smallest root of the equation\n$$\ns = G(s)\n$$\n"},"/math/stochastic-processes#Markov-chains-Monte-Carlo":{"id":"/math/stochastic-processes#Markov-chains-Monte-Carlo","title":"/math/stochastic-processes#Markov-chains-Monte-Carlo","tags":"[]#Markov-chains-Monte-Carlo","body":"Instead of looking at a Markov chain and learn what happens when then number of steps approaches infinity, the limiting distribution, we know start with a target distribution, the limiting distribution and then derive the Markov chain from that.\nIf we can get enough samples of the Markov chain we know that we have an approximate sample from our target distribution.\nComputing the marginal likelihood function is challenging in many different models.\n"},"/math/stochastic-processes#The-law-of-large-numbers":{"id":"/math/stochastic-processes#The-law-of-large-numbers","title":"/math/stochastic-processes#The-law-of-large-numbers","tags":"[]#The-law-of-large-numbers","body":"The law of large numbers is central in probability theory. It states that $ X_1, \\dots, X_n,  $ is a sequence of independent and identically distributed random variables with a common mean of $ \\mu < \\infty $, then the following holds with probability 1\n$$\n\\underset{n \\to \\infty}{\\lim} \\frac{X_1 + \\dots + X_n}{n} = \\mu\n$$\nAlso, if $ X $ is a random variable with the same distribution as the sequence and $ r $ is a bounded, real-valued function, then the sequence $ r(X_1), \\dots, r(X_n) $ is also an independent and identically distributed sequence with finite mean and a probability of 1 that the following holds\n$$\n\\underset{n \\to \\infty}{\\lim} \\frac{r(X_1) + \\dots + r(X_n)}{n} = E(r(X))\n$$\n"},"/math/stochastic-processes#Strong-law-of-large-numbers":{"id":"/math/stochastic-processes#Strong-law-of-large-numbers","title":"/math/stochastic-processes#Strong-law-of-large-numbers","tags":"[]#Strong-law-of-large-numbers","body":"Let $ X_1, \\dots, X_n $ be an ergodic Markov chain with stationary distribution $ \\pi $. Let $ X $ be a random variable with distribution $ \\pi $. Let $ r $ be a bounded, real-valued function. Then\n$$\n\\underset{n \\to \\infty}{\\lim} \\frac{r(X_1) + \\dots + r(X_n)}{n} = E(r(X))\n$$\nwhere $ E(r(X)) = \\sum_{j} r(j) \\pi_j $. When using this in practice, we may ignore the first $ m $ elements in the sequence before computing the average to improve accuracy. This technique is called **burn-in**.\n"},"/math/stochastic-processes#Metropolis-Hastings-algorithm":{"id":"/math/stochastic-processes#Metropolis-Hastings-algorithm","title":"/math/stochastic-processes#Metropolis-Hastings-algorithm","tags":"[]#Metropolis-Hastings-algorithm","body":"MMetropolis-Hastings algorithm is one of the most common methods when using Markov chain Monte Carlo. It is a method for obtaining a sequence of random samples from a probability distribution where direct sampling is difficult @{metropolis}. The sequence is used to approximate the distribution. Metropolis-Hasting works quite well in with multidimensional data and there are other methods which is better when working with single-dimensional distributions. The algorithm constructs a reversible Markov chain whose distribution is $ \\pi $, where $ \\pi = (\\pi_1, \\pi_1, \\dots ) $ is a discrete probability distribution.\nThus, the goal of the algorithm is to construct the Markov chain $ X_0, X_1, \\dots $, with stationary $ \\pi $ by simulating $ \\pi $.\n"},"/math/stochastic-processes#Poisson-process":{"id":"/math/stochastic-processes#Poisson-process","title":"/math/stochastic-processes#Poisson-process","tags":"[]#Poisson-process","body":"A Poisson process is a special type of counting process. Events arrive at specific time instants, starting at $ t = 0 $. The we count the number of arrivals that has occurred by the time $ t $.\nWith Poisson processes we may focus on (i) the number of events that occurred between a fixed time interval, (ii) when events occurred, (iii) the behavior of individual events.\n"},"/math/stochastic-processes#Counting-process":{"id":"/math/stochastic-processes#Counting-process","title":"/math/stochastic-processes#Counting-process","tags":"[]#Counting-process","body":"A counting process $ (N_t)_{t\\geq 0} $ a collection of positive integer valued random variables such that $  0 \\leq s \\leq t \\implies N_s \\leq N_t $. Contrary to Markov chains, that operate with a sequence of random variables, a counting process is an uncountable collection indexed over a continuous time interval.\n"},"/math/stochastic-processes#Definition":{"id":"/math/stochastic-processes#Definition","title":"/math/stochastic-processes#Definition","tags":"[]#Definition","body":"A Poisson process is a counting process with the following definition: Let $ \\lambda $ be the parameter of a Poisson process that is a counting process $ (N_t)_{t\\geq 0} $ with the following properties\n1. $ N_0 = 0 $\n2. $ N_t $ has a Poisson distribution with parameter $ \\lambda t $ for all $ t > 0 $\n3. $ N_{t+s} - N_s $ has the same distribution as $ N_t $ for $ s,t > 0 $.\n4. $ N_t - N_s $ and $ N_r - N_q $ are independent random variables for $ 0 \\leq q < r \\leq s < t $.\n"},"/math/stochastic-processes#Stationary-increments":{"id":"/math/stochastic-processes#Stationary-increments","title":"/math/stochastic-processes#Stationary-increments","tags":"[]#Stationary-increments","body":"Stationary increments is the third rule in the definition above. The distribution of the number of arrivals in an interval only depends on the length of the interval.\n"},"/math/stochastic-processes#Independent-increments":{"id":"/math/stochastic-processes#Independent-increments","title":"/math/stochastic-processes#Independent-increments","tags":"[]#Independent-increments","body":"Independent increments is the fourth rule in the definition above. The number of arrivals on disjoint intervals are independent random variables.\n"},"/math/stochastic-processes#First-arrival-times":{"id":"/math/stochastic-processes#First-arrival-times","title":"/math/stochastic-processes#First-arrival-times","tags":"[]#First-arrival-times","body":"If we let $ X $ denote the first arrival time, then $ X > t $ if and only if there are no arrivals in the interval $ [0, t] $. We have\n$$\n\\Pr(X > t) = \\Pr(N_t = 0) = e^{-\\lambda t}, \\qquad t > 0\n$$\nWe can see that $ X $ has an exponential distribution with parameters $ \\lambda $.\n"},"/math/stochastic-processes#Nth-arrival-times":{"id":"/math/stochastic-processes#Nth-arrival-times","title":"/math/stochastic-processes#Nth-arrival-times","tags":"[]#Nth-arrival-times","body":"Let $ S_n $ be the time of the nth arrival in a Poisson process with parameter $ \\lambda $, then $ S_n $ has a gamma distribution with parameters $ n $ and $ \\lambda $ according to\n$$\nf_{S_n} = \\frac{\\lambda ^n t^{n-1} e^{-\\lambda t}}{(n - 1)!}\n$$\n1. $ E[S_n] = \\frac{n}{\\lambda} $\n2. $ \\text{Var} (S_n) = \\frac{n}{\\lambda^2} $\n"},"/math/stochastic-processes#Distribution-of-arrival-times":{"id":"/math/stochastic-processes#Distribution-of-arrival-times","title":"/math/stochastic-processes#Distribution-of-arrival-times","tags":"[]#Distribution-of-arrival-times","body":"Let $ S_1, S_2, \\dots $ be the arrival times of a Poisson process with parameter $ \\lambda $. The joint distribution of $ (S_1, \\dots, S_n) $, conditional on $ N_t = n $, is the distribution of the order statistics of $ n $ independent and identically distributed random variables on $ [0, t] $. We have\n$$\nf(s_1, \\dots, s_n) = \\frac{n!}{t^n}\n$$\nIf we have $ n $ uniformly distributed random variables that are independent and identically distributed on $ [0, t] $, conditional on $ N_t = n $, they have the same distribution as $ (S_1, \\dots, S_n) $.\n"},"/math/stochastic-processes#Memorylessness":{"id":"/math/stochastic-processes#Memorylessness","title":"/math/stochastic-processes#Memorylessness","tags":"[]#Memorylessness","body":"Memorylessness means that the waiting time distributions are the same for all observers, and all observers will wait, on average, the same amount of time. Formally, a random variable $ X $ is memoryless if\n$$\n\\Pr(X > s + t \\mid X > s) = \\Pr(X > t)\n$$\nfor all $ s,t > 0 $.\n"},"/math/stochastic-processes#Thinning":{"id":"/math/stochastic-processes#Thinning","title":"/math/stochastic-processes#Thinning","tags":"[]#Thinning","body":"A thinned Poisson process is a kind of a subprocess to another Poisson process that is independent to another thinned process of the same parent process.\n"},"/math/stochastic-processes#Superposition-process":{"id":"/math/stochastic-processes#Superposition-process","title":"/math/stochastic-processes#Superposition-process","tags":"[]#Superposition-process","body":"If we have $ (N_t^{(1)})_{t\\geq 0}, \\dots, (N_t^{(n)})_{t\\geq 0} $ independent Poisson processes with respective parameters $ \\lambda_1, \\dots, \\lambda_n $, then let $ N_t = N_t^{(1)} + \\dots + N_t^{(n)}$ for $ t \\geq 0 $. $ (N_t)_{t\\geq 0} $ is then a Poisson process with parameters $ \\lambda = \\lambda_1 + \\dots + \\lambda_n $.\n"},"/math/stochastic-processes#Spatial-Poisson-process":{"id":"/math/stochastic-processes#Spatial-Poisson-process","title":"/math/stochastic-processes#Spatial-Poisson-process","tags":"[]#Spatial-Poisson-process","body":"A spatial Poisson process is a collection of random variables $ (N_A)_{A\\sube \\R^d} $ with parameter $ \\lambda $ if\n1. $ N_A $ has a Poisson distribution with parameter $ \\lambda | A |  $ for each bounded set $ A \\sube \\R^d $.\n2. $ N_A $ and $ N_B $ are independent random variables if $ A $ and $ B $ are disjoint sets.\n"},"/math/stochastic-processes#Brownian-motion":{"id":"/math/stochastic-processes#Brownian-motion","title":"/math/stochastic-processes#Brownian-motion","tags":"[]#Brownian-motion","body":"Brownian motion is a continuous stochastic process $ (B_t)_{t \\geq 0} $ that has the following properties\n1. $ B_0 = 0 $\n2. $ B_t \\sim \\text{Normal}(0, t) $, for $ t > 0 $\n3. $ B_{t + s} - B_s \\sim \\text{Normal} (0, t) $, for $ s,t > 0 $\n4. $ B_t - B_s $ is independent from $ B_r - B_q $, for $ 0 \\leq q < r \\leq s < t $\n5. The function $ t \\mapsto B_t $ is continuous with probability 1\n"},"/math/stochastic-processes#Martingale":{"id":"/math/stochastic-processes#Martingale","title":"/math/stochastic-processes#Martingale","tags":"[]#Martingale","body":"A stochastic process $ (Y_t)_{t \\geq 0} $ is a **martingale** if for all $ t \\geq 0 $\n1. $ E[Y_t \\mid Y_t, 0 \\geq r \\geq s] = Y_s $ for all $ 0 \\geq s \\geq t $\n2. $ E[|Y_t|] < \\infty $\n"},"/math/stochastic-processes#Undirected-weighted-graphs":{"id":"/math/stochastic-processes#Undirected-weighted-graphs","title":"/math/stochastic-processes#Undirected-weighted-graphs","tags":"[]#Undirected-weighted-graphs","body":""},"/math/stochastic-processes#References":{"id":"/math/stochastic-processes#References","title":"/math/stochastic-processes#References","tags":"[]#References","body":"{metropolis}:\n    title: Metropolis–Hastings algorithm\n    url: https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\n"},"/meta/structure#":{"id":"/meta/structure#","title":"/meta/structure#","tags":"[]#","body":"<pre style=\"background-color: white;\">\nroot \n├── bandits\n├── control-theory\n├── image-analysis\n├── latex\n├── algorithms\n│   ├── algorithms\n│   ├── cheat-sheet\n│   ├── keywords\n│   └── problem-list\n├── art\n│   └── painters\n├── databases\n│   ├── databases\n│   └── sql\n├── high-performance-computing\n│   └── distributed-systems\n├── machine-learning\n│   ├── collecting-data\n│   ├── dimensionality-reduction\n│   ├── ethics\n│   ├── evaluation\n│   ├── feature-selection\n│   ├── hyperparameters\n│   ├── keywords\n│   ├── linear-classifiers-regressors\n│   ├── machine-learning\n│   ├── neural-networks\n│   ├── optimization\n│   ├── paradigms\n│   ├── preprocessing\n│   └── models\n│       ├── CNN\n│       ├── LSTM\n│       ├── decision-tree\n│       ├── ensembles\n│       ├── random-forests\n│       └── support-vector-machine\n├── math\n│   ├── bayesian-inference\n│   ├── calculus\n│   ├── distributions\n│   ├── keywords\n│   ├── linear-algebra\n│   ├── nonlinear-optimization\n│   ├── number-theory\n│   ├── probability-theory\n│   ├── series\n│   ├── statistics\n│   └── stochastic-processes\n├── meta\n│   └── structure\n├── networking\n│   ├── cryptography\n│   ├── firewall\n│   ├── ip-address\n│   ├── keywords\n│   ├── network-security\n│   ├── osi-model\n│   ├── port\n│   └── protocols\n├── os\n│   ├── file-systems\n│   ├── interprocess-communication\n│   ├── keywords\n│   ├── memory-management\n│   ├── processes-and-threads\n│   └── processors\n├── programming-languages\n│   ├── python\n│   │   ├── matplotlib\n│   │   ├── numpy\n│   │   ├── pandas\n│   │   ├── python\n│   │   └── scikit-learn\n│   └── rust\n│       └── rust\n└── web\n    └── react\n</pre>\n"},"/networking/cryptography#":{"id":"/networking/cryptography#","title":"/networking/cryptography#","tags":"[]#","body":""},"/networking/cryptography#AES":{"id":"/networking/cryptography#AES","title":"/networking/cryptography#AES","tags":"[]#AES","body":"Advanced Encryption Standard\n1. https://sv.wikipedia.org/wiki/Advanced_Encryption_Standard\n2. https://www.moserware.com/2009/09/stick-figure-guide-to-advanced.html\n"},"/networking/cryptography#Asymmetric-key-encryption":{"id":"/networking/cryptography#Asymmetric-key-encryption","title":"/networking/cryptography#Asymmetric-key-encryption","tags":"[]#Asymmetric-key-encryption","body":"One key is often made public. We can either choose to have the encryption key as public or the decryption key as public. In this case everyone can send encrypted messages to the owner of the private key.\nIf the decryption key is public, everyone can verify that the public key has been used to encrypt a message. This can be used to sign documents.\nAsymmetric ciphers are very slow compared to symmetric ciphers and hash functions.\nWith the advances of quantum computing there is a potential to halve the key size for symmetric ciphers (Grover's algorithm @{grover}) and if the factorization problem is solved (Shor's algorithm @{shor})  public key encryption is broken.\n"},"/networking/cryptography#References":{"id":"/networking/cryptography#References","title":"/networking/cryptography#References","tags":"[]#References","body":"{grover}:\n    url: https://en.wikipedia.org/wiki/Grover%27s_algorithm\n{shor}:\n    url: https://en.wikipedia.org/wiki/Shor%27s_algorithm\n"},"/networking/firewall#":{"id":"/networking/firewall#","title":"/networking/firewall#","tags":"[\"wip\"]#","body":""},"/networking/firewall#References":{"id":"/networking/firewall#References","title":"/networking/firewall#References","tags":"[\"wip\"]#References","body":"{wiki}:\n    url: https://en.wikipedia.org/wiki/Firewall_(computing)\n"},"/networking/ip-address#":{"id":"/networking/ip-address#","title":"/networking/ip-address#","tags":"[\"wip\"]#","body":"There are two types of IP addresses: IPv4 and IPv6.\n"},"/networking/ip-address#References":{"id":"/networking/ip-address#References","title":"/networking/ip-address#References","tags":"[\"wip\"]#References","body":"{wiki}:\n    url: https://en.wikipedia.org/wiki/IP_address\n"},"/networking/keywords#":{"id":"/networking/keywords#","title":"/networking/keywords#","tags":"[\"keywords\"]#","body":""},"/networking/keywords#UDP":{"id":"/networking/keywords#UDP","title":"/networking/keywords#UDP","tags":"[\"keywords\"]#UDP","body":"User Datagram Protocol.\n"},"/networking/keywords#TCP":{"id":"/networking/keywords#TCP","title":"/networking/keywords#TCP","tags":"[\"keywords\"]#TCP","body":"Transmission Control Protocol.\n"},"/networking/keywords#RADIUS":{"id":"/networking/keywords#RADIUS","title":"/networking/keywords#RADIUS","tags":"[\"keywords\"]#RADIUS","body":"Remote Authentication Dial In User Service.\n"},"/networking/keywords#TTP":{"id":"/networking/keywords#TTP","title":"/networking/keywords#TTP","tags":"[\"keywords\"]#TTP","body":"Trusted Third Parties.\n"},"/networking/keywords#Roaming":{"id":"/networking/keywords#Roaming","title":"/networking/keywords#Roaming","tags":"[\"keywords\"]#Roaming","body":"Roaming is the ability to get wireless network service in an area that differs from the registered home network location.\n"},"/networking/keywords#Octet":{"id":"/networking/keywords#Octet","title":"/networking/keywords#Octet","tags":"[\"keywords\"]#Octet","body":"The sequence of 8 bits are called an **octet**. A byte may vary depending on the computer architecture.\n"},"/networking/keywords#Ciphers":{"id":"/networking/keywords#Ciphers","title":"/networking/keywords#Ciphers","tags":"[\"keywords\"]#Ciphers","body":"An algorithm to hide information from unauthorized or verify that the information is correctly transmitted.\n"},"/networking/keywords#DES":{"id":"/networking/keywords#DES","title":"/networking/keywords#DES","tags":"[\"keywords\"]#DES","body":"Data Encryption Standard.\n"},"/networking/keywords#3-DES":{"id":"/networking/keywords#3-DES","title":"/networking/keywords#3-DES","tags":"[\"keywords\"]#3-DES","body":"Repeating DES three times with different keys. Is assumed to be safe to use until 2030, but is slow.\n"},"/networking/keywords#AES":{"id":"/networking/keywords#AES","title":"/networking/keywords#AES","tags":"[\"keywords\"]#AES","body":"Advanced Encryption Standard.\n"},"/networking/keywords#RC4":{"id":"/networking/keywords#RC4","title":"/networking/keywords#RC4","tags":"[\"keywords\"]#RC4","body":"Ron's code 4. Is fast but weak.\n"},"/networking/keywords#ECB":{"id":"/networking/keywords#ECB","title":"/networking/keywords#ECB","tags":"[\"keywords\"]#ECB","body":"Electronic Code-Book mode.\n"},"/networking/keywords#CBC":{"id":"/networking/keywords#CBC","title":"/networking/keywords#CBC","tags":"[\"keywords\"]#CBC","body":"Cipher Block Chaining mode.\n"},"/networking/keywords#CTR":{"id":"/networking/keywords#CTR","title":"/networking/keywords#CTR","tags":"[\"keywords\"]#CTR","body":"Counter mode.\n"},"/networking/keywords#Asymmetric-key-encryption":{"id":"/networking/keywords#Asymmetric-key-encryption","title":"/networking/keywords#Asymmetric-key-encryption","tags":"[\"keywords\"]#Asymmetric-key-encryption","body":"One key is used to encrypt the data, and the other is used to decrypt the data. One of the keys can be public.\n"},"/networking/keywords#RSA":{"id":"/networking/keywords#RSA","title":"/networking/keywords#RSA","tags":"[\"keywords\"]#RSA","body":"Rivest, Shamir, Adleman. An encryption algorithm with asymmetric keys.\n"},"/networking/keywords#ECC":{"id":"/networking/keywords#ECC","title":"/networking/keywords#ECC","tags":"[\"keywords\"]#ECC","body":"Elliptic Curve Cryptography.\n"},"/networking/keywords#McEliece":{"id":"/networking/keywords#McEliece","title":"/networking/keywords#McEliece","tags":"[\"keywords\"]#McEliece","body":"An asymmetric encryption algorithm.\n"},"/networking/keywords#Lattice-based-cryptography":{"id":"/networking/keywords#Lattice-based-cryptography","title":"/networking/keywords#Lattice-based-cryptography","tags":"[\"keywords\"]#Lattice-based-cryptography","body":"Cryptography that involves lattices, which is a mathematical property defined in geometry and group theory.\n"},"/networking/keywords#MD5":{"id":"/networking/keywords#MD5","title":"/networking/keywords#MD5","tags":"[\"keywords\"]#MD5","body":"Message Digest 5. A common hash function.\n"},"/networking/keywords#SHA-1":{"id":"/networking/keywords#SHA-1","title":"/networking/keywords#SHA-1","tags":"[\"keywords\"]#SHA-1","body":"Secure hash algorithm.  A common hash function.\n"},"/networking/keywords#SHA-2":{"id":"/networking/keywords#SHA-2","title":"/networking/keywords#SHA-2","tags":"[\"keywords\"]#SHA-2","body":"Family name for SHA-224, SHA-256, SHA-384 and SHA-512. A common hash function.\n"},"/networking/keywords#SHA-3":{"id":"/networking/keywords#SHA-3","title":"/networking/keywords#SHA-3","tags":"[\"keywords\"]#SHA-3","body":"The next generation of hash functions.\n"},"/networking/keywords#HMAC":{"id":"/networking/keywords#HMAC","title":"/networking/keywords#HMAC","tags":"[\"keywords\"]#HMAC","body":"Keyed-Hashing for Message Authentication. A standard for message authentication with MAC.\n"},"/networking/keywords#CBC-MAC":{"id":"/networking/keywords#CBC-MAC","title":"/networking/keywords#CBC-MAC","tags":"[\"keywords\"]#CBC-MAC","body":"Cipher Block Chaining MAC.\n"},"/networking/keywords#Diffie-Hellman-Key-Agreement":{"id":"/networking/keywords#Diffie-Hellman-Key-Agreement","title":"/networking/keywords#Diffie-Hellman-Key-Agreement","tags":"[\"keywords\"]#Diffie-Hellman-Key-Agreement","body":"Offers a secure way of exchanging keys over an untrusted network, but should be used carefully since we are not sure with whom we may share a key with.\n"},"/networking/keywords#TLS":{"id":"/networking/keywords#TLS","title":"/networking/keywords#TLS","tags":"[\"keywords\"]#TLS","body":"Transport Layer Security.\n"},"/networking/keywords#SSH":{"id":"/networking/keywords#SSH","title":"/networking/keywords#SSH","tags":"[\"keywords\"]#SSH","body":"Secure Shell.\n"},"/networking/keywords#IPSec":{"id":"/networking/keywords#IPSec","title":"/networking/keywords#IPSec","tags":"[\"keywords\"]#IPSec","body":"Internet Protocol Security.\n"},"/networking/keywords#CA":{"id":"/networking/keywords#CA","title":"/networking/keywords#CA","tags":"[\"keywords\"]#CA","body":"Certificate Authority.\n"},"/networking/keywords#PKI":{"id":"/networking/keywords#PKI","title":"/networking/keywords#PKI","tags":"[\"keywords\"]#PKI","body":"Public Key Infrastructure.\n"},"/networking/keywords#CRL":{"id":"/networking/keywords#CRL","title":"/networking/keywords#CRL","tags":"[\"keywords\"]#CRL","body":"Certificate Revocation Lists\n"},"/networking/keywords#OCSP":{"id":"/networking/keywords#OCSP","title":"/networking/keywords#OCSP","tags":"[\"keywords\"]#OCSP","body":"Online Certificate Status Protocol.\n"},"/networking/keywords#MITM":{"id":"/networking/keywords#MITM","title":"/networking/keywords#MITM","tags":"[\"keywords\"]#MITM","body":"Man in the Middle.\n"},"/networking/keywords#DOS":{"id":"/networking/keywords#DOS","title":"/networking/keywords#DOS","tags":"[\"keywords\"]#DOS","body":"Denial of Service.\n"},"/networking/keywords#DDOS":{"id":"/networking/keywords#DDOS","title":"/networking/keywords#DDOS","tags":"[\"keywords\"]#DDOS","body":"Distributed Denial of Service.\n"},"/networking/keywords#Ingress-filtering":{"id":"/networking/keywords#Ingress-filtering","title":"/networking/keywords#Ingress-filtering","tags":"[\"keywords\"]#Ingress-filtering","body":"A technique used to ensure that incoming packets are actually from the network they claim to be.\n"},"/networking/keywords#Egress-filtering":{"id":"/networking/keywords#Egress-filtering","title":"/networking/keywords#Egress-filtering","tags":"[\"keywords\"]#Egress-filtering","body":"A technique used to control outgoing packets from a network to ensure that unauthorized or malicious traffic never leaves the network.\n"},"/networking/keywords#ICMP":{"id":"/networking/keywords#ICMP","title":"/networking/keywords#ICMP","tags":"[\"keywords\"]#ICMP","body":"Internet Control Message Protocol.\n"},"/networking/keywords#NAT":{"id":"/networking/keywords#NAT","title":"/networking/keywords#NAT","tags":"[\"keywords\"]#NAT","body":"Network Address Translation.\n"},"/networking/keywords#LSR":{"id":"/networking/keywords#LSR","title":"/networking/keywords#LSR","tags":"[\"keywords\"]#LSR","body":"Loose source route.\n"},"/networking/keywords#SSR":{"id":"/networking/keywords#SSR","title":"/networking/keywords#SSR","tags":"[\"keywords\"]#SSR","body":"Strict source route.\n"},"/networking/keywords#IDS":{"id":"/networking/keywords#IDS","title":"/networking/keywords#IDS","tags":"[\"keywords\"]#IDS","body":"Intrusion Detection System.\n"},"/networking/keywords#SYN":{"id":"/networking/keywords#SYN","title":"/networking/keywords#SYN","tags":"[\"keywords\"]#SYN","body":"Synchronization flag in TCP segment. Used to initiate a connection between two hosts.\n"},"/networking/keywords#ACK":{"id":"/networking/keywords#ACK","title":"/networking/keywords#ACK","tags":"[\"keywords\"]#ACK","body":"Acknowledgement flag in TCP segment. Used to acknowledge a successful transmission of a packet.\n"},"/networking/keywords#RST":{"id":"/networking/keywords#RST","title":"/networking/keywords#RST","tags":"[\"keywords\"]#RST","body":"Reset flag in TCP segment. Used to control whenever a segment arrives that does not meet the criteria for a referenced connection.\n"},"/networking/keywords#RFC":{"id":"/networking/keywords#RFC","title":"/networking/keywords#RFC","tags":"[\"keywords\"]#RFC","body":"Requests for Comments.\n"},"/networking/network-security#":{"id":"/networking/network-security#","title":"/networking/network-security#","tags":"[]#","body":""},"/networking/network-security#User-authentication":{"id":"/networking/network-security#User-authentication","title":"/networking/network-security#User-authentication","tags":"[]#User-authentication","body":""},"/networking/network-security#Cryptography":{"id":"/networking/network-security#Cryptography","title":"/networking/network-security#Cryptography","tags":"[]#Cryptography","body":""},"/networking/network-security#Network-layer-security":{"id":"/networking/network-security#Network-layer-security","title":"/networking/network-security#Network-layer-security","tags":"[]#Network-layer-security","body":""},"/networking/network-security#Transport-layer-security":{"id":"/networking/network-security#Transport-layer-security","title":"/networking/network-security#Transport-layer-security","tags":"[]#Transport-layer-security","body":""},"/networking/network-security#Firewalls":{"id":"/networking/network-security#Firewalls","title":"/networking/network-security#Firewalls","tags":"[]#Firewalls","body":""},"/networking/network-security#List-of-useful-resources":{"id":"/networking/network-security#List-of-useful-resources","title":"/networking/network-security#List-of-useful-resources","tags":"[]#List-of-useful-resources","body":"| Description | Link |\n| - | - |\n| Common mechanisms of attack | https://capec.mitre.org/data/definitions/1000.html |\n| Common domains of attack | https://capec.mitre.org/data/definitions/3000.html |\n| Top tools | https://sectools.org/ |\n| Common Vulnerability and Exposures (CVE) | https://www.cve.org/ |\n| CyberChef | https://gchq.github.io/CyberChef/ |\n"},"/networking/osi-model#":{"id":"/networking/osi-model#","title":"/networking/osi-model#","tags":"[\"wip\"]#","body":"The model OSI model consists of seven layers:\n1. [Physical layer ](https://en.wikipedia.org/wiki/Physical_layer)\n2. [Data Link layer](https://en.wikipedia.org/wiki/Data_link_layer)\n3. [Network layer](https://en.wikipedia.org/wiki/Network_layer)\n4. [Transport layer](https://en.wikipedia.org/wiki/Transport_layer)\n5. [Session layer](https://en.wikipedia.org/wiki/Session_layer)\n6. [Presentation layer](https://en.wikipedia.org/wiki/Presentation_layer)\n7. [Application layer](https://en.wikipedia.org/wiki/Application_layer)\n"},"/networking/osi-model#References":{"id":"/networking/osi-model#References","title":"/networking/osi-model#References","tags":"[\"wip\"]#References","body":"{wiki}:\n    url: https://en.wikipedia.org/wiki/OSI_model\n"},"/networking/port#":{"id":"/networking/port#","title":"/networking/port#","tags":"[\"wip\"]#","body":""},"/networking/protocols#":{"id":"/networking/protocols#","title":"/networking/protocols#","tags":"[\"wip\"]#","body":"1. DNS\n- UDP\n- SMTP\n- POP\n- PAP\n- CHAP\n- LDAP\n- ICMP\n"},"/networking/protocols#RADIUS":{"id":"/networking/protocols#RADIUS","title":"/networking/protocols#RADIUS","tags":"[\"wip\"]#RADIUS","body":"Remote Authentication Dial In User Service.\n1. https://en.wikipedia.org/wiki/RADIUS\n2. https://www.untruth.org/~josh/security/radius/radius-auth.html\nRADIUS is supported and used by almost all vendors of authentication devices and is de-facto standard protocol for remote authentication.\n"},"/networking/protocols#IPv4":{"id":"/networking/protocols#IPv4","title":"/networking/protocols#IPv4","tags":"[\"wip\"]#IPv4","body":"Internet Protocol version 4.\n1. https://en.wikipedia.org/wiki/IPv4\n<table class=\"no-padding\">\n<tbody><tr>\n<th>Offsets\n</th>\n<th>Octet\n</th>\n<th colspan=\"8\">0\n</th>\n<th colspan=\"8\">1\n</th>\n<th colspan=\"8\">2\n</th>\n<th colspan=\"8\">3\n</th></tr>\n<tr>\n<th>Octet\n</th>\n<th>Bit\n</th>\n<th style=\"width:2.6%;\">0\n</th>\n<th style=\"width:2.6%;\">1\n</th>\n<th style=\"width:2.6%;\">2\n</th>\n<th style=\"width:2.6%;\">3\n</th>\n<th style=\"width:2.6%;\">4\n</th>\n<th style=\"width:2.6%;\">5\n</th>\n<th style=\"width:2.6%;\">6\n</th>\n<th style=\"width:2.6%;\">7\n</th>\n<th style=\"width:2.6%;\">0\n</th>\n<th style=\"width:2.6%;\">1\n</th>\n<th style=\"width:2.6%;\">2\n</th>\n<th style=\"width:2.6%;\">3\n</th>\n<th style=\"width:2.6%;\">4\n</th>\n<th style=\"width:2.6%;\">5\n</th>\n<th style=\"width:2.6%;\">6\n</th>\n<th style=\"width:2.6%;\">7\n</th>\n<th style=\"width:2.6%;\">0\n</th>\n<th style=\"width:2.6%;\">1\n</th>\n<th style=\"width:2.6%;\">2\n</th>\n<th style=\"width:2.6%;\">3\n</th>\n<th style=\"width:2.6%;\">4\n</th>\n<th style=\"width:2.6%;\">5\n</th>\n<th style=\"width:2.6%;\">6\n</th>\n<th style=\"width:2.6%;\">7\n</th>\n<th style=\"width:2.6%;\">0\n</th>\n<th style=\"width:2.6%;\">1\n</th>\n<th style=\"width:2.6%;\">2\n</th>\n<th style=\"width:2.6%;\">3\n</th>\n<th style=\"width:2.6%;\">4\n</th>\n<th style=\"width:2.6%;\">5\n</th>\n<th style=\"width:2.6%;\">6\n</th>\n<th style=\"width:2.6%;\">7\n</th></tr>\n<tr>\n<th>0\n</th>\n<th>0\n</th>\n<td colspan=\"4\">Version\n</td>\n<td colspan=\"4\">IHL\n</td>\n<td colspan=\"6\">DSCP\n</td>\n<td colspan=\"2\">ECN\n</td>\n<td colspan=\"16\">Total Length\n</td></tr>\n<tr>\n<th>4\n</th>\n<th>32\n</th>\n<td colspan=\"16\">Identification\n</td>\n<td colspan=\"3\">Flags\n</td>\n<td colspan=\"13\">Fragment Offset\n</td></tr>\n<tr>\n<th>8\n</th>\n<th>64\n</th>\n<td colspan=\"8\">Time To Live\n</td>\n<td colspan=\"8\">Protocol\n</td>\n<td colspan=\"16\">Header Checksum\n</td></tr>\n<tr>\n<th>12\n</th>\n<th>96\n</th>\n<td colspan=\"32\">Source IP Address\n</td></tr>\n<tr>\n<th>16\n</th>\n<th>128\n</th>\n<td colspan=\"32\">Destination IP Address\n</td></tr>\n<tr>\n<th>20\n</th>\n<th>160\n</th>\n<td colspan=\"32\" rowspan=\"3\">Options (if IHL &gt; 5)\n</td></tr>\n<tr>\n<th>⋮\n</th>\n<th>⋮\n</th></tr>\n<tr>\n<th>56\n</th>\n<th>448\n</th></tr></tbody></table>\n"},"/networking/protocols#UDP":{"id":"/networking/protocols#UDP","title":"/networking/protocols#UDP","tags":"[\"wip\"]#UDP","body":"User Datagram Protocol.\n1. https://en.wikipedia.org/wiki/User_Datagram_Protocol\n<table class=\"no-padding\">\n<tbody><tr>\n<th>Offsets\n</th>\n<th>Octet </th>\n<th colspan=\"8\">0\n</th>\n<th colspan=\"8\">1\n</th>\n<th colspan=\"8\">2\n</th>\n<th colspan=\"8\">3\n</th></tr>\n<tr>\n<th>Octet </th>\n<th>Bit</th>\n<th>0</th>\n<th>1</th>\n<th>2</th>\n<th>3</th>\n<th>4</th>\n<th>5</th>\n<th>6</th>\n<th>7</th>\n<th>0</th>\n<th>1</th>\n<th>2</span></th>\n<th>3</span></th>\n<th>4</span></th>\n<th>5</span></th>\n<th>6</span></th>\n<th>7</span></th>\n<th>0</span></th>\n<th>1</span></th>\n<th>2</span></th>\n<th>3</span></th>\n<th>4</span></th>\n<th>5</span></th>\n<th>6</span></th>\n<th>7</span></th>\n<th>0</span></th>\n<th>1</span></th>\n<th>2</span></th>\n<th>3</span></th>\n<th>4</span></th>\n<th>5</span></th>\n<th>6</span></th>\n<th>7</span>\n</th></tr>\n<tr>\n<th>0\n</th>\n<th>0\n</th>\n<td colspan=\"16\" >Source port</td>\n<td colspan=\"16\">Destination port\n</td></tr>\n<tr>\n<th>4\n</th>\n<th>32 </th>\n<td colspan=\"16\">Length</td>\n<td colspan=\"16\">Checksum\n</td></tr></tbody></table>\n"},"/networking/protocols#TCP":{"id":"/networking/protocols#TCP","title":"/networking/protocols#TCP","tags":"[\"wip\"]#TCP","body":"Transmission Control Protocol.\n1. https://en.wikipedia.org/wiki/Transmission_Control_Protocol\n<table class=\"no-padding\">\n  <tbody>\n    <tr>\n      <th>Offsets</th>\n      <th>Octet</th>\n      <th colspan=\"8\">0</th>\n      <th colspan=\"8\">1</th>\n      <th colspan=\"8\">2</th>\n      <th colspan=\"8\">3</th>\n    </tr>\n    <tr>\n      <th style=\"border-top: none\">Octet</th>\n      <th>Bit</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n    <tr>\n      <th>0</th>\n      <th>0</th>\n      <td colspan=\"16\">Source port</td>\n      <td colspan=\"16\">Destination port</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>32</th>\n      <td colspan=\"32\">Sequence number</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <th>64</th>\n      <td colspan=\"32\">Acknowledgment number (if ACK set)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <th>96</th>\n      <td colspan=\"4\">Data offset</td>\n      <td colspan=\"3\">Reserved<br /><b>0 0 0</b></td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          NS\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          CWR\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          ECE\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          URG\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          ACK\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          PSH\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          RST\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          SYN\n        </div>\n      </td>\n      <td>\n        <div\n          style=\"\n            writing-mode: vertical-lr;\n            text-orientation: upright;\n            letter-spacing: -0.12em;\n            line-height: 1em;\n            width: 1em;\n          \"\n        >\n          FIN\n        </div>\n      </td>\n      <td colspan=\"16\">Window Size</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <th>128</th>\n      <td colspan=\"16\">Checksum</td>\n      <td colspan=\"16\">Urgent pointer (if URG set)</td>\n    </tr>\n    <tr>\n      <th>20<br /></th>\n      <th>160<br /></th>\n      <td colspan=\"32\" rowspan=\"3\">\n        Options (if <i>data offset</i> &gt; 5. Padded at the end with \"0\" bits\n        if necessary.)<br />\n      </td>\n    </tr>\n    <tr>\n      <th>⋮</th>\n      <th>⋮</th>\n    </tr>\n    <tr>\n      <th>60</th>\n      <th>480</th>\n    </tr>\n  </tbody>\n</table>\n"},"/os/file-systems#":{"id":"/os/file-systems#","title":"/os/file-systems#","tags":"[]#","body":""},"/os/file-systems#Files":{"id":"/os/file-systems#Files","title":"/os/file-systems#Files","tags":"[]#Files","body":""},"/os/file-systems#Access":{"id":"/os/file-systems#Access","title":"/os/file-systems#Access","tags":"[]#Access","body":"Early operating systems could only access a file in a sequential manner, meaning they were forced to read the whole file and could not skip parts or read out of order.\n"},"/os/file-systems#Meta-data":{"id":"/os/file-systems#Meta-data","title":"/os/file-systems#Meta-data","tags":"[]#Meta-data","body":"Files have additional information about the file itself called the file's **attributes** or **metadata**. This information could be when the file was created, last modified and many more properties.\n"},"/os/file-systems#Operations":{"id":"/os/file-systems#Operations","title":"/os/file-systems#Operations","tags":"[]#Operations","body":"There are a number of operations an operating system allow for storage and retrieval. The following operations are the most common.\n| Operation | Description |\n|-|-|\n| Create | Creation of the file without no content but some of the attributes are set. |\n| Delete | When a file is not needed anymore we could free up its disk space by deleting it. |\n| Open | Loads the file's attributes and addresses for faster access later on into memory. This must be called before using the file. |\n| Close | When we no longer need to access the file we should free up its space in memory. |\n| Read | Fetch the data more a file. |\n| Write | Write data to the file. |\n| Append | Append data to a file. This is a special case of write. |\n| Seek | Repositions the file access pointer to a specific place in the file to allow reads from that position. |\n| Rename | Change the name of the file. |\n| Set attributes | Set attributes that are settable. |\n| Get attributes | List attributes. |\n"},"/os/file-systems#Directories":{"id":"/os/file-systems#Directories","title":"/os/file-systems#Directories","tags":"[]#Directories","body":""},"/os/file-systems#Implementation":{"id":"/os/file-systems#Implementation","title":"/os/file-systems#Implementation","tags":"[]#Implementation","body":"File systems exists on the disk. Disks could be divided into several different partitions with independent file systems. We could for example have Windows on one partition with its own file system and Linux on another partition with another file system one the same computer. Sector 0 on the disk is called the @(MBR)(mbr), which is used to boot the computer. This sector also contains information about all other partitions. Every partition starts with a @(boot block)(boot-block) even if they are not bootable, because they might in the future. So the first thing the MBR program does is to execute the boot block once it has located the active partition. One of the partitions is marked as active.\n"},"/os/file-systems#Contiguous-allocation":{"id":"/os/file-systems#Contiguous-allocation","title":"/os/file-systems#Contiguous-allocation","tags":"[]#Contiguous-allocation","body":"One of the simplest schemes is contiguous allocation. A file that is 50KB with 1KB disk blocks would allocate 50 consecutive blocks. This technique is very simple to implement because we only need to keep track of two things for each file, that is the disk address and the number of disk blocks. The performance is also very good because we only one seek is needed. The one drawback is that the disk over time becomes fragmented, holes in the disk address space. We could keep track of the holes to reuse the space but then we need to know the final size of the file to choose a hole that fits. So if the is small at the beginning and we place it at a hole that perfectly fits what do we do if the size of this file increases?\n"},"/os/file-systems#Linked-list-allocation":{"id":"/os/file-systems#Linked-list-allocation","title":"/os/file-systems#Linked-list-allocation","tags":"[]#Linked-list-allocation","body":"Another approach is to keep every block of a file as a linked list. This way the first block would point to the next, but does not need to be right after the first block. This would allow us to use every disk block. No space is lost due to fragmentation. Sequential reading would be fast, but random access slower. To get to block $ n $ we would have to read $ n - 1 $ blocks. To avoid this we could keep each pointer the disk blocks in a table in memory. However this also comes with the disadvantage of requiring very much memory for big tables since the whole table needs to be in memory at all time. The table is called @(FAT)(fat).\n"},"/os/file-systems#I-nodes":{"id":"/os/file-systems#I-nodes","title":"/os/file-systems#I-nodes","tags":"[]#I-nodes","body":"Yet another approach is to associate each file with a data structure called **i-node (index-node)**. With the i-node we can locate every disk block of the file. The i-node lists the attributes and disk addresses of the file. In contrast with linked list, we only need to keep the i-node in memory when accessing the file. I-nodes are also much more memory efficient than linked list. With $ k $ files occupying $ n $ bytes we need to reserve $ kn $ bytes in total.\n"},"/os/interprocess-communication#":{"id":"/os/interprocess-communication#","title":"/os/interprocess-communication#","tags":"[]#","body":""},"/os/interprocess-communication#Critical-regions":{"id":"/os/interprocess-communication#Critical-regions","title":"/os/interprocess-communication#Critical-regions","tags":"[]#Critical-regions","body":"Race conditions arise when multiple processes want the modify the same resources. To avoid this we need some way to prohibit processes to modify some resource if that is already being modified by another process. This concept is called @(mutual exclusion)(mutual exclusion). A **critical region/section** is defined as the part of the program that could lead to race conditions, in other words the part which access the shared memory. To have a good solution to the critical section problem we need four conditions to hold\n1. Only one process may access the critical region at a time\n2. No assumptions should be made on the hardware (speeds and number of CPUs)\n3. A process running outside its critical region should not block any other process\n4. A process should not have to wait forever to enter its critical region\n"},"/os/interprocess-communication#Mutual-exclusion-with-busy-waiting":{"id":"/os/interprocess-communication#Mutual-exclusion-with-busy-waiting","title":"/os/interprocess-communication#Mutual-exclusion-with-busy-waiting","tags":"[]#Mutual-exclusion-with-busy-waiting","body":"On a single-processor system one easy way to accomplish this is to disable clock interrupts just after entering the critical region and enable them just before leaving. With no clock interrupts the CPU will not switch to another process. Thus the process can be sure that it is the only process accessing the shared resource. However it is not an elegant solution to give user processes the power to disable clock interrupts, because one may never turn them on again. Also, with more CPUs disabling the interrupts will only disable them for the current CPU. Although the kernel itself may very well use this method for convenience when updating different data structures. But more sophisticated methods are needed for synchronization. Another solution may be to take turns with for example a variable that tells whether a process may enter its critical region, if it can't it just spins. This is not a good solution if the processes are running with different speed, because then the faster process needs to wait for the slower all the time. The following is Petersons's solution to mutual exclusion which avoids taking turns:\n```c\n#define FALSE  0\n#define TRUE 1\n#define N 2 /* number of processes */\nint turn; /* whose turn is it? */\nint interested[N]; /* all values initially 0 (FALSE) */\nvoid enter_region(int process); /* process is 0 or 1 */\n{\n    int other; /* number of the other process */\n    other = 1 − process; /* the opposite of process */\n    interested[process] = TRUE; /* show that you are interested */\n    turn = process; /* set flag */\n    while (turn == process && interested[other] == TRUE)  /* null statement */ ;\n}\nvoid leave_region(int process) /* process: who is leaving */\n{\n    interested[process] = FALSE; /* indicate departure from critical region */\n}\n```\n"},"/os/interprocess-communication#Hardware-instructions":{"id":"/os/interprocess-communication#Hardware-instructions","title":"/os/interprocess-communication#Hardware-instructions","tags":"[]#Hardware-instructions","body":"Many processors nowadays support instructions that are @(atomic)(atomic). This instruction is the TSL (Test and Set Lock). The instruction guarantees that no other process can access the memory word until the instruction has finished, so the instruction effectively blocks the memory bus until it is finished to prohibit other processes to access it while it is active. XCHG is another such instruction which exchanges the contents of two locations in an atomic way.\n"},"/os/interprocess-communication#Mutual-exclusion-that-blocks":{"id":"/os/interprocess-communication#Mutual-exclusion-that-blocks","title":"/os/interprocess-communication#Mutual-exclusion-that-blocks","tags":"[]#Mutual-exclusion-that-blocks","body":"To avoid wasting CPU resources when a process is waiting for the lock we need to come up with another solution. A simple solution is to use `sleep()` and `wakeup()`\n"},"/os/interprocess-communication#Semaphores":{"id":"/os/interprocess-communication#Semaphores","title":"/os/interprocess-communication#Semaphores","tags":"[]#Semaphores","body":"A semaphore has a value where 0 represent that no wakeups were saved or above 0 which indicates that more than 0 wakeups are pending. Usually incrementing and decrementing are done through operations called `up` and `down`. These actions are executed in an atomic manner. The normal way to implement them as that is through system calls with the operating system briefly disabling all the interrupts while accessing the semaphore. Disabling all interrupts here should be of no harm because the access is only a few instructions. If the processor consists of multiple CPUs each semaphore should be protected by a lock variable as well with the hardware instructions (e.g. `TSL`).\n"},"/os/interprocess-communication#Mutex":{"id":"/os/interprocess-communication#Mutex","title":"/os/interprocess-communication#Mutex","tags":"[]#Mutex","body":"A mutex is a simplified version of a semaphore when counting is not needed. They are only good for managing mutual exclusion. They can have two states: unlocked or locked. They can be implemented in user space if hardware instructions like `TSL` are available.\n```assembly\nmutex_lock:\n    TSL REGISTER,MUTEX      % copy mutex to register and set mutex to 1\n    CMP REGISTER,#0         % was mutex zero?\n    JZE ok                  % if it was zero, mutex was unlocked, so return\n    CALL thread_yield       % mutex is busy; schedule another thread\n    JMP mutex_lock          % try again\nok: RET                     % return to caller; critical region entered\nmutex_unlock:\n    MOVE MUTEX,#0           % store a 0 in mutex\n    RET                     % return to caller\n```\nWe can see that if a process can not acquire the mutex, it will yield instead of busy waiting. This is especially important in user threads, because there is no clock that could stop threads that have run for too long. Thus a thread trying to acquire a lock by busy waiting will run forever and never acquire the lock, blocking other threads from being run.\n"},"/os/interprocess-communication#Avoid-locks":{"id":"/os/interprocess-communication#Avoid-locks","title":"/os/interprocess-communication#Avoid-locks","tags":"[]#Avoid-locks","body":"We could let readers read the old or new version of the modified shared data while a writer writes to it, instead of a weird combination.\n"},"/os/interprocess-communication#Deadlock":{"id":"/os/interprocess-communication#Deadlock","title":"/os/interprocess-communication#Deadlock","tags":"[]#Deadlock","body":"Four conditions must hold for there to be a resource deadlock:\n1. **Mutual exclusion**. A resource is assigned to **one** process or is available.\n2. **Hold-and-wait**. Processes already holding resources may request more resources.\n3. **No-preemption**. Resources cannot be taken away from a process forcibly, only explicitly released.\n4. **Circular wait**. Two or more processes form a chain where each process waits for resources already held by other processes in that chain.\nThere are in general four strategies for dealing with deadlocks:\n1. Ignore the problem and hope it will ignore you too.\n2. Let them occur and take appropriate actions to handle the situation.\n3. Careful resource allocation.\n4. Negating one of the conditions above.\nLets take a closer look at the fourth strategy, negating on of the four conditions. Lets begin by negating the first condition **mutual exclusion**. To make a resource accessible to more than one process at a time would be to make the data read-only. The key insight here is to only assign a resource when absolutely necessary and keep as few processes as possible from accessing that resource. If we try to negate **hold-and-wait** instead we could for example let every process request all their resources from the start, if everything is available the process can proceed completing its execution, else the process will just wait. However it can be hard to know what resources a process needs and resources may not be used in an optimal manner. If we try to negate **no-preemption** we could forcibly take every needed resource, but this could be impossible at worst. To negate **circular wait** we could restrain each process to only hold a single resource at a time. Before requesting access to a new resource it must release the resource it is currently holding. This may be unacceptable if the second resource request depend on the resource the process is currently holding. We could introduce a global accessing table which tells the order a process may access resources. Thus every process that wants to request resource $ i $ must request resource $ i - 1 $ first.\n"},"/os/keywords#":{"id":"/os/keywords#","title":"/os/keywords#","tags":"[\"keywords\"]#","body":"- shell\n- GUI (Graphical User Interface)\n- kernel mode / supervisor mode\n- user mode\n- SATA (Serial ATA)\n- disk driver\n- multiplexing\n- mainframes\n- batch system\n- multiprogramming\n- spooling (Simultaneous Peripheral Operation On Line)\n- timesharing\n- MULTICS\n- cloud computing\n- UNIX\n- UNIX-like\n- BSD (Berkeley Software Distribution)\n- POSIX\n- System V\n- MINIX\n- Linux\n- LSI (Large Scale Integration)\n- microcomputers\n- DOS (Disk Operating System)\n- network operating systems\n- distributed operating systems\n- X Window System (X11)\n- program counter\n- stack pointer\n- PSW (Program Status Word)\n- pipeline\n- superscalar CPU\n- system call\n- multithreading\n- hyperthreading (intel's name for multithreading)\n- cores\n- CPU (Graphical Processing Unit)\n- cache lines\n- cache hit\n- L1 cache\n- L2 cache\n- RAM (Random Access Memory)\n- core memory\n- ROM (Read Only Memory)\n- EEPROM (Electrically Erasable PROM)\n- flash memory\n- SSD (Solid State Disk)\n- virtual memory\n- REF: MMU (Memory Management Unit)\n- context switch\n- process switch\n- device driver\n- I/O port space\n- busy waiting\n- interrupt\n- waiting (busy, blocking)\n- interrupt vector\n- DMA (Direct Memory Access)\n- PCI (Peripheral Component Interconnect Express)\n- ISA (Industry Standard Architecture)\n- shared bus architecture\n- serial bus architecture\n- DMI (Direct Media Interface)\n- USB (Universal Serial Bus)\n- SCSI (Small Computer System Interface)\n- plug and play\n- BIOS (Basic Input Output System)\n- PDA (Personal Digital Assistant)\n- hard real-time system\n- soft real-time system\n- process\n- address space\n- process table\n- core image\n- command interpreter\n- child process\n- interprocess communication (IPC)\n- UID (User IDentification)\n- GID (Group IDentification)\n- superuser\n- Administrator\n- directory\n- working directory\n- file descriptor\n- root file system\n- special file (UNIX)\n- block special file\n- character special file\n- pipe\n- rwx bits (read, write, execute)\n- prompt\n- PID (Process IDentifier)\n- UNIX system calls\n- text segment\n- REF: data segment\n- stack segment\n- i-nodes\n- partitions\n- minor devices\n- API (Application Programming Interface)\n- shared libraries\n- DLL (Dynamic-Link Library)\n- monolithic system\n- microkernel\n- CMS (Conversational Monitor System)\n- shared hosting\n- type 1 hypervisor\n- type 2 hypervisor\n- host operating system\n- guset operating system\n- paravirtualization\n- JVM (Java Virtual Machine)\n- exokernel\n- multiprocessor\n- pseudoparallelism\n- REF: multiprogramming\n- REF: daemons\n- process scheduler\n- process table\n- process control blocks (PCB)\n- REF: interrupt vector\n- short-term scheduler\n- long-term scheduler\n- dispatcher\n- worker thread\n- REF: thread table\n- trap\n- wrapper\n- jacket\n- REF: upcall\n- pop-up thread\n- scheduler\n- scheduling algorithms\n- REF: compute-bound (CPU-bound)\n- REF: I/O-bound\n- REF: nonpreemptive\n- REF: suspended\n- REF: quantum\n- UMA (Uniform Memory Access)\n- NUMA (Nonuniform  Memory  Access)\n- cache line\n- cache-coherence protocol\n- crossbar switch\n- REF: mutual exclusion\n- REF:atomic\n- priority inversion problem\n- producer-consumer or bounded buffer problem\n- futex\n- condition variables\n- monitor (synchronization primitive)\n- message passing\n- barrier (synchronization mechanism)\n- RCU (Read-Copy-Update)\n- banker’s algorithm\n- memory hierarchy\n- memory manager\n- swapping\n- virtual memory\n- REF: free lists\n- REF: bitmaps\n- REF: pages\n- REF: virtual address space\n- REF: page frames\n- REF: page table\n- dirty bit\n- REF: TLB (Translation Lookaside Buffer)\n- associative memory\n- page table walk\n- minor page fault\n- major page fault\n- segmentation  fault\n- multilevel page table\n- page  directory\n- inverted  page  tables\n- FAT-16, FAT-32, exFAT\n- NTFS\n- magic number\n- sequential access\n- metadata\n- file descriptors\n- working directory\n- relative path name\n- current directory\n- absolute path name\n- hard link\n- soft link\n- symbolic link\n- REF: MBR (Master Boot Record)\n- REF: boot block\n- superblock\n- UDF (Universal Disk Format)\n"},"/os/keywords#Spin-lock":{"id":"/os/keywords#Spin-lock","title":"/os/keywords#Spin-lock","tags":"[\"keywords\"]#Spin-lock","body":"A lock that uses busy waiting.\n"},"/os/keywords#Synchronization":{"id":"/os/keywords#Synchronization","title":"/os/keywords#Synchronization","tags":"[\"keywords\"]#Synchronization","body":"To make sure that certain event chains do not occur.\n"},"/os/keywords#Livelock":{"id":"/os/keywords#Livelock","title":"/os/keywords#Livelock","tags":"[\"keywords\"]#Livelock","body":"A situation where no process is blocked but events are happening with no progress.\n"},"/os/keywords#Starvation":{"id":"/os/keywords#Starvation","title":"/os/keywords#Starvation","tags":"[\"keywords\"]#Starvation","body":"A situation where a process run indefinitely but fail to make any progress due to unfairness.\n"},"/os/keywords#Deadlock":{"id":"/os/keywords#Deadlock","title":"/os/keywords#Deadlock","tags":"[\"keywords\"]#Deadlock","body":"A situation where all processes are blocked waiting for each other and will remain in that state indefinitely.\n"},"/os/keywords#Preemptable-resource":{"id":"/os/keywords#Preemptable-resource","title":"/os/keywords#Preemptable-resource","tags":"[\"keywords\"]#Preemptable-resource","body":"A resource that **can** be taken away from another process without any bad effects.\n"},"/os/keywords#Nonpreemptable--resource":{"id":"/os/keywords#Nonpreemptable--resource","title":"/os/keywords#Nonpreemptable--resource","tags":"[\"keywords\"]#Nonpreemptable--resource","body":"A resource that **cannot** be taken away from another process without any bad effects.\n"},"/os/keywords#Static-relocation":{"id":"/os/keywords#Static-relocation","title":"/os/keywords#Static-relocation","tags":"[\"keywords\"]#Static-relocation","body":"A method for relocation every memory address during the load process with a constant, the constant being the first physical memory address the program was loaded into.\n"},"/os/keywords#Dynamic-relocation":{"id":"/os/keywords#Dynamic-relocation","title":"/os/keywords#Dynamic-relocation","tags":"[\"keywords\"]#Dynamic-relocation","body":"A method for mapping a process' address space onto different physical memory parts.\n"},"/os/keywords#Memory-compaction":{"id":"/os/keywords#Memory-compaction","title":"/os/keywords#Memory-compaction","tags":"[\"keywords\"]#Memory-compaction","body":"A technique to move all processes in memory down as far as possible to avoid memory holes.\n"},"/os/keywords#Random-access-files":{"id":"/os/keywords#Random-access-files","title":"/os/keywords#Random-access-files","tags":"[\"keywords\"]#Random-access-files","body":"Files that can be read in any order.\n"},"/os/keywords#FAT":{"id":"/os/keywords#FAT","title":"/os/keywords#FAT","tags":"[\"keywords\"]#FAT","body":"**FAT (File Allocation Table)**. A table in memory that keeps track of the pointers to all disk blocks in the same file.\n"},"/os/memory-management#":{"id":"/os/memory-management#","title":"/os/memory-management#","tags":"[]#","body":""},"/os/memory-management#Physical-memory":{"id":"/os/memory-management#Physical-memory","title":"/os/memory-management#Physical-memory","tags":"[]#Physical-memory","body":"The first computers had no memory abstractions whatsoever. Thus accessing the memory was actually accessing the physical memory in the requested location. However having to programs running at the same time became a challenge, because one program would most certainly overwrite a memory location that the other program used leading to crashes. One way to overcome this is @(static relocation)(static-relocation), but it is slow and tricky to implement. However the operating system could run multiple programs concurrently even without memory abstractions. The way it would do so is saving the entire contents of memory to a dist file, @(swapping)(swapping), and put in another program. In this way only one program would have access to the memory at a given time. Another problem to take into consideration is that if a user program could access every memory location it could intentionally or by accident overwrite the memory of the operating system unless there is some locking mechanisms.\n"},"/os/memory-management#Address-space":{"id":"/os/memory-management#Address-space","title":"/os/memory-management#Address-space","tags":"[]#Address-space","body":"So how to we solve **protection** and **relocation** of memory? By introducing a new abstract called the **address space**. The address space is a set of addresses that is a process can use to access memory. It is also unique for that process unless, in some occasions, some processes want to share their address spaces. A simple solution to map each process' address space to the physical memory is to use to special registers, **base** and **limit**. The base register holds the physical address assigned to a program and the limit register the length of that program. Thus if two programs are loaded into memory at the same time, the second program would have the base as the length of first program. When these programs are executed and a memory instruction is referenced the hardware automatically adds the base value to that memory reference before executing it. If the new value is above the limit or below the base of that program a fault is generated. The obvious disadvantage of this is that for every memory instruction additional computation is required.\n"},"/os/memory-management#Swapping":{"id":"/os/memory-management#Swapping","title":"/os/memory-management#Swapping","tags":"[]#Swapping","body":"In practice the total memory needed for all processes that are running concurrently often exceeds the amount of @(RAM)(ram). To deal with this two approaches are used, **swapping** and **virtual memory**. Swapping involves bringing in each process to memory, run it for some time, and the put it back on the disk. Virtual memory on the other hand allows each process to run even though they are partially in memory. So how much memory needs to be allocated for a process when swapping? If every process is created with a fixed size the operating systems knows how much memory is needed and allocates exactly that amount. But if the process contains dynamic elements allowing the @(data segment)(data-segment) to grow the problem becomes much more complicated. If a memory hole, created by swapping in and out different processes, are located next to a process that could easily be allocated for the program to hold dynamic elements. If it can't grow it has to move to a memory hole that is big enough or other processes have to be swapped out to create a space big enough. If the swap area is full as well when a process can't grow it is suspended until enough space is available or killed. Thus it can be a good idea to allocate some extra memory for each process to reduce overhead in swapping and moving processes around. But we should only swap the memory in use, and not the extra allocated memory.\nWhen memory is dynamically used the operating system must keep track of it either by @(bitmaps)(bitmaps) or @(free lists)(free-lists). The bitmap divide the memory into allocation units where each unit corresponds to a bit, 0 if the unit is free or 1 if it is used. There is a tradeoff of how big these allocations units should be. The operating system could also maintain a linked list of all the allocated memory and available memory. When the list is sorted by addresses several algorithms exist to allocate the memory. The simplest algorithm is called **first fit**. It just scan the list until it finds a memory segment big enough. A variation of the first fit algorithm is the **next fit**. It extends first fit by keeping track of every hole it encounters to that the next time it searches it begins at such a hole. However simulations have showed that next fit gives worse performance than first fit. Yet another approach is **best fit**. It searches every possible hole and take the smallest. An alternative is also **worst fit** which takes the biggest available memory but it is not very good. Another is **quick fit** which keeps track of commonly requested sizes in a separate list. All of these algorithms have the disadvantage that when a process is swapped out or terminated it could possibly be quite expensive to check if a merge of the newly available memory to already existing adjacent holes could be done.\n"},"/os/memory-management#Segmentation":{"id":"/os/memory-management#Segmentation","title":"/os/memory-management#Segmentation","tags":"[]#Segmentation","body":"A segment is an independent address space used to manage the growing and shrinking data structures. It also simplifies linking if procedures occupy separate segments, because then the start address is same for all procedures (0) and we need only the segment number to call the procedure. If a procedure changes no other procedure needs to change due to the fact that the start address does not change. This is not the case if this technique is not used, because then procedures may be tightly packed next to each other and changing the size of one procedure may change the whole structure. A segment consists of linear addresses starting from 0 up to same maximum value which can change at execution. To specify an address the program must provide a segment number and an address within the segment. Segmentation makes it easier to share data and procedures between processes.\n"},"/os/memory-management#Virtual-memory":{"id":"/os/memory-management#Virtual-memory","title":"/os/memory-management#Virtual-memory","tags":"[]#Virtual-memory","body":"The idea behind **virtual memory** is that each program has its own address space, broken up into pieces called @(pages)(pages). Every page consists of a linear sequence of addresses mapped onto the physical addresses. Because all virtual addresses do not need to be in memory at the same time, the operating system is alerted when an address that is not on the physical memory is referenced. If the address is in memory the mapping is done automatically.\n"},"/os/memory-management#Paging":{"id":"/os/memory-management#Paging","title":"/os/memory-management#Paging","tags":"[]#Paging","body":"Virtual addresses are generated to form the @(virtual address space)(virtual-address-space). In computers without virtual memory the virtual memory addresses are sent directly to the memory bus without any alteration so they represent the physical memory. However, in computers with virtual memory addresses are sent to a @(MMU)(mmu) that maps the addresses to the correct physical addresses. A page is a fixed-size unit that the address space is divided into, while @(page frames)(page-frames) are fixed-size units in the physical address space usually of the same size as pages. If we have 64KB of virtual memory, 32KB of physical memory we can not keep the whole virtual memory in memory. If the page size is 4KB we get 16 virtual pages and 8 page frames. When we need to swap in memory addresses from disk that is not currently in memory the whole page is swapped in. A 4KB page consists of 4096 addresses. When accessing address 0 the MMU would see that it is page 0, the addresses 0-4095, and depending on the mapping it may map the page to page frame 1. Thus transforming the virtual address page to the physical addresses 4096-8191 assuming they have the same size. The relation between the virtual addresses and the physical addresses is given by the @(page table)(page-table). Because there are only 8 page frames in the example above and 16 pages, 8 of the pages are not mapped at a given time. Present and absent bits keep track of which virtual page that is currently mapped into the physical memory. When an address, not currently mapped, is referenced the MMU notices this and causes the CPU to trap (@(page fault)(page-fault)) the operating system. This causes the operating system to replace a little used page (marking it as unmapped) frame with the referenced page (marking it as mapped). The mapping in the page table is split into a virtual page number and an offset. Thus we need to have four bits to represent 16 virtual pages. A typical page table entry has a page frame number, a present/absent bit, caching, referenced, modified and protection. The referenced bit plays an important role in many page replacement algorithms.\n"},"/os/memory-management#Performance":{"id":"/os/memory-management#Performance","title":"/os/memory-management#Performance","tags":"[]#Performance","body":"Paging may become a large bottleneck the more bits we use to address each page and offset. For example a 32-bit address space with 4KB page sizes has 1 million pages. To speed things up, a @(TLB)(tlb) may be used, which is a small hardware for mapping the virtual addresses to physical addresses without going through the page table. This usually works well because most programs tend to only reference a small portion of the pages, while the rest are barely used at all. The TLB usually has between 8-256 entries, entries that are exactly the same as the entries in the page table except the virtual page number which is not used at all. So when a virtual address is referenced and goes to the MMU for translation, a check is done to see if the address is present in the TLB by comparing it do every entry simultaneously. If a match is found we do not need to access the page table. If it is a miss a page table lookup is needed, and the match of that lookup replaced one of the entries in the TLB. Software TLBs are surprisingly quite good with acceptable performance if the TLB is quite large. A soft miss, using software TLB,is when the page is not in the TLB but in memory. Similarly, a hard miss is when the page is not in the TLB and not in the memory.\nTo deal with large virtual memories one can consider using a **multilevel page table**. Here we have page tables referencing to other page tables.\n"},"/os/memory-management#Replacement-algorithms":{"id":"/os/memory-management#Replacement-algorithms","title":"/os/memory-management#Replacement-algorithms","tags":"[]#Replacement-algorithms","body":""},"/os/processes-and-threads#":{"id":"/os/processes-and-threads#","title":"/os/processes-and-threads#","tags":"[]#","body":""},"/os/processes-and-threads#Introduction":{"id":"/os/processes-and-threads#Introduction","title":"/os/processes-and-threads#Introduction","tags":"[]#Introduction","body":"Concurrent is not the same as parallel. Concurrent means that we feel that many processes run at the same time, but they actually do not. The kernel switch so fast between each process that we feel that they run at the same time. Parallel execution means that the processes are actually run in parallel. They are executed at the same time on different CPU cores.\n"},"/os/processes-and-threads#Amdahl's-Law":{"id":"/os/processes-and-threads#Amdahl's-Law","title":"/os/processes-and-threads#Amdahl's-Law","tags":"[]#Amdahl's-Law","body":"Amdahl's law state the performance gain by adding CPU cores to an execution that has both serial and parallel components. It could be stated in a formula:\n$$\n\\text{speedup} \\leq \\frac{1}{S + \\frac{(1-S)}{N}}\n$$\nwhere $ S $ is the *serial portion* and $ N $ is the *processing cores*.\nAs an example, suppose that an application has a section that is 75% parallel and 25% serial, then moving from 1 to 2 cores has\n$$\n\\text{speedup} \\leq \\frac{1}{0.25 + \\frac{(1-0.25)}{2}} = 1.6\n$$\nThus the speedup cannot be greater than $ 1.6 $.\n"},"/os/processes-and-threads#Processes":{"id":"/os/processes-and-threads#Processes","title":"/os/processes-and-threads#Processes","tags":"[]#Processes","body":"A process is one of the oldest and most important abstractions in an operating system. They support (pseudo) concurrent operations even when there is only one CPU available. In a multiprogramming system the CPU switches between processes very quickly only running each for a couple of (multiple of) milliseconds. Thus, at any given time only one process is running, but because of the fast switching between processes it gives the illusion of concurrent execution.\n"},"/os/processes-and-threads#The-model":{"id":"/os/processes-and-threads#The-model","title":"/os/processes-and-threads#The-model","tags":"[]#The-model","body":"A process is an instance of an executing program including information about the program counter, variables and registers. The os can therefore switch between processes in a rapid manner and save each process' state so the next time that process starts executing it can go on from where it left. The rapid switching of processes is called @(multiprogramming)(multiprogramming). Processes in UNIX form a tree structure, while this is not the case in Windows.\n"},"/os/processes-and-threads#Creation":{"id":"/os/processes-and-threads#Creation","title":"/os/processes-and-threads#Creation","tags":"[]#Creation","body":"Four main events can cause processes to be generated:\n1. System initialization.\n2. Calling a process-creation system call from a running process.\n3. A user request.\n4. Initiation of a batch job.\nWhen the operating system is booting a number of different processes are created. These could be foreground applications or background processes, also called @(daemons)(daemons). In UNIX(-like) there is only one system call to create a new process: `fork()`. This call duplicates the running process and the two processes will after the call, have the same memory image, environment, the same open files. To fork in C we do the following:\n```c\nint main() {\n    pid = fork()\n    // if pid=0 we are the child process\n    // else we are the parent process\n    if (pid == 0) {\n        // child\n    }\n    else {\n        // parent\n    }\n}\n```\nWe need to wait for the child process to completely remove the process from memory once it has finished. We do this by the `waitpid` system call.\nA zombie process is a process which has finished, but not been successfully terminated from its parent (waited). A process will when it dies, send the `SIGCHLD` signal to its parent indicating that the parent can wait for the child process to exit it successfully.\nWe can't kill zombie processes with the `SIGKILL` signal as zombie processes are already dead. Instead we have to send the `SIGCHLD` signal to the parent process. We can do this by the `kill` command as follows:\n```bash\nkill -s SIGCHILD pid\n```\nIf the parent is not programmed to handle this signal, we have to kill the parent process. Zombie processes of a terminated process will be inherited by `init`, which will become the new parent. `init` is the first process started and has $ \\text{pid} = 1 $. `init` will wait for each zombie child process periodically, making them exit gracefully.\nIf we do not free up any zombie processes, they will start taking up a majority of the available pids on the system, which eventually will block us from creating new processes.\n```c\n// pid_t waitpid(pid_t pid, int *status, int options);\n// pid     0: Wait for any child process whose process\n//            group ID is equal to that of the calling process.\n//        -1: Wait for any child process.\n//       > 0: Wait for the child whose process ID is equal to\n//            the value of pid.\n//      < -1: Wait for any child process whose process group\n//            ID is equal to the absolute value of pid.\nwaitpid(pid, &status, 0);\n```\nBy default this system call is blocking. To prevent this we can pass the flag option `WNOHANG`. This tells `waitpid` to return immediately if there is no child processes ready to be noticed.\n```c\n// pid_t waitpid(pid_t pid, int *status, int options);\n// options    WNOHANG: Return immediately\n//          WUNTRACED: Additionally return if a child has\n//                     stopped.\n//         WCONTINUED: Additionally return if a stopped child\n//                     has been resumed by the signal SIGCONT\nwaitpid(pid, &status, WNOHANG);\n```\nHere is an example of a signal handler that will take care of background child processes when they are finished:\n```c\n// handler for SIGCHLD, the signal that indicates that at\n// least one child process has been terminated\nvoid background_wait(int s) {\n    int wpid, status;\n    while (1) {\n        // check if there are some processes that have\n        // finished running and finish them then return\n        wpid = waitpid(-1, &status, WNOHANG);\n        // there are some processes that are not finished\n        // or no processes at all return\n        if (wpid <= 0)\n            return;\n    }\n}\n```\nThe `SIGCHLD` handler must be set up before a child process is forked. We need to have a loop here because we don't know how many child processes that have exited.\n"},"/os/processes-and-threads#State":{"id":"/os/processes-and-threads#State","title":"/os/processes-and-threads#State","tags":"[]#State","body":"A process may be in the following states:\n1. Running (using the CPU)\n2. Ready (temporarily stopped to let another process run, but runnable)\n3. Blocked (unable to run until some external event happens)\nThe first and second state are almost the same, both signaling that they want to be run. It is just a matter of which process the operating system chooses to \"switch to\" at that time instant. The third state will not run even if the CPU is idle. In systems like UNIX when a process reads from a pipe or special file and there is no input available the process is automatically blocked. Transitions from state 1 and state 2 is dependent on the process scheduler. There are many different algorithms to choose from when implementing the process scheduler, each optimizing some requirement. There is, however no algorithm that excels in every aspect which leads to tradeoffs.\n"},"/os/processes-and-threads#Implementation":{"id":"/os/processes-and-threads#Implementation","title":"/os/processes-and-threads#Implementation","tags":"[]#Implementation","body":"The operating system maintains a table with one process per entry. Each entry contains important information about the process' state, like the stack pointer, memory allocation, program counter, open files, scheduling information and other useful information. This information is needed to allow the operating system to start the process again after being the blocked or ready state as if it was never there. The @(interrupt vector)(interrupt-vector) assists in maintaining multiple processes on each CPU. This table shows some of the usual information which is used in a process table entry:\n| Process management | Memory management | File management |\n| - | - | - |\n| Registers | Pointer to text segment info | Root directory\n| Program counter | Pointer to data segment info | Working directory\n| Program status word | Pointer to stack segment info | File descriptors\n| Stack pointer |  | User ID\n| Process state |  | Group ID\n| Priority |  |\n| Scheduling parameters |  |\n| Process ID |  |\n| Parent process |  |\n| Process group |  |\n| Signals |  |\n| Time when process started |  |\n| CPU time used |  |\n| Children's CPU time |  |\n| Time of next alarm |  |\n"},"/os/processes-and-threads#Threads":{"id":"/os/processes-and-threads#Threads","title":"/os/processes-and-threads#Threads","tags":"[]#Threads","body":"A thread is just like a process, but with one major difference: it shares the same address space with other threads of the same process. That means every thread of a process will also share the same global variables. A thread has the same states as a process:\n- running\n- blocked\n- ready\n- terminated\nThere are a couple of multithreading models:\n- Many-to-One\n- One-to-One\n- Many-to-Many\n"},"/os/processes-and-threads#Implicit-threading":{"id":"/os/processes-and-threads#Implicit-threading","title":"/os/processes-and-threads#Implicit-threading","tags":"[]#Implicit-threading","body":"Program correctness may become very difficult to assure as the number of threads increase leading to management of threads by the programmer becoming hard to sustain. This leads to thread management being done by compilers or run-time libraries instead of the programmers.\n"},"/os/processes-and-threads#POSIX-threads":{"id":"/os/processes-and-threads#POSIX-threads","title":"/os/processes-and-threads#POSIX-threads","tags":"[]#POSIX-threads","body":"IEEE defines a standard for writing portable threaded programs and most UNIX system supports it.\n| Call | Description |\n| - | - |\n| Pthread_create | Creates a new thread |\n| Pthread_exit   | Terminates the thread |\n| Pthread_join   | Waits for a thread to exit |\n| Pthread_yield  | Release CPU for another thread |\n| Pthread\\_attr_init | Create and initialize a thread's attribute structure |\n| Pthread\\_attr_destroy | Remove a thread's attribute structure |\n"},"/os/processes-and-threads#Implementation-user-space":{"id":"/os/processes-and-threads#Implementation-user-space","title":"/os/processes-and-threads#Implementation-user-space","tags":"[]#Implementation-user-space","body":"A thread may be implemented in either the user space or the kernel. If the implementation is in the user space it has the advantage of not needing the operating system to support threading (the kernel). A @(thread table)(thread-table) is needed as well, which has a similar function to the kernel's process table. Invoking threading operations in user space is just local procedures, which certainly is more efficient than making a kernel call, because no trapping is needed, no context switching and the memory cache does not need to be flushed. The threading algorithm may be customized as well in a more flexible manner. However, there are few problems. Namely, how to implement blocking system calls. Letting one thread make a blocking system call will stop all threads, because it blocks the whole process. Another problem is that if a thread starts running it never stops if it does not want to. Precisely, a thread must give up the CPU voluntarily so that other threads also can work, because there is no clock interrupts making it impossible to schedule round-robin. Solutions to overcome this is often messy. The general argument against user space threading is that threads are used to make blocking calls, so that other code can run meanwhile the application is waiting for a certain task. But implementing blocking behaviour is messy.\n"},"/os/processes-and-threads#Implementation-kernel":{"id":"/os/processes-and-threads#Implementation-kernel","title":"/os/processes-and-threads#Implementation-kernel","tags":"[]#Implementation-kernel","body":"A kernel implementation of threading does not need a run-time system for each threads as well as no thread table in each process. The kernel keeps track of each thread with a thread table of its own. Every mutating operation involving threading is updated in the thread table. The thread table stores each thread's registers, state, among other information (the same information as user space threads but different location). The process table is still used alongside the thread table. Every blocking call in each thread is implemented as a system call. When a thread is blocked, the kernel may run a thread from the same process or a thread from another process. But this all comes with a greatly increased cost, which is why some systems recycle threads. That is, when a thread is destroyed it is marked as not runnable, but the data structure remains untouched. When a new thread is created later on, it can reuse the recycled thread's data structure to save some overhead.\n"},"/os/processes-and-threads#Scheduler-activations":{"id":"/os/processes-and-threads#Scheduler-activations","title":"/os/processes-and-threads#Scheduler-activations","tags":"[]#Scheduler-activations","body":"To use the best of both worlds, a concept called scheduler activations was developed. They try to mimic the functionality of kernel threads, but with performance more alike of user threads. Nonblocking system calls and checks in advance should not be necessary to make certain system calls. When a thread is blocking because of a system call or a page fault, other threads within the same process should be able to run. The kernel creates a certain number of virtual processors for each process. The user space run-time is then allowed to allocate threads to the processors. The basic idea behind scheduler activations then follows a mechanism called @(upcall)(upcall).\n"},"/os/processes-and-threads#Pop-up-thread":{"id":"/os/processes-and-threads#Pop-up-thread","title":"/os/processes-and-threads#Pop-up-thread","tags":"[]#Pop-up-thread","body":"A pop-up thread is a thread that is created to handle a new request meanwhile the parent thread continues to handle new incoming requests.\n"},"/os/processes-and-threads#Processes-and-threads-in-Linux":{"id":"/os/processes-and-threads#Processes-and-threads-in-Linux","title":"/os/processes-and-threads#Processes-and-threads-in-Linux","tags":"[]#Processes-and-threads-in-Linux","body":"The kernel represents processes as tasks internally. A task represents any execution context, therefore making no distinction between a process and a thread. This is unlike most OS approaches. A single-threaded process will hence be represented as one task, and a multithreaded process will have one task for each thread. Linux identifies each process with its PID. For each process a process descriptor is active in memory for as long as the process is active. It contains information needed to manage all processes, e.g. scheduling parameters, open file descriptors with more. The information can be split up in a few broad categories:\n1. **Scheduling parameters** Includes process priority, consumed CPU time and consumed sleep time which are used to determine which process to run next.\n2. **Memory image** Pointers to the page tables and text, data, and stack segments of a process when the process is in memory. When it is not it instead contains the location on the disk. This also includes visibility information about each data block.\n3. **Signals** Which signals should be caught, ignored, blocked and active.\n4. **Machine registers** Traps to the kernel are stored here.\n5. **System call state** The current system call is stored here.\n6. **File descriptor table** Involved file descriptors for a system call.\n7. **Accounting** General limits the kernel puts on each process, like maximum stack size for each process.\n8. **Kernel stack** The kernel stack which is used to handle kernel parts by a process.\n9. **Other** Current process state with more.\nWhen a new process is created a new process descriptor is created which contains information that mostly is filled in by the parent process often based upon its own values. Linux checks for an available PID, assigns it, and updates the PID hash-table to point to the new task. The semantics of the the instruction `fork` say that no memory is shared between the parent and the child, but that means that we need to copy these structures. Linux avoids this by giving each child its own empty structure but pointing them to the parent with read-only access. The structures are only allocated once the child attempts to write to these read-only parent structures. Then being marked with both read and write access. Linux introduces a system call `clone` not found in any other version of UNIX, to deal with many of the issues arising from threads when for example forking.\n"},"/os/processes-and-threads#Scheduling":{"id":"/os/processes-and-threads#Scheduling","title":"/os/processes-and-threads#Scheduling","tags":"[]#Scheduling","body":"When a computer is constructed to allow multiple processes to run at the same time, each process constantly competes for CPU time. If one process is the only one in ready state, the competition is easy. But when there a more than one process in ready state and only CPU is available the operating system has to decide which process to execute next. The component making this decision is the scheduler which uses a scheduling algorithm to decide which process to execute next. Scheduling most often applies to both processes and threads.\n"},"/os/processes-and-threads#Process-behaviour":{"id":"/os/processes-and-threads#Process-behaviour","title":"/os/processes-and-threads#Process-behaviour","tags":"[]#Process-behaviour","body":"To be able to construct a good scheduling algorithm one needs to analyze how different processes utilize the CPU. Some processes spend a considerable amount of time computing. These processes are called @(CPU-bound)(CPU-bound). Other processes are mostly waiting for I/O and they are called @(I/O-bound)(I/O-bound) processes. I/O-bound activity is defined as when a process enters blocked state while waiting for an external device to finish. One observation is that CPU-bound processes have long CPU bursts (occupies the CPU for longer period of time) while I/O-bound processes have short CPU bursts (occupies the CPU for shorter period of time). Thus, the principal idea is to let I/O-bound processes higher priority to run so that they can issue disk requests and keep the disk busy while the CPU is doing some other computation. If there are no available processes after a process exits, an idle process provided by the system is usually run. Scheduling algorithms can be divided into two different groups: @(nonpreemptive)(nonpreemptive) and @(preemptive)(preemptive) depending on how the deal with clock interrupts. A nonpreemptive scheduling algorithm picks a process to run until it blocks. It could in fact run for several hours nonstop. A preemptive scheduling algorithm picks a process to run for a fixed amount of time. When that fixed period of time has finished the process is @(suspended)(suspended) and the algorithm picks another process to run instead.\n"},"/os/processes-and-threads#Categories-of-scheduling":{"id":"/os/processes-and-threads#Categories-of-scheduling","title":"/os/processes-and-threads#Categories-of-scheduling","tags":"[]#Categories-of-scheduling","body":"There are three different environments worth distinguishing when talking about scheduling. These are\n1. Batch\n2. Interactive\n3. Real time\nIn **batch** systems long waiting times are often acceptable, which means a nonpreemptive or a preemptive (with a long fixed duration) is suitable. They are applicable in corporate mainframes. When there are **interative** users involved in the system, preemption is necessary to keep one process from dominating the CPU usage. In **real time** systems there is often no need to have preemptive scheduling, because the processes run in such environment know that they are not going to use the compute resources for a long time and blocks quickly. Because there are different use cases, the goal of the scheduling algorithm differs as well.\n**General System**\n- Fairness\n- Policy enforcement\n- Balance\n**Batch**\n- Throughput\n- Turnaround time (time for a batch to finish)\n- CPU utilization\n**Interative**\n- Response time\n- User experience (proportionality)\n**Real time**\n- Deadlines\n- Predictability\n"},"/os/processes-and-threads#Algorithms-used-in-batch-systems":{"id":"/os/processes-and-threads#Algorithms-used-in-batch-systems","title":"/os/processes-and-threads#Algorithms-used-in-batch-systems","tags":"[]#Algorithms-used-in-batch-systems","body":"**Nonpreemptive first-come, first-served**. Here we have a single queue of ready processes. The first process that enters the queue may run for how much as it wants, then when terminated or blocked, the next process that started (the next process in the queue) gets to run. As more processes start they are put onto the end of the queue. When a blocked process becomes ready, it is also put onto the end of the queue. The disadvantages with this is that processes with short CPU time but that are I/O bound and placed after a long CPU bound process will have to wait until their turn, even though that could have run simultaneously with the long CPU bound process.\n**Shortest job first**. This is another nonpreemptive algorithm that run times are known beforehand. The scheduler picks the shortest of these run times first. If we have four jobs A,B,C,D with runtimes 8,4,4,4 minutes the turnaround time for each one of these is 8,12,16,20 respectively if we run them in the order given. If we use the shortest job first we instead run A last, reducing the mean of the turnaround times. It is an optimal solution if every job is available simultaneously.\n**Shortest remaining time left**. This is a preemptive version of the shortest job first. The scheduler chooses the process with the smallest run time remaining. Again we must know the run times in advance. This algorithm favors new processes with small run time.\n"},"/os/processes-and-threads#Algorithms-used-in-interactive-systems":{"id":"/os/processes-and-threads#Algorithms-used-in-interactive-systems","title":"/os/processes-and-threads#Algorithms-used-in-interactive-systems","tags":"[]#Algorithms-used-in-interactive-systems","body":"**Round-robin scheduling**. One of the classics (oldest, fairest and most widely used). Each process gets a time interval called `quantum` during which it is allowed to run. If the process is still running at the end of the quantum the scheduler gives the CPU to another process. Otherwise, the schedule switching occurs when the process blocks or terminates as usual. The scheduler keeps a list of all the processes. When a process has finished its quantum it is put at the end of the list. Setting the quantum to a reasonable length is often a tradeoff between switching to much (context switch overhead) and not giving short interactive requests time to run (longer quantum length). In practice 20-50 msec is often used.\n**Priority scheduling**. In this algorithm a process is assigned a priority of how important it is. The scheduler switches to the process with the highest priority. It is often convenient to use round-robin in combination with priority scheduling and use priority classes. Within each class round-robin is used, but for each class priority scheduling is used.\n**Other**\n- Multiple queues\n- Shortest process next (similar to shortest job first, but for interactive systems)\n- Guaranteed scheduling\n- Lottery scheduling\n- Fair-share scheduling\n"},"/os/processes-and-threads#Policy":{"id":"/os/processes-and-threads#Policy","title":"/os/processes-and-threads#Policy","tags":"[]#Policy","body":"Because no scheduler algorithm is best in all cases there is a need to separate the logic of the scheduling mechanism from the scheduling policy. The scheduling algorithm in of itself becomes parametrized in a way which makes it more flexible and can depend on the scenario instead of being fixed.\n"},"/os/processors#":{"id":"/os/processors#","title":"/os/processors#","tags":"[]#","body":""},"/os/processors#Multiprocessors":{"id":"/os/processors#Multiprocessors","title":"/os/processors#Multiprocessors","tags":"[]#Multiprocessors","body":""},"/programming-languages/python/matplotlib#":{"id":"/programming-languages/python/matplotlib#","title":"/programming-languages/python/matplotlib#","tags":"[]#","body":""},"/programming-languages/python/matplotlib#Installation":{"id":"/programming-languages/python/matplotlib#Installation","title":"/programming-languages/python/matplotlib#Installation","tags":"[]#Installation","body":"```python\npip install matplotlib\n```\n"},"/programming-languages/python/matplotlib#Usage":{"id":"/programming-languages/python/matplotlib#Usage","title":"/programming-languages/python/matplotlib#Usage","tags":"[]#Usage","body":"Matplotlib is the core library for plotting graphs. See [full documentation](https://matplotlib.org/stable/api/index.html).\n```python\nimport matplotlib.pyplot as plt\n```\n"},"/programming-languages/python/matplotlib#Examples":{"id":"/programming-languages/python/matplotlib#Examples","title":"/programming-languages/python/matplotlib#Examples","tags":"[]#Examples","body":"```python\nx = [1, 2, 3, 4]\ny = [1, 4, 9, 16]\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.plot(x, y, color='red', linewidth=2)\nax.scatter([2, 4, 6], [3, 9, 16], color='blue', marker='^')\nax.set_xlim(0, 6.5)\nplt.savefig('test.png')\nplt.show()\n```\n```python\nx = [1, 2, 3, 4]\ny = [1, 4, 9, 16]\nplt.plot(x, y, color='orange', linewidth=1)\nplt.show()\n```\n"},"/programming-languages/python/matplotlib#Prepare":{"id":"/programming-languages/python/matplotlib#Prepare","title":"/programming-languages/python/matplotlib#Prepare","tags":"[]#Prepare","body":"```python\nx = np.linspace(0, 10, 50)\ny = np.sin(x)\n```\n"},"/programming-languages/python/matplotlib#Create":{"id":"/programming-languages/python/matplotlib#Create","title":"/programming-languages/python/matplotlib#Create","tags":"[]#Create","body":"```python\nfig = plt.figure()\nfig.add_axes()\n# row-col-num (2-2-1)\nax = fig.add_subplot(221)\nfig2, ax2 = plt.subplots(nrows=2, ncols=2)\n```\n"},"/programming-languages/python/matplotlib#Customize":{"id":"/programming-languages/python/matplotlib#Customize","title":"/programming-languages/python/matplotlib#Customize","tags":"[]#Customize","body":""},"/programming-languages/python/matplotlib#Markers":{"id":"/programming-languages/python/matplotlib#Markers","title":"/programming-languages/python/matplotlib#Markers","tags":"[]#Markers","body":"```python\nplt.plot(x, y, marker='o')\n```\n"},"/programming-languages/python/matplotlib#Linestyles":{"id":"/programming-languages/python/matplotlib#Linestyles","title":"/programming-languages/python/matplotlib#Linestyles","tags":"[]#Linestyles","body":"```python\nplt.plot(x, y, ls='solid')\nplt.plot(x, y, ls='--')\nplt.plot(x, y, ls='solid', x**2, y**2, ls='--'))\n```\n"},"/programming-languages/python/matplotlib#Text":{"id":"/programming-languages/python/matplotlib#Text","title":"/programming-languages/python/matplotlib#Text","tags":"[]#Text","body":"```python\n# location (x,y)\nplt.text(1,1,'Function')\nplt.annotate(\n    'Local Max',\n    xy=(3.3, 1),\n    xytext=(3, 1.8),\n    arrowprops=dict(facecolor='green', shrink=0.05),\n)\n```\n"},"/programming-languages/python/matplotlib#Legends":{"id":"/programming-languages/python/matplotlib#Legends","title":"/programming-languages/python/matplotlib#Legends","tags":"[]#Legends","body":"```python\nplt.title('Title')\nplt.legend(loc='max')\nplt.legend(loc='upper left')\nax.set(title='Axes', xlabel='x', ylabel='y')\n```\n"},"/programming-languages/python/matplotlib#Limits":{"id":"/programming-languages/python/matplotlib#Limits","title":"/programming-languages/python/matplotlib#Limits","tags":"[]#Limits","body":"```python\nax.axis('equal')\nax.margins(x=0.0, y=0.1)\nax.set(xlim=[0,1], ylim=[0,10])\nax.set_xlim([0,1])\n```\n"},"/programming-languages/python/matplotlib#Ticks":{"id":"/programming-languages/python/matplotlib#Ticks","title":"/programming-languages/python/matplotlib#Ticks","tags":"[]#Ticks","body":"```python\nax.xaxis.set(\n    ticks=range(1, 10),\n    ticklabels=[1, 'foo', -10, 'bar'],\n)\n```\n"},"/programming-languages/python/numpy#":{"id":"/programming-languages/python/numpy#","title":"/programming-languages/python/numpy#","tags":"[]#","body":""},"/programming-languages/python/numpy#Installation":{"id":"/programming-languages/python/numpy#Installation","title":"/programming-languages/python/numpy#Installation","tags":"[]#Installation","body":"```python\npip install numpy\n```\n"},"/programming-languages/python/numpy#Usage":{"id":"/programming-languages/python/numpy#Usage","title":"/programming-languages/python/numpy#Usage","tags":"[]#Usage","body":"NumPy is the core library for working with numbers in python. It provides high-performance multidimensional arrays. See [full documentation](https://numpy.org/doc/stable/reference/index.html).\n```python\nimport numpy as np\n```\n"},"/programming-languages/python/numpy#Input-and-output":{"id":"/programming-languages/python/numpy#Input-and-output","title":"/programming-languages/python/numpy#Input-and-output","tags":"[]#Input-and-output","body":"Read or write files with different formats.\n"},"/programming-languages/python/numpy#Read":{"id":"/programming-languages/python/numpy#Read","title":"/programming-languages/python/numpy#Read","tags":"[]#Read","body":"```python\nnp.load('name.npy')\nnp.loadtxt('name.txt')\nnp.genfromtext('name.csv', delimiter=',')\n```\n"},"/programming-languages/python/numpy#Write":{"id":"/programming-languages/python/numpy#Write","title":"/programming-languages/python/numpy#Write","tags":"[]#Write","body":"```python\nnp.save('name', a)\nnp.savez('name', a, b)\nnp.savetxt('name.txt', a, delimiter=' ')\n```\n"},"/programming-languages/python/numpy#Create-arrays":{"id":"/programming-languages/python/numpy#Create-arrays","title":"/programming-languages/python/numpy#Create-arrays","tags":"[]#Create-arrays","body":"Different routines for creating an array. See [documentation](https://numpy.org/doc/stable/reference/routines.html).\n```python\na = np.array([1,2,3])\na = np.array([[(1,2,3), (4,5,6)], [(7,8,9), (10,11,12)]], dtype=float)\n```\n"},"/programming-languages/python/numpy#Zeros":{"id":"/programming-languages/python/numpy#Zeros","title":"/programming-languages/python/numpy#Zeros","tags":"[]#Zeros","body":"```python\n>>> np.zeros((2, 1))\narray([[ 0.],\n       [ 0.]])\n```\n"},"/programming-languages/python/numpy#Ones":{"id":"/programming-languages/python/numpy#Ones","title":"/programming-languages/python/numpy#Ones","tags":"[]#Ones","body":"```python\n>>> np.ones((2, 1))\narray([[1.],\n       [1.]])\n```\n"},"/programming-languages/python/numpy#Empty":{"id":"/programming-languages/python/numpy#Empty","title":"/programming-languages/python/numpy#Empty","tags":"[]#Empty","body":"```python\n>>> np.empty([2, 2], dtype=int)\narray([[-2312341235, -234123552],\n       [  12344234,    45357345]])\n```\n"},"/programming-languages/python/numpy#Arange":{"id":"/programming-languages/python/numpy#Arange","title":"/programming-languages/python/numpy#Arange","tags":"[]#Arange","body":"```python\n>>> np.arange(3,7)\narray([3, 4, 5, 6])\n>>> np.arange(3,7,2)\narray([3, 5])\n```\n"},"/programming-languages/python/numpy#Linspace":{"id":"/programming-languages/python/numpy#Linspace","title":"/programming-languages/python/numpy#Linspace","tags":"[]#Linspace","body":"```python\n>>> np.linspace(2.0, 3.0, num=5)\narray([2.  , 2.25, 2.5 , 2.75, 3.  ])\n```\n"},"/programming-languages/python/numpy#Full":{"id":"/programming-languages/python/numpy#Full","title":"/programming-languages/python/numpy#Full","tags":"[]#Full","body":"```python\n>>> np.full((2, 2), 10)\narray([[10, 10],\n       [10, 10]])\n```\n"},"/programming-languages/python/numpy#Eye-(identity)":{"id":"/programming-languages/python/numpy#Eye-(identity)","title":"/programming-languages/python/numpy#Eye-(identity)","tags":"[]#Eye-(identity)","body":"```python\n>>> np.eye(2, dtype=int)\narray([[1, 0],\n       [0, 1]])\n>>> np.eye(3, k=1)\narray([[0.,  1.,  0.],\n       [0.,  0.,  1.],\n       [0.,  0.,  0.]])\n```\n"},"/programming-languages/python/numpy#Describe":{"id":"/programming-languages/python/numpy#Describe","title":"/programming-languages/python/numpy#Describe","tags":"[]#Describe","body":"```python\n# dimension\na.shape\n# length\nlen(a)\n# number of array dimensions\na.ndim\n# number of array elements\na.size\n# data type\na.dtype\n```\n"},"/programming-languages/python/numpy#Common-functions":{"id":"/programming-languages/python/numpy#Common-functions","title":"/programming-languages/python/numpy#Common-functions","tags":"[]#Common-functions","body":"```python\n# summation\na.sum()\n# min\na.min()\n# max\na.max()\n# mean value\na.mean()\n# median\na.median()\n```\n"},"/programming-languages/python/numpy#Manipulation":{"id":"/programming-languages/python/numpy#Manipulation","title":"/programming-languages/python/numpy#Manipulation","tags":"[]#Manipulation","body":"Different functions for reshaping the array. See [documentation](https://numpy.org/doc/stable/reference/routines.array-manipulation.html)\n"},"/programming-languages/python/numpy#Trasposing":{"id":"/programming-languages/python/numpy#Trasposing","title":"/programming-languages/python/numpy#Trasposing","tags":"[]#Trasposing","body":"```python\nnp.transpose(a)\n# or\na.T\n```\n"},"/programming-languages/python/numpy#Adding-or-removing-elements":{"id":"/programming-languages/python/numpy#Adding-or-removing-elements","title":"/programming-languages/python/numpy#Adding-or-removing-elements","tags":"[]#Adding-or-removing-elements","body":"```python\n# insert value at index\nnp.insert(a, index, value)\n# append items\nnp.append(a, b)\n# remove items\nnp.remove(a, [1])\n# resize array\na=np.array([[0,1],[2,3]])\n>>> np.resize(a,(2,3))\narray([[0, 1, 2],\n       [3, 0, 1]])\n>>> np.resize(a,(1,4))\narray([[0, 1, 2, 3]])\n>>> np.resize(a,(2,4))\narray([[0, 1, 2, 3],\n       [0, 1, 2, 3]])\n```\n"},"/programming-languages/python/pandas#":{"id":"/programming-languages/python/pandas#","title":"/programming-languages/python/pandas#","tags":"[]#","body":""},"/programming-languages/python/pandas#Installation":{"id":"/programming-languages/python/pandas#Installation","title":"/programming-languages/python/pandas#Installation","tags":"[]#Installation","body":"```python\npip install pandas\n```\n"},"/programming-languages/python/pandas#Usage":{"id":"/programming-languages/python/pandas#Usage","title":"/programming-languages/python/pandas#Usage","tags":"[]#Usage","body":"Pandas uses NumPy for most data types. See [full documentation](https://pandas.pydata.org/docs/reference/index.html).\n```python\nimport pandas as pd\n```\n"},"/programming-languages/python/pandas#Input-and-output":{"id":"/programming-languages/python/pandas#Input-and-output","title":"/programming-languages/python/pandas#Input-and-output","tags":"[]#Input-and-output","body":"Read and write files with different formats. See [documentation](https://pandas.pydata.org/docs/reference/io.html).\n"},"/programming-languages/python/pandas#Read":{"id":"/programming-languages/python/pandas#Read","title":"/programming-languages/python/pandas#Read","tags":"[]#Read","body":"```python\n# csv\ndf = pd.read_csv(path)\n# excel\ndf = pd.read_excel(path)\n# custom delimiter\ndf = pd.read_csv(path, delimiter='\\t')\n```\n"},"/programming-languages/python/pandas#Write":{"id":"/programming-languages/python/pandas#Write","title":"/programming-languages/python/pandas#Write","tags":"[]#Write","body":"```python\n# csv\ndf.to_csv('path.csv', index=False)\n# excel\n# one sheet\ndf.to_excel(\"path.xlsx\", sheet_name='Sheet_name_1')\n# more than one\ndf2 = df1.copy()\nwith pd.ExcelWriter('output.xlsx') as writer:\n    df1.to_excel(writer, sheet_name='Sheet_name_1')\n    df2.to_excel(writer, sheet_name='Sheet_name_2')\n```\n"},"/programming-languages/python/pandas#Accessing-rows-and-columns":{"id":"/programming-languages/python/pandas#Accessing-rows-and-columns","title":"/programming-languages/python/pandas#Accessing-rows-and-columns","tags":"[]#Accessing-rows-and-columns","body":"Selecting and accessing different data. See [user guide](https://pandas.pydata.org/docs/user_guide/indexing.html).\n```python\n# get the first 4 rows\ndf.head(4)\n# get the last 4 rows\ndf.tail(4)\n# get headers\ndf.columns\n# read specific column\ndf['A']\n# read multiple columns\ndf[['A', 'B']]\n# read specific row\ndf[0]\n# read multiple rows\ndf[0:4]\n# read specific location (row=2, column=1)\ndf.iloc[2,1]\n# loop through each row\nfor index, row in df.iterrows():\n    print(index, row)\n# filter\n# will give every row with the type value fire\ndf.loc[df['A'] == 'test']\n```\n"},"/programming-languages/python/pandas#Sorting-and-describing-data":{"id":"/programming-languages/python/pandas#Sorting-and-describing-data","title":"/programming-languages/python/pandas#Sorting-and-describing-data","tags":"[]#Sorting-and-describing-data","body":"```python\n# will give count, mean, standard deviation, min, max, 25%, 50%, 75%\ndf.describe()\n# sort by column\ndf.sort_values('A', ascending=True)\n# will sort first by name then by type\ndf.sort_values(['A', 'B'], ascending=True)\n# will sort first by name then by type\n# the first with ascending=True and the last with ascending=False\ndf.sort_values(['A', 'B'], ascending=[1, 0])\n```\n"},"/programming-languages/python/pandas#Manipulate-data":{"id":"/programming-languages/python/pandas#Manipulate-data","title":"/programming-languages/python/pandas#Manipulate-data","tags":"[]#Manipulate-data","body":"```python\n# create a new column with the values from column 'name' and 'type'\n# it makes sense if 'name' and 'type' are numbers\ndf['C'] = df['A'] + df['B']\n# or\ndf['C'] = df.iloc[:, :].sum(axis=1)\n# remove column\ndf = df.drop(columns=['C'])\n```\n"},"/programming-languages/python/pandas#Plotting":{"id":"/programming-languages/python/pandas#Plotting","title":"/programming-languages/python/pandas#Plotting","tags":"[]#Plotting","body":""},"/programming-languages/python/python#":{"id":"/programming-languages/python/python#","title":"/programming-languages/python/python#","tags":"[]#","body":""},"/programming-languages/python/python#Enumerate":{"id":"/programming-languages/python/python#Enumerate","title":"/programming-languages/python/python#Enumerate","tags":"[]#Enumerate","body":"```python\n>>> a = ['A', 'B', 'C']\n>>> list(enumerate(a))\n[(0, 'A'), (1, 'B'), (2, 'C')]\n```\n"},"/programming-languages/python/python#Comprehension":{"id":"/programming-languages/python/python#Comprehension","title":"/programming-languages/python/python#Comprehension","tags":"[]#Comprehension","body":"```python\n# list comprehension\n>>> m = [x ** 2 for x in range(5)]\n>>> m\n[0, 1, 4, 9, 16]\n# set comprehension\n>>> m = {x ** 2 for x in range(5)}\n>>> m\n{0, 1, 4, 9, 16}\n# dict comprehension\n>>> m = {x: x ** 2 for x in range(5)}\n>>> m\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16}\n```\n"},"/programming-languages/python/python#Generator":{"id":"/programming-languages/python/python#Generator","title":"/programming-languages/python/python#Generator","tags":"[]#Generator","body":"```python\n# a generator is evaluated lazily\n>>> m = (x ** 2 for x in range(5))\n>>> list(m)\n[0, 1, 4, 9, 16]\n```\n"},"/programming-languages/python/python#Unpacking":{"id":"/programming-languages/python/python#Unpacking","title":"/programming-languages/python/python#Unpacking","tags":"[]#Unpacking","body":"```python\n>>> a, b, c = 1, 2, 3\n>>> a, b, c\n(1, 2, 3)\n>>> a, b, c = [1, 2, 3]\n>>> a, b, c\n(1, 2, 3)\n>>> a, *b, c = [1, 2, 3, 4, 5]\n>>> a\n1\n>>> b\n[2, 3, 4]\n>>> c\n5\n```\n"},"/programming-languages/python/python#Swapping":{"id":"/programming-languages/python/python#Swapping","title":"/programming-languages/python/python#Swapping","tags":"[]#Swapping","body":"```python\n>>> a, b = 1, 2\n>>> a, b = b, a\n>>> a, b\n(2, 1)\n```\n"},"/programming-languages/python/python#Slices":{"id":"/programming-languages/python/python#Slices","title":"/programming-languages/python/python#Slices","tags":"[]#Slices","body":"```python\n# items start through stop-1 with increment\na[start:stop:increment]\n# items start through the rest of the array\na[start:]\n# items from the beginning through stop-1\na[:stop]\n# a copy of the whole array\na[:]\n# a copy of the whole array\na[::]\n# last item in the array\na[-1]\n# last two items in the array\na[-2:]\n# everything except the last two items\na[:-2]\n# all items in the array, reversed\na[::-1]\n```\n"},"/programming-languages/python/scikit-learn#":{"id":"/programming-languages/python/scikit-learn#","title":"/programming-languages/python/scikit-learn#","tags":"[]#","body":""},"/programming-languages/rust/rust#":{"id":"/programming-languages/rust/rust#","title":"/programming-languages/rust/rust#","tags":"[]#","body":"- [the book][thebook]\n- [rustlings][rustlings]\n- [by example][example]\n- [standard lib][std]\n- [edition guide][edition]\n- [cargo][cargo]\n- [rustdoc][rustdoc]\n- [rust compiler (rustc)][rustc]\n- [error][error]\n- [command line apps][cmd]\n- [webassenbly][wasm]\n- [embedded][embedded]\n- [reference][reference]\n- [nomicon - the dark arts of rust][nomicon]\n- [really unstable][unstable]\n- [sheet][sheet]\n[thebook]: https://doc.rust-lang.org/book/\n[rustlings]: https://github.com/rust-lang/rustlings/\n[example]: https://doc.rust-lang.org/stable/rust-by-example/\n[std]: https://doc.rust-lang.org/std/index.html\n[edition]: https://doc.rust-lang.org/edition-guide/index.html\n[cargo]: https://doc.rust-lang.org/cargo/index.html\n[rustdoc]: https://doc.rust-lang.org/rustdoc/index.html\n[rustc]: https://doc.rust-lang.org/rustc/index.html\n[error]: https://doc.rust-lang.org/error-index.html\n[cmd]: https://rust-cli.github.io/book/index.html\n[wasm]: https://rustwasm.github.io/docs/book/\n[embedded]: https://doc.rust-lang.org/stable/embedded-book/\n[reference]: https://doc.rust-lang.org/reference/index.html\n[nomicon]: https://doc.rust-lang.org/nomicon/index.html\n[unstable]: https://doc.rust-lang.org/nightly/unstable-book/index.html\n[sheet]: https://cheats.rs/\n"},"/web/react#":{"id":"/web/react#","title":"/web/react#","tags":"[]#","body":"```bash\nnpx create-react-app <app> --typescript\n```\n"}}